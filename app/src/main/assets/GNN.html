<div class="vector-header-container"><header class="vector-header mw-header">
<div class="vector-header-start"><nav class="vector-main-menu-landmark">
<div id="vector-main-menu-dropdown" class="vector-dropdown vector-main-menu-dropdown vector-button-flush-left vector-button-flush-right"><input id="vector-main-menu-dropdown-checkbox" class="vector-dropdown-checkbox " type="checkbox" data-event-name="ui.dropdown-vector-main-menu-dropdown" /><label id="vector-main-menu-dropdown-label" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " for="vector-main-menu-dropdown-checkbox"><span class="vector-dropdown-label-text">Main menu</span></label>
<div class="vector-dropdown-content">&nbsp;</div>
</div>
</nav><a class="mw-logo" href="https://en.wikipedia.org/wiki/Main_Page"><img class="mw-logo-icon" src="https://en.wikipedia.org/static/images/icons/wikipedia.png" alt="" width="50" height="50" /><span class="mw-logo-container"><img class="mw-logo-wordmark" src="https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-wordmark-en.svg" alt="Wikipedia" /><img class="mw-logo-tagline" src="https://en.wikipedia.org/static/images/mobile/copyright/wikipedia-tagline-en.svg" alt="The Free Encyclopedia" width="117" height="13" /></span></a></div>
<div class="vector-header-end">
<div id="p-search" class="vector-search-box-vue  vector-search-box-collapses vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
<div class="vector-typeahead-search-container">
<div class="cdx-typeahead-search cdx-typeahead-search--show-thumbnail cdx-typeahead-search--auto-expand-width"><form id="searchform" class="cdx-search-input cdx-search-input--has-end-button" action="https://en.wikipedia.org/w/index.php">
<div id="simpleSearch" class="cdx-search-input__input-wrapper" data-search-loc="header-moved">
<div class="cdx-text-input cdx-text-input--has-start-icon"><input id="searchInput" accesskey="f" class="cdx-text-input__input" title="Search Wikipedia [alt-shift-f]" autocomplete="off" name="search" type="search" placeholder="Search Wikipedia" /></div>
</div>
<button class="cdx-button cdx-search-input__end-button">Search</button></form></div>
</div>
</div>
<nav class="vector-user-links">
<div id="p-vector-user-menu-overflow" class="vector-menu mw-portlet mw-portlet-vector-user-menu-overflow">
<div class="vector-menu-content">
<ul class="vector-menu-content-list">
<li id="pt-createaccount-2" class="user-links-collapsible-item mw-list-item"><a title="You are encouraged to create an account and log in; however, it is not mandatory" href="https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&amp;returnto=Generative+adversarial+network">Create account</a></li>
<li id="pt-login-2" class="user-links-collapsible-item mw-list-item"><a accesskey="o" title="You're encouraged to log in; however, it's not mandatory. [alt-shift-o]" href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&amp;returnto=Generative+adversarial+network">Log in</a></li>
</ul>
</div>
</div>
<div id="vector-user-links-dropdown" class="vector-dropdown vector-user-menu vector-button-flush-right vector-user-menu-logged-out" title="Log in and more options"><input id="vector-user-links-dropdown-checkbox" class="vector-dropdown-checkbox " type="checkbox" data-event-name="ui.dropdown-vector-user-links-dropdown" /><label id="vector-user-links-dropdown-label" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " for="vector-user-links-dropdown-checkbox"><span class="vector-dropdown-label-text">Personal tools</span></label>
<div class="vector-dropdown-content">&nbsp;</div>
</div>
</nav></div>
</header></div>
<div class="mw-page-container">
<div class="mw-page-container-inner">
<div class="vector-main-menu-container ">&nbsp;</div>
<div class="vector-sitenotice-container">&nbsp;</div>
<nav id="mw-panel-toc" class="mw-table-of-contents-container vector-toc-landmark vector-sticky-pinned-container" data-event-name="ui.sidebar-toc">
<div id="vector-toc-pinned-container" class="vector-pinned-container">
<div id="vector-toc" class="vector-toc vector-pinnable-element">
<div class="vector-pinnable-header vector-toc-pinnable-header vector-pinnable-header-pinned" data-feature-name="toc-pinned" data-pinnable-element-id="vector-toc">
<h2 class="vector-pinnable-header-label">Contents</h2>
&nbsp;<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-toc.unpin">hide</button></div>
<ul id="mw-panel-toc-list" class="vector-toc-contents">
<li id="toc-mw-content-text" class="vector-toc-list-item vector-toc-level-1 vector-toc-level-1-active vector-toc-list-item-active">
<div class="vector-toc-text">(Top)</div>
</li>
<li id="toc-Definition" class="vector-toc-list-item vector-toc-level-1">
<div class="vector-toc-text">Definition</div>
<button class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">Toggle Definition subsection</button>
<ul id="toc-Definition-sublist" class="vector-toc-list"></ul>
</li>
<li id="toc-Mathematical_properties" class="vector-toc-list-item vector-toc-level-1">
<div class="vector-toc-text">Mathematical properties</div>
<button class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">Toggle Mathematical properties subsection</button>
<ul id="toc-Mathematical_properties-sublist" class="vector-toc-list"></ul>
</li>
<li id="toc-Training_and_evaluating_GAN" class="vector-toc-list-item vector-toc-level-1">
<div class="vector-toc-text">Training and evaluating GAN</div>
<button class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">Toggle Training and evaluating GAN subsection</button>
<ul id="toc-Training_and_evaluating_GAN-sublist" class="vector-toc-list"></ul>
</li>
<li id="toc-Variants" class="vector-toc-list-item vector-toc-level-1">
<div class="vector-toc-text">Variants</div>
<button class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">Toggle Variants subsection</button>
<ul id="toc-Variants-sublist" class="vector-toc-list"></ul>
</li>
<li id="toc-Applications" class="vector-toc-list-item vector-toc-level-1">
<div class="vector-toc-text">Applications</div>
<button class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">Toggle Applications subsection</button>
<ul id="toc-Applications-sublist" class="vector-toc-list"></ul>
</li>
<li id="toc-AI_generated_video" class="vector-toc-list-item vector-toc-level-1">
<div class="vector-toc-text">AI generated video</div>
<button class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">Toggle AI generated video subsection</button>
<ul id="toc-AI_generated_video-sublist" class="vector-toc-list"></ul>
</li>
<li id="toc-History" class="vector-toc-list-item vector-toc-level-1">
<div class="vector-toc-text">History</div>
<ul id="toc-History-sublist" class="vector-toc-list"></ul>
</li>
<li id="toc-References" class="vector-toc-list-item vector-toc-level-1">
<div class="vector-toc-text">References</div>
<ul id="toc-References-sublist" class="vector-toc-list"></ul>
</li>
<li id="toc-External_links" class="vector-toc-list-item vector-toc-level-1">
<div class="vector-toc-text">External links</div>
<ul id="toc-External_links-sublist" class="vector-toc-list"></ul>
</li>
</ul>
</div>
</div>
</nav>
<div class="mw-content-container"><header class="mw-body-header vector-page-titlebar">
<h1 id="firstHeading" class="firstHeading mw-first-heading"><span class="mw-page-title-main">Generative adversarial network</span></h1>
<div id="p-lang-btn" class="vector-dropdown mw-portlet mw-portlet-lang"><input id="p-lang-btn-checkbox" class="vector-dropdown-checkbox mw-interlanguage-selector" type="checkbox" data-event-name="ui.dropdown-p-lang-btn" /><label id="p-lang-btn-label" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive mw-portlet-lang-heading-23" for="p-lang-btn-checkbox"><span class="vector-dropdown-label-text">23 languages</span></label></div>
</header>
<div class="vector-page-toolbar">
<div class="vector-page-toolbar-container">
<div id="left-navigation"><nav>
<div id="p-associated-pages" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-associated-pages">
<div class="vector-menu-content">
<ul class="vector-menu-content-list">
<li id="ca-nstab-main" class="selected vector-tab-noicon mw-list-item"><a accesskey="c" class="" title="View the content page [alt-shift-c]" href="https://en.wikipedia.org/wiki/Generative_adversarial_network" data-mw="interface">Article</a></li>
<li id="ca-talk" class="vector-tab-noicon mw-list-item"><a accesskey="t" class="" title="Discuss improvements to the content page [alt-shift-t]" href="https://en.wikipedia.org/wiki/Talk:Generative_adversarial_network" rel="discussion" data-mw="interface">Talk</a></li>
</ul>
</div>
</div>
</nav></div>
<div id="right-navigation" class="vector-collapsible"><nav>
<div id="p-views" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-views">
<div class="vector-menu-content">
<ul class="vector-menu-content-list">
<li id="ca-view" class="selected vector-tab-noicon mw-list-item"><a class="" href="https://en.wikipedia.org/wiki/Generative_adversarial_network" data-mw="interface">Read</a></li>
<li id="ca-edit" class="vector-tab-noicon mw-list-item"><a accesskey="e" class="" title="Edit this page [alt-shift-e]" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit" data-mw="interface">Edit</a></li>
<li id="ca-history" class="vector-tab-noicon mw-list-item"><a accesskey="h" class="" title="Past revisions of this page [alt-shift-h]" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=history" data-mw="interface">View history</a></li>
</ul>
</div>
</div>
</nav><nav class="vector-page-tools-landmark">
<div id="vector-page-tools-dropdown" class="vector-dropdown vector-page-tools-dropdown"><input id="vector-page-tools-dropdown-checkbox" class="vector-dropdown-checkbox " type="checkbox" data-event-name="ui.dropdown-vector-page-tools-dropdown" /><label id="vector-page-tools-dropdown-label" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" for="vector-page-tools-dropdown-checkbox"><span class="vector-dropdown-label-text">Tools</span></label>
<div class="vector-dropdown-content">&nbsp;</div>
</div>
</nav></div>
</div>
</div>
<div class="vector-column-end">&nbsp;</div>
<div id="bodyContent" class="vector-body ve-init-mw-desktopArticleTarget-targetContainer" data-mw-ve-target-container="">
<div class="vector-body-before-content">
<div class="mw-indicators">&nbsp;</div>
<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
</div>
<div id="contentSub">&nbsp;</div>
<div id="mw-content-text" class="mw-body-content mw-content-ltr" dir="ltr" lang="en">
<div class="mw-parser-output">
<div class="hatnote navigation-not-searchable">Not to be confused with&nbsp;<a title="Adversarial machine learning" href="https://en.wikipedia.org/wiki/Adversarial_machine_learning">Adversarial machine learning</a>.</div>
<table class="sidebar sidebar-collapse nomobile nowraplinks">
<tbody>
<tr>
<td class="sidebar-pretitle">Part of a series on</td>
</tr>
<tr>
<th class="sidebar-title-with-pretitle"><a title="Machine learning" href="https://en.wikipedia.org/wiki/Machine_learning">Machine learning</a><br />and&nbsp;<a title="Data mining" href="https://en.wikipedia.org/wiki/Data_mining">data mining</a></th>
</tr>
<tr>
<td class="sidebar-image"><span class="mw-default-size"><a class="mw-file-description" title="Scatterplot featuring a linear support vector machine's decision boundary (dashed line)" href="https://en.wikipedia.org/wiki/File:Kernel_Machine.svg"><img class="mw-file-element" src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/220px-Kernel_Machine.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" alt="Scatterplot featuring a linear support vector machine's decision boundary (dashed line)" width="220" height="100" data-file-width="512" data-file-height="233" /></a></span></td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title">Paradigms</div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title">Problems</div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title">
<div><a title="Supervised learning" href="https://en.wikipedia.org/wiki/Supervised_learning">Supervised learning</a><br /><span class="nobold">(<strong><a title="Statistical classification" href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a></strong>&nbsp;&bull;&nbsp;<strong><a title="Regression analysis" href="https://en.wikipedia.org/wiki/Regression_analysis">regression</a></strong>)</span></div>
</div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title"><a title="Cluster analysis" href="https://en.wikipedia.org/wiki/Cluster_analysis">Clustering</a></div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title"><a title="Dimensionality reduction" href="https://en.wikipedia.org/wiki/Dimensionality_reduction">Dimensionality reduction</a></div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title"><a title="Structured prediction" href="https://en.wikipedia.org/wiki/Structured_prediction">Structured prediction</a></div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title"><a title="Anomaly detection" href="https://en.wikipedia.org/wiki/Anomaly_detection">Anomaly detection</a></div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default" tabindex="0" type="button"><span class="mw-collapsible-text">hide</span></button>
<div class="sidebar-list-title"><a title="Artificial neural network" href="https://en.wikipedia.org/wiki/Artificial_neural_network">Artificial neural network</a></div>
<div class="sidebar-list-content mw-collapsible-content hlist">
<ul>
<li><a title="Autoencoder" href="https://en.wikipedia.org/wiki/Autoencoder">Autoencoder</a></li>
<li><a title="Cognitive computing" href="https://en.wikipedia.org/wiki/Cognitive_computing">Cognitive computing</a></li>
<li><a title="Deep learning" href="https://en.wikipedia.org/wiki/Deep_learning">Deep learning</a></li>
<li><a title="DeepDream" href="https://en.wikipedia.org/wiki/DeepDream">DeepDream</a></li>
<li><a title="Multilayer perceptron" href="https://en.wikipedia.org/wiki/Multilayer_perceptron">Multilayer perceptron</a></li>
<li><a title="Recurrent neural network" href="https://en.wikipedia.org/wiki/Recurrent_neural_network">RNN</a>&nbsp;
<ul>
<li><a title="Long short-term memory" href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM</a></li>
<li><a title="Gated recurrent unit" href="https://en.wikipedia.org/wiki/Gated_recurrent_unit">GRU</a></li>
<li><a title="Echo state network" href="https://en.wikipedia.org/wiki/Echo_state_network">ESN</a></li>
<li><a title="Reservoir computing" href="https://en.wikipedia.org/wiki/Reservoir_computing">reservoir computing</a></li>
</ul>
</li>
<li><a title="Restricted Boltzmann machine" href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine">Restricted Boltzmann machine</a></li>
<li><a class="mw-selflink selflink">GAN</a></li>
<li><a title="Self-organizing map" href="https://en.wikipedia.org/wiki/Self-organizing_map">SOM</a></li>
<li><a title="Convolutional neural network" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional neural network</a>&nbsp;
<ul>
<li><a title="U-Net" href="https://en.wikipedia.org/wiki/U-Net">U-Net</a></li>
</ul>
</li>
<li><a title="Transformer (machine learning model)" href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Transformer</a>&nbsp;
<ul>
<li><a title="Vision transformer" href="https://en.wikipedia.org/wiki/Vision_transformer">Vision</a></li>
</ul>
</li>
<li><a title="Spiking neural network" href="https://en.wikipedia.org/wiki/Spiking_neural_network">Spiking neural network</a></li>
<li><a title="Memtransistor" href="https://en.wikipedia.org/wiki/Memtransistor">Memtransistor</a></li>
<li><a title="Electrochemical RAM" href="https://en.wikipedia.org/wiki/Electrochemical_RAM">Electrochemical RAM</a>&nbsp;(ECRAM)</li>
</ul>
</div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title"><a title="Reinforcement learning" href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement learning</a></div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title">Learning with humans</div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title">Model diagnostics</div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title">Mathematical foundations</div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title">Machine-learning venues</div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="sidebar-list-title">Related articles</div>
</div>
</td>
</tr>
<tr>
<td class="sidebar-navbar">
<div class="navbar plainlinks hlist navbar-mini">
<ul>
<li class="nv-view"><a title="Template:Machine learning" href="https://en.wikipedia.org/wiki/Template:Machine_learning"><abbr title="View this template">v</abbr></a></li>
<li class="nv-talk"><a title="Template talk:Machine learning" href="https://en.wikipedia.org/wiki/Template_talk:Machine_learning"><abbr title="Discuss this template">t</abbr></a></li>
<li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li>
</ul>
</div>
</td>
</tr>
</tbody>
</table>
<figure class="mw-default-size"><a class="mw-file-description" href="https://en.wikipedia.org/wiki/File:Generative_Adversarial_Network_illustration.svg"><img class="mw-file-element" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Generative_Adversarial_Network_illustration.svg/220px-Generative_Adversarial_Network_illustration.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Generative_Adversarial_Network_illustration.svg/330px-Generative_Adversarial_Network_illustration.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Generative_Adversarial_Network_illustration.svg/440px-Generative_Adversarial_Network_illustration.svg.png 2x" alt="" width="220" height="81" data-file-width="1021" data-file-height="378" /></a>
<figcaption>An illustration of how a GAN works.</figcaption>
</figure>
<p>A&nbsp;<strong>generative adversarial network</strong>&nbsp;(<strong>GAN</strong>) is a class of&nbsp;<a title="Machine learning" href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>&nbsp;frameworks and a prominent framework for approaching&nbsp;<a class="mw-redirect" title="Generative AI" href="https://en.wikipedia.org/wiki/Generative_AI">generative AI</a>.<sup id="cite_ref-1" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-1">[1]</a></sup><sup id="cite_ref-2" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-2">[2]</a></sup>&nbsp;The concept was initially developed by&nbsp;<a title="Ian Goodfellow" href="https://en.wikipedia.org/wiki/Ian_Goodfellow">Ian Goodfellow</a>&nbsp;and his colleagues in June 2014.<sup id="cite_ref-GANnips_3-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup>&nbsp;In a GAN, two&nbsp;<a title="Neural network" href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>&nbsp;contest with each other in the form of a&nbsp;<a title="Zero-sum game" href="https://en.wikipedia.org/wiki/Zero-sum_game">zero-sum game</a>, where one agent's gain is another agent's loss.<sup id="cite_ref-tomczak2020_4-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-tomczak2020-4">[4]</a></sup></p>
<p>Given a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of&nbsp;<a title="Generative model" href="https://en.wikipedia.org/wiki/Generative_model">generative model</a>&nbsp;for&nbsp;<a title="Unsupervised learning" href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised learning</a>, GANs have also proved useful for&nbsp;<a class="mw-redirect" title="Semi-supervised learning" href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised learning</a>,<sup id="cite_ref-ITT_GANs_5-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-ITT_GANs-5">[5]</a></sup>&nbsp;fully&nbsp;<a title="Supervised learning" href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>,<sup id="cite_ref-6" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-6">[6]</a></sup>&nbsp;and&nbsp;<a title="Reinforcement learning" href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>.<sup id="cite_ref-7" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-7">[7]</a></sup></p>
<p>The core idea of a GAN is based on the "indirect" training through the discriminator, another neural network that can tell how "realistic" the input seems, which itself is also being updated dynamically.<sup id="cite_ref-8" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-8">[8]</a></sup>&nbsp;This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.</p>
<p>GANs are similar to&nbsp;<a title="Mimicry" href="https://en.wikipedia.org/wiki/Mimicry">mimicry</a>&nbsp;in&nbsp;<a title="Evolutionary biology" href="https://en.wikipedia.org/wiki/Evolutionary_biology">evolutionary biology</a>, with an&nbsp;<a title="Evolutionary arms race" href="https://en.wikipedia.org/wiki/Evolutionary_arms_race">evolutionary arms race</a>&nbsp;between both networks.</p>
<h2><span id="Definition" class="mw-headline">Definition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Definition" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=1">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span id="Mathematical" class="mw-headline">Mathematical</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Mathematical" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=2">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The original GAN is defined as the following&nbsp;<a title="Game theory" href="https://en.wikipedia.org/wiki/Game_theory">game</a>:<sup id="cite_ref-GANnips_3-1" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup></p>
<blockquote>
<p>Each&nbsp;<a title="Probability space" href="https://en.wikipedia.org/wiki/Probability_space">probability space</a>&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(&Omega;,����)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f37076644bc268ce5c2a4c572d85499087f3c366" alt="{\displaystyle (\Omega ,\mu _{ref})}" /></span>&nbsp;defines a GAN game.</p>
<p>There are 2 players: generator and discriminator.</p>
<p>The generator's&nbsp;<a title="Strategy (game theory)" href="https://en.wikipedia.org/wiki/Strategy_(game_theory)">strategy set</a>&nbsp;is&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(&Omega;)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b95df45bc7d7faec1a5b88437d4b26b8a16ad108" alt="{\displaystyle {\mathcal {P}}(\Omega )}" /></span>, the set of all probability measures&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>&nbsp;on&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d80b0b33ae50a23bfe35d912fb6d780bf6e9f135" alt="\Omega " /></span>.</p>
<p>The discriminator's strategy set is the set of&nbsp;<a title="Markov kernel" href="https://en.wikipedia.org/wiki/Markov_kernel">Markov kernels</a>&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��:&Omega;&rarr;�[0,1]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dce97271df1c30e57ae96f72c566661f1bae9dad" alt="{\displaystyle \mu _{D}:\Omega \to {\mathcal {P}}[0,1]}" /></span>, where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�[0,1]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/23bc6194efec9e3aaf67b5270e6b8cbc3834d99e" alt="{\displaystyle {\mathcal {P}}[0,1]}" /></span>&nbsp;is the set of probability measures on&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">[0,1]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/20265bacd2212748888b178c01f3114e7f380ba4" alt="[0,1]" /></span>.</p>
<p>The GAN game is a&nbsp;<a title="Zero-sum game" href="https://en.wikipedia.org/wiki/Zero-sum_game">zero-sum game</a>, with objective function</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(��,��):=��&sim;����,�&sim;��(�)[ln⁡�]+��&sim;��,�&sim;��(�)[ln⁡(1&minus;�)].</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4f9a7e2d9dfb639407838c714845709e09adf451" alt="{\displaystyle L(\mu _{G},\mu _{D}):=\mathbb {E} _{x\sim \mu _{ref},y\sim \mu _{D}(x)}[\ln y]+\mathbb {E} _{x\sim \mu _{G},y\sim \mu _{D}(x)}[\ln(1-y)].}" /></div>
The generator aims to minimize the objective, and the discriminator aims to maximize the objective.
<p>&nbsp;</p>
</blockquote>
<p>The generator's task is to approach&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��&asymp;����</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/148823eaf9f7df04583d3b662626b9bbebb442dc" alt="{\displaystyle \mu _{G}\approx \mu _{ref}}" /></span>, that is, to match its own output distribution as closely as possible to the reference distribution. The discriminator's task is to output a value close to 1 when the input appears to be from the reference distribution, and to output a value close to 0 when the input looks like it came from the generator distribution.</p>
<h3><span id="In_practice" class="mw-headline">In practice</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: In practice" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=3">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The&nbsp;<a title="Generative model" href="https://en.wikipedia.org/wiki/Generative_model"><em>generative</em>&nbsp;network</a>&nbsp;generates candidates while the&nbsp;<a title="Discriminative model" href="https://en.wikipedia.org/wiki/Discriminative_model"><em>discriminative</em>&nbsp;network</a>&nbsp;evaluates them.<sup id="cite_ref-GANnips_3-2" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup>&nbsp;The contest operates in terms of data distributions. Typically, the generative network learns to map from a&nbsp;<a title="Latent space" href="https://en.wikipedia.org/wiki/Latent_space">latent space</a>&nbsp;to a data distribution of interest, while the discriminative network distinguishes candidates produced by the generator from the true data distribution. The generative network's training objective is to increase the error rate of the discriminative network (i.e., "fool" the discriminator network by producing novel candidates that the discriminator thinks are not synthesized (are part of the true data distribution)).<sup id="cite_ref-GANnips_3-3" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup><sup id="cite_ref-9" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-9">[9]</a></sup></p>
<p>A known dataset serves as the initial training data for the discriminator. Training involves presenting it with samples from the training dataset until it achieves acceptable accuracy. The generator is trained based on whether it succeeds in fooling the discriminator. Typically, the generator is seeded with randomized input that is sampled from a predefined&nbsp;<a title="Latent space" href="https://en.wikipedia.org/wiki/Latent_space">latent space</a>&nbsp;(e.g. a&nbsp;<a title="Multivariate normal distribution" href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">multivariate normal distribution</a>). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. Independent&nbsp;<a title="Backpropagation" href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>&nbsp;procedures are applied to both networks so that the generator produces better samples, while the discriminator becomes more skilled at flagging synthetic samples.<sup id="cite_ref-OpenAI_com_10-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-OpenAI_com-10">[10]</a></sup>&nbsp;When used for image generation, the generator is typically a&nbsp;<a class="new" title="Deconvolutional neural network (page does not exist)" href="https://en.wikipedia.org/w/index.php?title=Deconvolutional_neural_network&amp;action=edit&amp;redlink=1">deconvolutional neural network</a>, and the discriminator is a&nbsp;<a title="Convolutional neural network" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a>.</p>
<h3><span id="Relation_to_other_statistical_machine_learning_methods" class="mw-headline">Relation to other statistical machine learning methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Relation to other statistical machine learning methods" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=4">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>GANs are&nbsp;<strong>implicit generative models</strong>,<sup id="cite_ref-11" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-11">[11]</a></sup>&nbsp;which means that they do not explicitly model the likelihood function nor provide a means for finding the latent variable corresponding to a given sample, unlike alternatives such as&nbsp;<a title="Flow-based generative model" href="https://en.wikipedia.org/wiki/Flow-based_generative_model">flow-based generative model</a>.</p>
<figure class="mw-default-size"><a class="mw-file-description" href="https://en.wikipedia.org/wiki/File:Types_of_deep_generative_models.png"><img class="mw-file-element" src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Types_of_deep_generative_models.png/220px-Types_of_deep_generative_models.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Types_of_deep_generative_models.png/330px-Types_of_deep_generative_models.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Types_of_deep_generative_models.png/440px-Types_of_deep_generative_models.png 2x" alt="" width="220" height="93" data-file-width="1522" data-file-height="646" /></a>
<figcaption>Main types of deep generative models that perform maximum likelihood estimation<sup id="cite_ref-:5_12-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:5-12">[12]</a></sup></figcaption>
</figure>
<p>Compared to fully visible belief networks such as&nbsp;<a title="WaveNet" href="https://en.wikipedia.org/wiki/WaveNet">WaveNet</a>&nbsp;and PixelRNN and autoregressive models in general, GANs can generate one complete sample in one pass, rather than multiple passes through the network.</p>
<p>Compared to&nbsp;<a title="Boltzmann machine" href="https://en.wikipedia.org/wiki/Boltzmann_machine">Boltzmann machines</a>&nbsp;and nonlinear&nbsp;<a title="Independent component analysis" href="https://en.wikipedia.org/wiki/Independent_component_analysis">ICA</a>, there is no restriction on the type of function used by the network.</p>
<p>Since neural networks are&nbsp;<a title="Universal approximation theorem" href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximators</a>, GANs are&nbsp;<a title="Asymptotic theory (statistics)" href="https://en.wikipedia.org/wiki/Asymptotic_theory_(statistics)">asymptotically consistent</a>.&nbsp;<a class="mw-redirect" title="Variational autoencoders" href="https://en.wikipedia.org/wiki/Variational_autoencoders">Variational autoencoders</a>&nbsp;might be universal approximators, but it is not proven as of 2017.<sup id="cite_ref-:5_12-1" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:5-12">[12]</a></sup></p>
<h2><span id="Mathematical_properties" class="mw-headline">Mathematical properties</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Mathematical properties" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=5">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span id="Measure-theoretic_considerations" class="mw-headline">Measure-theoretic considerations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Measure-theoretic considerations" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=6">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>This section provides some of the mathematical theory behind these methods.</p>
<p>In&nbsp;<a title="Probability axioms" href="https://en.wikipedia.org/wiki/Probability_axioms">modern probability theory</a>&nbsp;based on&nbsp;<a class="mw-redirect" title="Measure theory" href="https://en.wikipedia.org/wiki/Measure_theory">measure theory</a>, a probability space also needs to be equipped with a&nbsp;<a title="&Sigma;-algebra" href="https://en.wikipedia.org/wiki/%CE%A3-algebra">&sigma;-algebra</a>. As a result, a more rigorous definition of the GAN game would make the following changes:</p>
<blockquote>
<p>Each probability space&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(&Omega;,�,����)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/347eca89996b195cda47d892cc834a3ef1a5b2e9" alt="{\displaystyle (\Omega ,{\mathcal {B}},\mu _{ref})}" /></span>&nbsp;defines a GAN game.</p>
<p>The generator's strategy set is&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(&Omega;,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cb03d702198c4033de8ede7e8c8375115e55e739" alt="{\displaystyle {\mathcal {P}}(\Omega ,{\mathcal {B}})}" /></span>, the set of all probability measures&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>&nbsp;on the measure-space&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(&Omega;,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3c71c3b681b11d672fb4712a121dc140ff810ef" alt="{\displaystyle (\Omega ,{\mathcal {B}})}" /></span>.</p>
<p>The discriminator's strategy set is the set of&nbsp;<a title="Markov kernel" href="https://en.wikipedia.org/wiki/Markov_kernel">Markov kernels</a>&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��:(&Omega;,�)&rarr;�([0,1],�([0,1]))</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/54c054944874a3a2751d0c67770b8af5d0425425" alt="{\displaystyle \mu _{D}:(\Omega ,{\mathcal {B}})\to {\mathcal {P}}([0,1],{\mathcal {B}}([0,1]))}" /></span>, where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�([0,1])</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2a2035d78993071419aef7ec2b3f1b7df235173f" alt="{\displaystyle {\mathcal {B}}([0,1])}" /></span>&nbsp;is the&nbsp;<a class="mw-redirect" title="Borel Algebra" href="https://en.wikipedia.org/wiki/Borel_Algebra">Borel &sigma;-algebra</a>&nbsp;on&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">[0,1]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/20265bacd2212748888b178c01f3114e7f380ba4" alt="[0,1]" /></span>.</p>
</blockquote>
<p>Since issues of measurability never arise in practice, these will not concern us further.</p>
<h3><span id="Choice_of_the_strategy_set" class="mw-headline">Choice of the strategy set</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Choice of the strategy set" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=7">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In the most generic version of the GAN game described above, the strategy set for the discriminator contains all Markov kernels&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��:&Omega;&rarr;�[0,1]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dce97271df1c30e57ae96f72c566661f1bae9dad" alt="{\displaystyle \mu _{D}:\Omega \to {\mathcal {P}}[0,1]}" /></span>, and the strategy set for the generator contains arbitrary&nbsp;<a title="Probability distribution" href="https://en.wikipedia.org/wiki/Probability_distribution">probability distributions</a>&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>&nbsp;on&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d80b0b33ae50a23bfe35d912fb6d780bf6e9f135" alt="\Omega " /></span>.</p>
<p>However, as shown below, the optimal discriminator strategy against any&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>&nbsp;is deterministic, so there is no loss of generality in restricting the discriminator's strategies to deterministic functions&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;&rarr;[0,1]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/298d9bf50461bcde11bd77e61e9048b0eaabbc12" alt="{\displaystyle D:\Omega \to [0,1]}" /></span>. In most applications,&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ef982b6520cd729ae492de79147fe021da519e94" alt="D" /></span>&nbsp;is a&nbsp;<a class="mw-redirect" title="Deep neural network" href="https://en.wikipedia.org/wiki/Deep_neural_network">deep neural network</a>&nbsp;function.</p>
<p>As for the generator, while&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>&nbsp;could theoretically be any computable probability distribution, in practice, it is usually implemented as a&nbsp;<a title="Pushforward measure" href="https://en.wikipedia.org/wiki/Pushforward_measure">pushforward</a>:&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��=��∘�&minus;1</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8ab37d81cd40b907ad6c73294e256fbb7b3d0daa" alt="{\displaystyle \mu _{G}=\mu _{Z}\circ G^{-1}}" /></span>. That is, start with a random variable&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&sim;��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d0bc23402cf269f4cb481c696feede26eb43acb7" alt="{\displaystyle z\sim \mu _{Z}}" /></span>, where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4dfd7b88be4d0e36a21cb6d4a486bcaf0128a324" alt="{\displaystyle \mu _{Z}}" /></span>&nbsp;is a probability distribution that is easy to compute (such as the&nbsp;<a title="Continuous uniform distribution" href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution">uniform distribution</a>, or the&nbsp;<a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">Gaussian distribution</a>), then define a function&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;�&rarr;&Omega;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/040cac2259b446fc3c032b683b8e7c9fb57aaea5" alt="{\displaystyle G:\Omega _{Z}\to \Omega }" /></span>. Then the distribution&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>&nbsp;is the distribution of&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e82b08ac9027d31c740345f2302cb7a68d5a0646" alt="G(z)" /></span>.</p>
<p>Consequently, the generator's strategy is usually defined as just&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5551faa0c67e2772a68ae24ecb0d828adb057a56" alt="G" /></span>, leaving&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&sim;��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d0bc23402cf269f4cb481c696feede26eb43acb7" alt="{\displaystyle z\sim \mu _{Z}}" /></span>&nbsp;implicit. In this formalism, the GAN game objective is</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(�,�):=��&sim;����[ln⁡�(�)]+��&sim;��[ln⁡(1&minus;�(�(�)))].</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b80920fa9a3607339cfd49d19ad8c0fdc80bf37c" alt="{\displaystyle L(G,D):=\mathbb {E} _{x\sim \mu _{ref}}[\ln D(x)]+\mathbb {E} _{z\sim \mu _{Z}}[\ln(1-D(G(z)))].}" /></div>
<p>&nbsp;</p>
<h3><span id="Generative_reparametrization" class="mw-headline">Generative reparametrization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Generative reparametrization" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=8">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The GAN architecture has two main components. One is casting optimization into a game, of form&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">min�max��(�,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e9563e238ceb863fb98c258aa56b16873cb30514" alt="{\displaystyle \min _{G}\max _{D}L(G,D)}" /></span>, which is different from the usual kind of optimization, of form&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">min��(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c4be030d0fbd7d7ccceb9d12b30e59f0a824327e" alt="{\displaystyle \min _{\theta }L(\theta )}" /></span>. The other is the decomposition of&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dda577f83b0f673b3c59652dfcd8c195b965030f" alt="{\displaystyle \mu _{G}}" /></span>&nbsp;into&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��∘�&minus;1</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/74f0b05f29a2e4abca5208276c4bf7d7b6e80ace" alt="{\displaystyle \mu _{Z}\circ G^{-1}}" /></span>, which can be understood as a reparametrization trick.</p>
<p>To see its significance, one must compare GAN with previous methods for learning generative models, which were plagued with "intractable probabilistic computations that arise in maximum likelihood estimation and related strategies".<sup id="cite_ref-GANnips_3-4" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup></p>
<p>At the same time, Kingma and Welling<sup id="cite_ref-13" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-13">[13]</a></sup>&nbsp;and Rezende et al.<sup id="cite_ref-14" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-14">[14]</a></sup>&nbsp;developed the same idea of reparametrization into a general stochastic backpropagation method. Among its first applications was the&nbsp;<a title="Variational autoencoder" href="https://en.wikipedia.org/wiki/Variational_autoencoder">variational autoencoder</a>.</p>
<h3><span id="Move_order_and_strategic_equilibria" class="mw-headline">Move order and strategic equilibria</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Move order and strategic equilibria" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=9">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In the original paper, as well as most subsequent papers, it is usually assumed that the generator&nbsp;<em>moves first</em>, and the discriminator&nbsp;<em>moves second</em>, thus giving the following minimax game:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">min��max���(��,��):=��&sim;����,�&sim;��(�)[ln⁡�]+��&sim;��,�&sim;��(�)[ln⁡(1&minus;�)].</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a649527e824cb68df0eefd7ab3c83aace18d0550" alt="{\displaystyle \min _{\mu _{G}}\max _{\mu _{D}}L(\mu _{G},\mu _{D}):=\mathbb {E} _{x\sim \mu _{ref},y\sim \mu _{D}(x)}[\ln y]+\mathbb {E} _{x\sim \mu _{G},y\sim \mu _{D}(x)}[\ln(1-y)].}" /></div>
<p>&nbsp;</p>
<p>If both the generator's and the discriminator's strategy sets are spanned by a finite number of strategies, then by the&nbsp;<a title="Minimax theorem" href="https://en.wikipedia.org/wiki/Minimax_theorem">minimax theorem</a>,</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">min��max���(��,��)=max��min���(��,��)</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/62ff1981dfa6b88c4280b870ad78a494b3a5f1c0" alt="{\displaystyle \min _{\mu _{G}}\max _{\mu _{D}}L(\mu _{G},\mu _{D})=\max _{\mu _{D}}\min _{\mu _{G}}L(\mu _{G},\mu _{D})}" /></div>
that is, the move order does not matter.
<p>&nbsp;</p>
<p>However, since the strategy sets are both not finitely spanned, the minimax theorem does not apply, and the idea of an "equilibrium" becomes delicate. To wit, there are the following different concepts of equilibrium:</p>
<ul>
<li>Equilibrium when generator moves first, and discriminator moves second:
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�^�&isin;arg⁡min��max���(��,��),�^�&isin;arg⁡max���(�^�,��),</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/aa056df879862edd13b98ba12bec9a613e52eb77" alt="{\displaystyle {\hat {\mu }}_{G}\in \arg \min _{\mu _{G}}\max _{\mu _{D}}L(\mu _{G},\mu _{D}),\quad {\hat {\mu }}_{D}\in \arg \max _{\mu _{D}}L({\hat {\mu }}_{G},\mu _{D}),\quad }" /></div>
</li>
<li>Equilibrium when discriminator moves first, and generator moves second:
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�^�&isin;arg⁡max��min���(��,��),�^�&isin;arg⁡min���(��,�^�),</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/08032237cedf412aacc7a95b5c69bea9de1b17d9" alt="{\displaystyle {\hat {\mu }}_{D}\in \arg \max _{\mu _{D}}\min _{\mu _{G}}L(\mu _{G},\mu _{D}),\quad {\hat {\mu }}_{G}\in \arg \min _{\mu _{G}}L(\mu _{G},{\hat {\mu }}_{D}),}" /></div>
</li>
<li><a title="Nash equilibrium" href="https://en.wikipedia.org/wiki/Nash_equilibrium">Nash equilibrium</a>&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(�^�,�^�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ac9ac97217a832bb60a5756d2e60f83e9fddf73e" alt="{\displaystyle ({\hat {\mu }}_{D},{\hat {\mu }}_{G})}" /></span>, which is stable under simultaneous move order:
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�^�&isin;arg⁡max���(�^�,��),�^�&isin;arg⁡min���(��,�^�)</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/29ff8bfcd5fc1f619a8526c325a0d9c44f0a9673" alt="{\displaystyle {\hat {\mu }}_{D}\in \arg \max _{\mu _{D}}L({\hat {\mu }}_{G},\mu _{D}),\quad {\hat {\mu }}_{G}\in \arg \min _{\mu _{G}}L(\mu _{G},{\hat {\mu }}_{D})}" /></div>
</li>
</ul>
<p>For general games, these equilibria do not have to agree, or even to exist. For the original GAN game, these equilibria all exist, and are all equal. However, for more general GAN games, these do not necessarily exist, or agree.<sup id="cite_ref-:2_15-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:2-15">[15]</a></sup></p>
<h3><span id="Main_theorems_for_GAN_game" class="mw-headline">Main theorems for GAN game</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Main theorems for GAN game" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=10">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The original GAN paper proved the following two theorems:<sup id="cite_ref-GANnips_3-5" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup></p>
<div class="math_theorem">
<p><strong class="theorem-name">Theorem</strong>&nbsp;<span class="theorem-note">(the optimal discriminator computes the Jensen&ndash;Shannon divergence)</span><span class="theoreme-tiret">&nbsp;&mdash;&nbsp;</span>For any fixed generator strategy&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>, let the optimal reply be&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&lowast;=arg⁡max��(��,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f2cfb932c958232bd3c37ee1b8adf287157b6aed" alt="{\displaystyle D^{*}=\arg \max _{D}L(\mu _{G},D)}" /></span>, then</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�&lowast;(�)=������(����+��)�(��,�&lowast;)=2���(����;��)&minus;2ln⁡2</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bc2e56289a7b7f867e47e20b764cb7b6ac0c9c2a" alt="{\displaystyle {\begin{aligned}D^{*}(x)&amp;={\frac {d\mu _{ref}}{d(\mu _{ref}+\mu _{G})}}\\L(\mu _{G},D^{*})&amp;=2D_{JS}(\mu _{ref};\mu _{G})-2\ln 2\end{aligned}}}" /></div>
<p>&nbsp;</p>
<p>where the derivative is the&nbsp;<a class="mw-redirect" title="Radon&ndash;Nikodym derivative" href="https://en.wikipedia.org/wiki/Radon%E2%80%93Nikodym_derivative">Radon&ndash;Nikodym derivative</a>, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">���</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3ac9a4b47b552666c5597114ce9d57e81e5d627a" alt="{\displaystyle D_{JS}}" /></span>&nbsp;is the&nbsp;<a title="Jensen&ndash;Shannon divergence" href="https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence">Jensen&ndash;Shannon divergence</a>.</p>
</div>
<div class="math_proof"><strong>Proof</strong>
<p>By Jensen's inequality,</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">��&sim;����,�&sim;��(�)[ln⁡�]&le;��&sim;����[ln⁡��&sim;��(�)[�]]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/31e886807b731e9a4b642171490fbb6270173038" alt="{\displaystyle \mathbb {E} _{x\sim \mu _{ref},y\sim \mu _{D}(x)}[\ln y]\leq \mathbb {E} _{x\sim \mu _{ref}}[\ln \mathbb {E} _{y\sim \mu _{D}(x)}[y]]}" /></div>
and similarly for the other term. Therefore, the optimal reply can be deterministic, i.e.&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��(�)=��(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e7abeefe38a8088fa2f56360c90b005c9ac6d8d0" alt="{\displaystyle \mu _{D}(x)=\delta _{D(x)}}" /></span>&nbsp;for some function&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;&rarr;[0,1]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/298d9bf50461bcde11bd77e61e9048b0eaabbc12" alt="{\displaystyle D:\Omega \to [0,1]}" /></span>, in which case
<p>&nbsp;</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(��,��):=��&sim;����[ln⁡�(�)]+��&sim;��[ln⁡(1&minus;�(�))].</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/57034e7142a53b2db126deeeb9e38eb12b29ef5a" alt="{\displaystyle L(\mu _{G},\mu _{D}):=\mathbb {E} _{x\sim \mu _{ref}}[\ln D(x)]+\mathbb {E} _{x\sim \mu _{G}}[\ln(1-D(x))].}" /></div>
<p>&nbsp;</p>
<p>To define suitable density functions, we define a base measure&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:=����+��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6c3ecb403f89e8ad90170fba236d99388af17bde" alt="{\displaystyle \mu :=\mu _{ref}+\mu _{G}}" /></span>, which allows us to take the Radon&ndash;Nikodym derivatives</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">����=���������=�����</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ea51976d99cfb22e6983cecc8f7ee4bb8afc7ba1" alt="{\displaystyle \rho _{ref}={\frac {d\mu _{ref}}{d\mu }}\quad \rho _{G}={\frac {d\mu _{G}}{d\mu }}}" /></div>
with&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����+��=1</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7c85def31b5207b71d715ed5d2b8e1516cbd19cc" alt="{\displaystyle \rho _{ref}+\rho _{G}=1}" /></span>.
<p>&nbsp;</p>
<p>We then have</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(��,��):=&int;�(��)[����(�)ln⁡(�(�))+��(�)ln⁡(1&minus;�(�))].</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fde5f0d6dabafb2e5229d7c83a358cd3cf2bf2cf" alt="{\displaystyle L(\mu _{G},\mu _{D}):=\int \mu (dx)\left[\rho _{ref}(x)\ln(D(x))+\rho _{G}(x)\ln(1-D(x))\right].}" /></div>
<p>&nbsp;</p>
<p>The integrand is just the negative&nbsp;<a class="mw-redirect" title="Cross-entropy" href="https://en.wikipedia.org/wiki/Cross-entropy">cross-entropy</a>&nbsp;between two Bernoulli random variables with parameters&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/60e53880c74e3bcbaba5f523981e8331aa288f7f" alt="{\displaystyle \rho _{ref}(x)}" /></span>&nbsp;and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a85880c6af2d5092c8ac431fa65b9a4602cd1b24" alt="D(x)" /></span>. We can write this as&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&minus;�(����(�))&minus;���(����(�)‖�(�))</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/44c23bb9e8e7fab26943573a5aaf1b86b23a9f91" alt="{\displaystyle -H(\rho _{ref}(x))-D_{KL}(\rho _{ref}(x)\|D(x))}" /></span>, where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b6efa35838a1b87f98b48ff8f2006b5e200432cf" alt="H" /></span>&nbsp;is the&nbsp;<a title="Binary entropy function" href="https://en.wikipedia.org/wiki/Binary_entropy_function">binary entropy function</a>, so</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(��,��)=&minus;&int;�(��)(�(����(�))+���(����(�)‖�(�))).</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/17de577c3794e908bb271f51ef0f8cf3131c1945" alt="{\displaystyle L(\mu _{G},\mu _{D})=-\int \mu (dx)(H(\rho _{ref}(x))+D_{KL}(\rho _{ref}(x)\|D(x))).}" /></div>
<p>&nbsp;</p>
<p>This means that the optimal strategy for the discriminator is&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�)=����(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/59a94b42353ca349dcace83678e26f29c4adc72d" alt="{\displaystyle D(x)=\rho _{ref}(x)}" /></span>, with</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(��,��&lowast;)=&minus;&int;�(��)�(����(�))=���(����‖��)&minus;2ln⁡2</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/49a99b1ec87c8d49d75e80ccdf0191f073e5c46f" alt="{\displaystyle L(\mu _{G},\mu _{D}^{*})=-\int \mu (dx)H(\rho _{ref}(x))=D_{JS}(\mu _{ref}\|\mu _{G})-2\ln 2}" /></div>
<p>&nbsp;</p>
<p>after routine calculation.</p>
</div>
<p><strong>Interpretation</strong>: For any fixed generator strategy&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>, the optimal discriminator keeps track of the likelihood ratio between the reference distribution and the generator distribution:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(�)1&minus;�(�)=��������(�)=����(��)��(��);�(�)=�(ln⁡����(��)&minus;ln⁡��(��))</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/51683d797e2fef48d15dc515c20d306373955fdc" alt="{\displaystyle {\frac {D(x)}{1-D(x)}}={\frac {d\mu _{ref}}{d\mu _{G}}}(x)={\frac {\mu _{ref}(dx)}{\mu _{G}(dx)}};\quad D(x)=\sigma (\ln \mu _{ref}(dx)-\ln \mu _{G}(dx))}" /></div>
where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ad27903377f2074c04cbcd5dec23f910b21688c1" alt="\sigma " /></span>&nbsp;is the&nbsp;<a title="Logistic function" href="https://en.wikipedia.org/wiki/Logistic_function">logistic function</a>. In particular, if the prior probability for an image&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e315c1e498e50190b9be0e8ad82a80be836c89f" alt="x" /></span>&nbsp;to come from the reference distribution is equal to&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">12</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/294aa706548adbc7778fb15bf5616abc4d9ad7be" alt="{\frac  12}" /></span>, then&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a85880c6af2d5092c8ac431fa65b9a4602cd1b24" alt="D(x)" /></span>&nbsp;is just the posterior probability that&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e315c1e498e50190b9be0e8ad82a80be836c89f" alt="x" /></span>&nbsp;came from the reference distribution:
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(�)=��(�&nbsp;came from reference distribution|�).</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4a8b8b9474bb7ca4f7b431b41ec72b9dc2676312" alt="{\displaystyle D(x)=Pr(x{\text{ came from reference distribution}}|x).}" /></div>
<p>&nbsp;</p>
<div class="math_theorem">
<p><strong class="theorem-name">Theorem</strong>&nbsp;<span class="theorem-note">(the unique equilibrium point)</span><span class="theoreme-tiret">&nbsp;&mdash;&nbsp;</span>For any GAN game, there exists a pair&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(�^�,�^�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ac9ac97217a832bb60a5756d2e60f83e9fddf73e" alt="{\displaystyle ({\hat {\mu }}_{D},{\hat {\mu }}_{G})}" /></span>&nbsp;that is both a sequential equilibrium and a Nash equilibrium:</p>
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�^�,�^�)=min��max���(��,��)=max��min���(��,��)=&minus;2ln⁡2�^�&isin;arg⁡max��min���(��,��),�^�&isin;arg⁡min��max���(��,��)�^�&isin;arg⁡max���(�^�,��),�^�&isin;arg⁡min���(��,�^�)&forall;�&isin;&Omega;,�^�(�)=�12,�^�=����</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4d942a93b27e8756bd086b75761668b2e354b90e" alt="{\displaystyle {\begin{aligned}L({\hat {\mu }}_{G},{\hat {\mu }}_{D})=\min _{\mu _{G}}\max _{\mu _{D}}L(\mu _{G},\mu _{D})=&amp;\max _{\mu _{D}}\min _{\mu _{G}}L(\mu _{G},\mu _{D})=-2\ln 2\\{\hat {\mu }}_{D}\in \arg \max _{\mu _{D}}\min _{\mu _{G}}L(\mu _{G},\mu _{D}),&amp;\quad {\hat {\mu }}_{G}\in \arg \min _{\mu _{G}}\max _{\mu _{D}}L(\mu _{G},\mu _{D})\\{\hat {\mu }}_{D}\in \arg \max _{\mu _{D}}L({\hat {\mu }}_{G},\mu _{D}),&amp;\quad {\hat {\mu }}_{G}\in \arg \min _{\mu _{G}}L(\mu _{G},{\hat {\mu }}_{D})\\\forall x\in \Omega ,{\hat {\mu }}_{D}(x)=\delta _{\frac {1}{2}},&amp;\quad {\hat {\mu }}_{G}=\mu _{ref}\end{aligned}}}" /></span></p>
<p>That is, the generator perfectly mimics the reference, and the discriminator outputs&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">12</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/294aa706548adbc7778fb15bf5616abc4d9ad7be" alt="{\frac  12}" /></span>&nbsp;deterministically on all inputs.</p>
</div>
<div class="math_proof"><strong>Proof</strong>
<p>From the previous proposition,</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">arg⁡min��max���(��,��)=����;min��max���(��,��)=&minus;2ln⁡2.</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5476c4f054d5baa02f0efb7f1d577283d2d8c1b2" alt="{\displaystyle \arg \min _{\mu _{G}}\max _{\mu _{D}}L(\mu _{G},\mu _{D})=\mu _{ref};\quad \min _{\mu _{G}}\max _{\mu _{D}}L(\mu _{G},\mu _{D})=-2\ln 2.}" /></div>
<p>&nbsp;</p>
<p>For any fixed discriminator strategy&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/aea0f1037b8ef749163f76b37879e2603927e1ec" alt="\mu _{D}" /></span>, any&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>&nbsp;concentrated on the set</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">{�|��&sim;��(�)[ln⁡(1&minus;�)]=inf���&sim;��(�)[ln⁡(1&minus;�)]}</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d9d620c0a45064347c4f08943a9a0bf648a363f8" alt="{\displaystyle \{x|\mathbb {E} _{y\sim \mu _{D}(x)}[\ln(1-y)]=\inf _{x}\mathbb {E} _{y\sim \mu _{D}(x)}[\ln(1-y)]\}}" /></div>
is an optimal strategy for the generator. Thus,
<p>&nbsp;</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">arg⁡max��min���(��,��)=arg⁡max����&sim;����,�&sim;��(�)[ln⁡�]+inf���&sim;��(�)[ln⁡(1&minus;�)].</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7701f71008167657766c5e4a33ec6440f686ef83" alt="{\displaystyle \arg \max _{\mu _{D}}\min _{\mu _{G}}L(\mu _{G},\mu _{D})=\arg \max _{\mu _{D}}\mathbb {E} _{x\sim \mu _{ref},y\sim \mu _{D}(x)}[\ln y]+\inf _{x}\mathbb {E} _{y\sim \mu _{D}(x)}[\ln(1-y)].}" /></div>
<p>&nbsp;</p>
<p>By Jensen's inequality, the discriminator can only improve by adopting the deterministic strategy of always playing&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�)=��&sim;��(�)[�]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/62b34fdf229109bdb32719d1987b3c18e9f88623" alt="{\displaystyle D(x)=\mathbb {E} _{y\sim \mu _{D}(x)}[y]}" /></span>. Therefore,</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">arg⁡max��min���(��,��)=arg⁡max���&sim;����[ln⁡�(�)]+inf�ln⁡(1&minus;�(�))</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9f7e4eb5a68ce879d600329e8596a119fe723de1" alt="{\displaystyle \arg \max _{\mu _{D}}\min _{\mu _{G}}L(\mu _{G},\mu _{D})=\arg \max _{D}\mathbb {E} _{x\sim \mu _{ref}}[\ln D(x)]+\inf _{x}\ln(1-D(x))}" /></div>
<p>&nbsp;</p>
<p>By Jensen's inequality,</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">ln⁡��&sim;����[�(�)]+inf�ln⁡(1&minus;�(�))=ln⁡��&sim;����[�(�)]+ln⁡(1&minus;sup��(�))=ln⁡[��&sim;����[�(�)](1&minus;sup��(�))]&le;ln⁡[sup��(�))(1&minus;sup��(�))]&le;ln⁡14,</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d2fd9f562288fbdfda2367c3ab5c33edefd16806" alt="{\displaystyle \ln \mathbb {E} _{x\sim \mu _{ref}}[D(x)]+\inf _{x}\ln(1-D(x))=\ln \mathbb {E} _{x\sim \mu _{ref}}[D(x)]+\ln(1-\sup _{x}D(x))=\ln[\mathbb {E} _{x\sim \mu _{ref}}[D(x)](1-\sup _{x}D(x))]\leq \ln[\sup _{x}D(x))(1-\sup _{x}D(x))]\leq \ln {\frac {1}{4}},}" /></div>
<p>&nbsp;</p>
<p>with equality if&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�)=12</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0b973611b59fecbac4f096cae1a652716edb8133" alt="{\displaystyle D(x)={\frac {1}{2}}}" /></span>, so</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">&forall;�&isin;&Omega;,�^�(�)=�12;max��min���(��,��)=&minus;2ln⁡2.</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8f2daa485f652357ef90393d0a20fbea122e6842" alt="{\displaystyle \forall x\in \Omega ,{\hat {\mu }}_{D}(x)=\delta _{\frac {1}{2}};\quad \max _{\mu _{D}}\min _{\mu _{G}}L(\mu _{G},\mu _{D})=-2\ln 2.}" /></div>
<p>&nbsp;</p>
<p>Finally, to check that this is a Nash equilibrium, note that when&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��=����</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f9e8ac3e626ed16df9083a96e69f53366d30d1b7" alt="{\displaystyle \mu _{G}=\mu _{ref}}" /></span>, we have</p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(��,��):=��&sim;����,�&sim;��(�)[ln⁡(�(1&minus;�))]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b2ac15894f8e8cf1d86f5c692c25f62bdcb1f98" alt="{\displaystyle L(\mu _{G},\mu _{D}):=\mathbb {E} _{x\sim \mu _{ref},y\sim \mu _{D}(x)}[\ln(y(1-y))]}" /></div>
which is always maximized by&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�=12</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/52dc902fc1d3a9d6137bfe986703bb9a2a99cffd" alt="{\displaystyle y={\frac {1}{2}}}" /></span>.
<p>&nbsp;</p>
<p>When&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&forall;�&isin;&Omega;,��(�)=�12</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7ecabdb51eb106d620377f80b5680dcb9fb7d042" alt="{\displaystyle \forall x\in \Omega ,\mu _{D}(x)=\delta _{\frac {1}{2}}}" /></span>, any strategy is optimal for the generator.</p>
</div>
<h2><span id="Training_and_evaluating_GAN" class="mw-headline">Training and evaluating GAN</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Training and evaluating GAN" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=11">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span id="Training" class="mw-headline">Training</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Training" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=12">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<h4><span id="Unstable_convergence" class="mw-headline">Unstable convergence</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Unstable convergence" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=13">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>While the GAN game has a unique global equilibrium point when both the generator and discriminator have access to their entire strategy sets, the equilibrium is no longer guaranteed when they have a restricted strategy set.<sup id="cite_ref-:2_15-1" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:2-15">[15]</a></sup></p>
<p>In practice, the generator has access only to measures of form&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��∘��&minus;1</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f04987cbb022c086a8f3196e1236616e9d692de9" alt="{\displaystyle \mu _{Z}\circ G_{\theta }^{-1}}" /></span>, where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19730cfa60610fa988f2ac0ef94de6fefa8daded" alt="G_{\theta }" /></span>&nbsp;is a function computed by a neural network with parameters&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/528115c670a13eca2cc38e7c5ae283edd1026b06" alt="\theta " /></span>, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4dfd7b88be4d0e36a21cb6d4a486bcaf0128a324" alt="{\displaystyle \mu _{Z}}" /></span>&nbsp;is an easily sampled distribution, such as the uniform or normal distribution. Similarly, the discriminator has access only to functions of form&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/eb2221422911a45f6c56c65806becf8a76d46f96" alt="{\displaystyle D_{\zeta }}" /></span>, a function computed by a neural network with parameters&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2660ec7e36bacc91720a5f18d09f7f185de04cda" alt="\zeta " /></span>. These restricted strategy sets take up a&nbsp;<em>vanishingly small proportion</em>&nbsp;of their entire strategy sets.<sup id="cite_ref-:3_16-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:3-16">[16]</a></sup></p>
<p>Further, even if an equilibrium still exists, it can only be found by searching in the high-dimensional space of all possible neural network functions. The standard strategy of using&nbsp;<a title="Gradient descent" href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>&nbsp;to find the equilibrium often does not work for GAN, and often the game "collapses" into one of several failure modes. To improve the convergence stability, some training strategies start with an easier task, such as generating low-resolution images<sup id="cite_ref-:1_17-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:1-17">[17]</a></sup>&nbsp;or simple images (one object with uniform background),<sup id="cite_ref-18" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-18">[18]</a></sup>&nbsp;and gradually increase the difficulty of the task during training. This essentially translates to applying a curriculum learning scheme.<sup id="cite_ref-19" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-19">[19]</a></sup></p>
<h4><span id="Mode_collapse" class="mw-headline">Mode collapse</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Mode collapse" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=14">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>GANs often suffer from&nbsp;<strong>mode collapse</strong>&nbsp;where they fail to generalize properly, missing entire modes from the input data. For example, a GAN trained on the&nbsp;<a class="mw-redirect" title="MNIST" href="https://en.wikipedia.org/wiki/MNIST">MNIST</a>&nbsp;dataset containing many samples of each digit might only generate pictures of digit 0. This was named in the first paper as the "<a title="Look Around You" href="https://en.wikipedia.org/wiki/Look_Around_You">Helvetica scenario</a>".</p>
<p>One way this can happen is if the generator learns too fast compared to the discriminator. If the discriminator&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ef982b6520cd729ae492de79147fe021da519e94" alt="D" /></span>&nbsp;is held constant, then the optimal generator would only output elements of&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">arg⁡max��(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d56a433ff074c3da94bfe4a11ec51be0b22cc743" alt="{\displaystyle \arg \max _{x}D(x)}" /></span>.<sup id="cite_ref-20" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-20">[20]</a></sup>&nbsp;So for example, if during GAN training for generating MNIST dataset, for a few epochs, the discriminator somehow prefers the digit 0 slightly more than other digits, the generator may seize the opportunity to generate only digit 0, then be unable to escape the local minimum after the discriminator improves.</p>
<p>Some researchers perceive the root problem to be a weak discriminative network that fails to notice the pattern of omission, while others assign blame to a bad choice of&nbsp;<a class="mw-redirect" title="Objective function" href="https://en.wikipedia.org/wiki/Objective_function">objective function</a>. Many solutions have been proposed, but it is still an open problem.<sup id="cite_ref-21" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-21">[21]</a></sup><sup id="cite_ref-22" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-22">[22]</a></sup></p>
<p>Even the state-of-the-art architecture, BigGAN (2019), could not avoid mode collapse. The authors resorted to "allowing collapse to occur at the later stages of training, by which time a model is sufficiently trained to achieve good results".<sup id="cite_ref-:0_23-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:0-23">[23]</a></sup></p>
<h4><span id="Two_time-scale_update_rule" class="mw-headline">Two time-scale update rule</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Two time-scale update rule" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=15">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The&nbsp;<strong>two time-scale update rule (TTUR)</strong>&nbsp;is proposed to make GAN convergence more stable by making the learning rate of the generator lower than that of the discriminator. The authors argued that the generator should move slower than the discriminator, so that it does not "drive the discriminator steadily into new regions without capturing its gathered information".</p>
<p>They proved that a general class of games that included the GAN game, when trained under TTUR, "converges under mild assumptions to a stationary local Nash equilibrium".<sup id="cite_ref-24" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-24">[24]</a></sup></p>
<p>They also proposed using the&nbsp;<a title="Stochastic optimization" href="https://en.wikipedia.org/wiki/Stochastic_optimization">Adam stochastic optimization</a><sup id="cite_ref-25" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-25">[25]</a></sup>&nbsp;to avoid mode collapse, as well as the&nbsp;<a title="Fr&eacute;chet inception distance" href="https://en.wikipedia.org/wiki/Fr%C3%A9chet_inception_distance">Fr&eacute;chet inception distance</a>&nbsp;for evaluating GAN performances.</p>
<h4><span id="Vanishing_gradient" class="mw-headline">Vanishing gradient</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Vanishing gradient" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=16">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Conversely, if the discriminator learns too fast compared to the generator, then the discriminator could almost perfectly distinguish&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">���,����</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1c218f5228e8f892e1bebb0b1860d64b466b24d6" alt="{\displaystyle \mu _{G_{\theta }},\mu _{ref}}" /></span>. In such case, the generator&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19730cfa60610fa988f2ac0ef94de6fefa8daded" alt="G_{\theta }" /></span>&nbsp;could be stuck with a very high loss no matter which direction it changes its&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/528115c670a13eca2cc38e7c5ae283edd1026b06" alt="\theta " /></span>, meaning that the gradient&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&nabla;��(��,��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f352a89b55badf2662e56a7531565f7452692664" alt="{\displaystyle \nabla _{\theta }L(G_{\theta },D_{\zeta })}" /></span>&nbsp;would be close to zero. In such case, the generator cannot learn, a case of the&nbsp;<a title="Vanishing gradient problem" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem"><strong>vanishing gradient</strong>&nbsp;problem</a>.<sup id="cite_ref-:3_16-1" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:3-16">[16]</a></sup></p>
<p>Intuitively speaking, the discriminator is too good, and since the generator cannot take any small step (only small steps are considered in gradient descent) to improve its payoff, it does not even try.</p>
<p>One important method for solving this problem is the&nbsp;<a title="Wasserstein GAN" href="https://en.wikipedia.org/wiki/Wasserstein_GAN">Wasserstein GAN</a>.</p>
<h3><span id="Evaluation" class="mw-headline">Evaluation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Evaluation" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=17">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>GANs are usually evaluated by&nbsp;<a title="Inception score" href="https://en.wikipedia.org/wiki/Inception_score">Inception score</a>&nbsp;(IS), which measures how varied the generator's outputs are (as classified by an image classifier, usually&nbsp;<a title="Inceptionv3" href="https://en.wikipedia.org/wiki/Inceptionv3">Inception-v3</a>), or&nbsp;<a title="Fr&eacute;chet inception distance" href="https://en.wikipedia.org/wiki/Fr%C3%A9chet_inception_distance">Fr&eacute;chet inception distance</a>&nbsp;(FID), which measures how similar the generator's outputs are to a reference set (as classified by a learned image featurizer, such as Inception-v3 without its final layer). Many papers that propose new GAN architectures for image generation report how their architectures break the&nbsp;<a title="State of the art" href="https://en.wikipedia.org/wiki/State_of_the_art">state of the art</a>&nbsp;on FID or IS.</p>
<p>Another evaluation method is the Learned Perceptual Image Patch Similarity (LPIPS), which starts with a learned image featurizer&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��:Image&rarr;��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cb99bc553ef0aa2f8dfc0840c92373e0edce560f" alt="{\displaystyle f_{\theta }:{\text{Image}}\to \mathbb {R} ^{n}}" /></span>, and finetunes it by supervised learning on a set of&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(�,�&prime;,PerceptualDifference(�,�&prime;))</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/98118454e3529d5335b5877d15b9e59cedc3610f" alt="{\displaystyle (x,x',{\text{PerceptualDifference}}(x,x'))}" /></span>, where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e315c1e498e50190b9be0e8ad82a80be836c89f" alt="x" /></span>&nbsp;is an image,&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ad671ae6006c25f9d6a79e14a920a65fd85e0ed3" alt="x'" /></span>&nbsp;is a perturbed version of it, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">PerceptualDifference(�,�&prime;)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/aa693c510a8dd47ce79944993cf021bedca288cb" alt="{\displaystyle {\text{PerceptualDifference}}(x,x')}" /></span>&nbsp;is how much they differ, as reported by human subjects. The model is finetuned so that it can approximate&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">‖��(�)&minus;��(�&prime;)‖&asymp;PerceptualDifference(�,�&prime;)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/eb23d78ca33f4fee4c62d9e073efe0887a391ca3" alt="{\displaystyle \|f_{\theta }(x)-f_{\theta }(x')\|\approx {\text{PerceptualDifference}}(x,x')}" /></span>. This finetuned model is then used to define&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">LPIPS(�,�&prime;):=‖��(�)&minus;��(�&prime;)‖</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/763dbfac661d87afa955394f79500075882c6d17" alt="{\displaystyle {\text{LPIPS}}(x,x'):=\|f_{\theta }(x)-f_{\theta }(x')\|}" /></span>.<sup id="cite_ref-26" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-26">[26]</a></sup></p>
<p>Other evaluation methods are reviewed in.<sup id="cite_ref-27" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-27">[27]</a></sup></p>
<h2><span id="Variants" class="mw-headline">Variants</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Variants" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=18">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>There is a veritable zoo of GAN variants.<sup id="cite_ref-28" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-28">[28]</a></sup>&nbsp;Some of the most prominent are as follows:</p>
<h3><span id="Conditional_GAN" class="mw-headline">Conditional GAN</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Conditional GAN" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=19">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Conditional GANs are similar to standard GANs except they allow the model to conditionally generate samples based on additional information. For example, if we want to generate a cat face given a dog picture, we could use a conditional GAN.</p>
<p>The generator in a GAN game generates&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a278f484a0f833cfe1a1d2a61d4176bf988b85c4" alt="\mu_G" /></span>, a probability distribution on the probability space&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d80b0b33ae50a23bfe35d912fb6d780bf6e9f135" alt="\Omega " /></span>. This leads to the idea of a conditional GAN, where instead of generating one probability distribution on&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d80b0b33ae50a23bfe35d912fb6d780bf6e9f135" alt="\Omega " /></span>, the generator generates a different probability distribution&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b960f83a5f34c2a10b58c498524e99db56b3dc01" alt="{\displaystyle \mu _{G}(c)}" /></span>&nbsp;on&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d80b0b33ae50a23bfe35d912fb6d780bf6e9f135" alt="\Omega " /></span>, for each given class label&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7422142036966592529a097f042da841a2c9b51" alt="c" /></span>.</p>
<p>For example, for generating images that look like&nbsp;<a title="ImageNet" href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a>, the generator should be able to generate a picture of cat when given the class label "cat".</p>
<p>In the original paper,<sup id="cite_ref-GANnips_3-6" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup>&nbsp;the authors noted that GAN can be trivially extended to conditional GAN by providing the labels to both the generator and the discriminator.</p>
<p>Concretely, the conditional GAN game is just the GAN game with class labels provided:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(��,�):=��&sim;��,�&sim;����(�)[ln⁡�(�,�)]+��&sim;��,�&sim;��(�)[ln⁡(1&minus;�(�,�))]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/018470e5b806a4bf28807f54fce87edded361685" alt="{\displaystyle L(\mu _{G},D):=\mathbb {E} _{c\sim \mu _{C},x\sim \mu _{ref}(c)}[\ln D(x,c)]+\mathbb {E} _{c\sim \mu _{C},x\sim \mu _{G}(c)}[\ln(1-D(x,c))]}" /></div>
where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e209b251e74e94609cb3b5029d7223f95367c6cd" alt="{\displaystyle \mu _{C}}" /></span>&nbsp;is a probability distribution over classes,&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cc0f279d0ebef01d9d78eaf5a691b45d83f4cc66" alt="{\displaystyle \mu _{ref}(c)}" /></span>&nbsp;is the probability distribution of real images of class&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7422142036966592529a097f042da841a2c9b51" alt="c" /></span>, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b960f83a5f34c2a10b58c498524e99db56b3dc01" alt="{\displaystyle \mu _{G}(c)}" /></span>&nbsp;the probability distribution of images generated by the generator when given class label&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7422142036966592529a097f042da841a2c9b51" alt="c" /></span>.
<p>&nbsp;</p>
<p>In 2017, a conditional GAN learned to generate 1000 image classes of&nbsp;<a title="ImageNet" href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a>.<sup id="cite_ref-29" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-29">[29]</a></sup></p>
<h3><span id="GANs_with_alternative_architectures" class="mw-headline">GANs with alternative architectures</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: GANs with alternative architectures" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=20">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The GAN game is a general framework and can be run with any reasonable parametrization of the generator&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5551faa0c67e2772a68ae24ecb0d828adb057a56" alt="G" /></span>&nbsp;and discriminator&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ef982b6520cd729ae492de79147fe021da519e94" alt="D" /></span>. In the original paper, the authors demonstrated it using&nbsp;<a title="Multilayer perceptron" href="https://en.wikipedia.org/wiki/Multilayer_perceptron">multilayer perceptron</a>&nbsp;networks and&nbsp;<a title="Convolutional neural network" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a>. Many alternative architectures have been tried.</p>
<p><strong>Deep convolutional GAN (DCGAN):</strong><sup id="cite_ref-30" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-30">[30]</a></sup>&nbsp;For both generator and discriminator, uses only deep networks consisting entirely of convolution-deconvolution layers, that is, fully convolutional networks.<sup id="cite_ref-31" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-31">[31]</a></sup></p>
<p><strong>Self-attention GAN (SAGAN):</strong><sup id="cite_ref-32" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-32">[32]</a></sup>&nbsp;Starts with the DCGAN, then adds residually-connected standard&nbsp;<a class="mw-redirect" title="Attention mechanism" href="https://en.wikipedia.org/wiki/Attention_mechanism">self-attention modules</a>&nbsp;to the generator and discriminator.</p>
<p><strong>Variational autoencoder GAN (VAEGAN):<sup id="cite_ref-33" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-33">[33]</a></sup></strong>&nbsp;Uses a&nbsp;<a title="Variational autoencoder" href="https://en.wikipedia.org/wiki/Variational_autoencoder">variational autoencoder</a>&nbsp;(VAE) for the generator.</p>
<p><strong>Transformer GAN (TransGAN):</strong><sup id="cite_ref-34" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-34">[34]</a></sup>&nbsp;Uses the pure&nbsp;<a title="Transformer (machine learning model)" href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">transformer</a>&nbsp;architecture for both the generator and discriminator, entirely devoid of convolution-deconvolution layers.</p>
<p><strong>Flow-GAN:</strong><sup id="cite_ref-35" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-35">[35]</a></sup>&nbsp;Uses&nbsp;<a title="Flow-based generative model" href="https://en.wikipedia.org/wiki/Flow-based_generative_model">flow-based generative model</a>&nbsp;for the generator, allowing efficient computation of the likelihood function.</p>
<h3><span id="GANs_with_alternative_objectives" class="mw-headline">GANs with alternative objectives</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: GANs with alternative objectives" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=21">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Many GAN variants are merely obtained by changing the loss functions for the generator and discriminator.</p>
<p><strong>Original GAN:</strong></p>
<p>We recast the original GAN objective into a form more convenient for comparison:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">{min���(�,��)=&minus;��&sim;��[ln⁡�(�)]&minus;��&sim;����[ln⁡(1&minus;�(�))]min���(�,��)=&minus;��&sim;��[ln⁡(1&minus;�(�))]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8d63f87002c359c49e4129001d24f1cbe72bb9af" alt="{\displaystyle {\begin{cases}\min _{D}L_{D}(D,\mu _{G})=-\mathbb {E} _{x\sim \mu _{G}}[\ln D(x)]-\mathbb {E} _{x\sim \mu _{ref}}[\ln(1-D(x))]\\\min _{G}L_{G}(D,\mu _{G})=-\mathbb {E} _{x\sim \mu _{G}}[\ln(1-D(x))]\end{cases}}}" /></div>
<p>&nbsp;</p>
<p><strong>Original GAN, non-saturating loss:</strong></p>
<p>This objective for generator was recommended in the original paper for faster convergence.<sup id="cite_ref-GANnips_3-7" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup></p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">��=��&sim;��[ln⁡�(�)]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0fa507c647c2e473c5ae1e9ff8324d3e5678a3a5" alt="{\displaystyle L_{G}=\mathbb {E} _{x\sim \mu _{G}}[\ln D(x)]}" /></div>
The effect of using this objective is analyzed in Section 2.2.2 of Arjovsky et al.<sup id="cite_ref-36" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-36">[36]</a></sup>
<p>&nbsp;</p>
<p><strong>Original GAN, maximum likelihood:</strong></p>
<p>&nbsp;</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">��=��&sim;��[(exp∘�&minus;1∘�)(�)]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5802ca7fcd3acb4138f4af911f531a866faf7940" alt="{\displaystyle L_{G}=\mathbb {E} _{x\sim \mu _{G}}[(\exp \circ \sigma ^{-1}\circ D)(x)]}" /></div>
where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ad27903377f2074c04cbcd5dec23f910b21688c1" alt="\sigma " /></span>&nbsp;is the logistic function. When the discriminator is optimal, the generator gradient is the same as in&nbsp;<a title="Maximum likelihood estimation" href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood estimation</a>, even though GAN cannot perform maximum likelihood estimation&nbsp;<em>itself</em>.<sup id="cite_ref-37" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-37">[37]</a></sup><sup id="cite_ref-38" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-38">[38]</a></sup>
<p>&nbsp;</p>
<p><strong><a title="Hinge loss" href="https://en.wikipedia.org/wiki/Hinge_loss">Hinge loss</a>&nbsp;GAN</strong>:<sup id="cite_ref-39" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-39">[39]</a></sup></p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">��=&minus;��&sim;����[min(0,&minus;1+�(�))]&minus;��&sim;��[min(0,&minus;1&minus;�(�))]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c0644f1bfb3c7ff9b835fce995c5723ad217bb61" alt="{\displaystyle L_{D}=-\mathbb {E} _{x\sim {p}_{ref}}\left[\min \left(0,-1+D\left(x\right)\right)\right]-\mathbb {E} _{x\sim \mu _{G}}\left[\min \left(0,-1-D\left(x\right)\right)\right]}" /></div>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">��=&minus;��&sim;��[�(�)]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cdd4d471bcff109ba9a253528b4af9973808163b" alt="{\displaystyle L_{G}=-\mathbb {E} _{x\sim \mu _{G}}[D\left(x\right)]}" /></div>
<strong>Least squares GAN:</strong><sup id="cite_ref-40" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-40">[40]</a></sup>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">��=��&sim;����[(�(�)&minus;�)2]+��&sim;��[(�(�)&minus;�)2]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1ce29c337072014c7420aa16f98132dea66dd19d" alt="{\displaystyle L_{D}=\mathbb {E} _{x\sim \mu _{ref}}[(D(x)-b)^{2}]+\mathbb {E} _{x\sim \mu _{G}}[(D(x)-a)^{2}]}" /></div>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">��=��&sim;��[(�(�)&minus;�)2]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b17a43360234d70453ba840b08962a96eece249a" alt="{\displaystyle L_{G}=\mathbb {E} _{x\sim \mu _{G}}[(D(x)-c)^{2}]}" /></div>
where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�,�,�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8286cd13135c21adbdeb8cd89c36072e08a843c" alt="a,b,c" /></span>&nbsp;are parameters to be chosen. The authors recommended&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�=&minus;1,�=1,�=0</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/022e02b39b357be43951bf0a9a446b54e3b2f42e" alt="{\displaystyle a=-1,b=1,c=0}" /></span>.
<p>&nbsp;</p>
<h3><span id="Wasserstein_GAN_.28WGAN.29"></span><span id="Wasserstein_GAN_(WGAN)" class="mw-headline">Wasserstein GAN (WGAN)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Wasserstein GAN (WGAN)" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=22">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="hatnote navigation-not-searchable">Main article:&nbsp;<a title="Wasserstein GAN" href="https://en.wikipedia.org/wiki/Wasserstein_GAN">Wasserstein GAN</a></div>
<p>The Wasserstein GAN modifies the GAN game at two points:</p>
<ul>
<li>The discriminator's strategy set is the set of measurable functions of type&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;&rarr;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5fd749cd052c95082902759ce7cc54aae48b2eaf" alt="{\displaystyle D:\Omega \to \mathbb {R} }" /></span>&nbsp;with bounded&nbsp;<a class="mw-redirect" title="Lipschitz norm" href="https://en.wikipedia.org/wiki/Lipschitz_norm">Lipschitz norm</a>:&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">‖�‖�&le;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cd0f760814ecd557a56037147ff29a62d886cc02" alt="{\displaystyle \|D\|_{L}\leq K}" /></span>, where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/49a64c4dcb4b067ca93f05a70b6f567477f714d3" alt="K" /></span>&nbsp;is a fixed positive constant.</li>
<li>The objective is
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�����(��,�):=��&sim;��[�(�)]&minus;��&sim;����[�(�)]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cb364d3ae8420f48a1e43bf7ac4480e8a38b2475" alt="{\displaystyle L_{WGAN}(\mu _{G},D):=\mathbb {E} _{x\sim \mu _{G}}[D(x)]-\mathbb {E} _{x\sim \mu _{ref}}[D(x)]}" /></div>
</li>
</ul>
<p>One of its purposes is to solve the problem of mode collapse (see above).<sup id="cite_ref-:3_16-2" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:3-16">[16]</a></sup>&nbsp;The authors claim "In no experiment did we see evidence of mode collapse for the WGAN algorithm".</p>
<h3><span id="GANs_with_more_than_2_players" class="mw-headline">GANs with more than 2 players</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: GANs with more than 2 players" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=23">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<h4><span id="Adversarial_autoencoder" class="mw-headline">Adversarial autoencoder</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Adversarial autoencoder" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=24">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>An adversarial autoencoder (AAE)<sup id="cite_ref-41" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-41">[41]</a></sup>&nbsp;is more autoencoder than GAN. The idea is to start with a plain&nbsp;<a title="Autoencoder" href="https://en.wikipedia.org/wiki/Autoencoder">autoencoder</a>, but train a discriminator to discriminate the latent vectors from a reference distribution (often the normal distribution).</p>
<h4><span id="InfoGAN" class="mw-headline">InfoGAN</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: InfoGAN" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=25">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In conditional GAN, the generator receives both a noise vector&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5805f5a9a74bfcb5326c77802d202931959a6044" alt="z" /></span>&nbsp;and a label&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7422142036966592529a097f042da841a2c9b51" alt="c" /></span>, and produces an image&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a88f03055ac5a10afb8f0ec0fb02a80c698f06d9" alt="{\displaystyle G(z,c)}" /></span>. The discriminator receives image-label pairs&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(�,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6d64a7befd5f948803d714546775acd5f8a3c667" alt="{\displaystyle (x,c)}" /></span>, and computes&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/364cfa9fab4f007a032d7659758b835e0149e131" alt="{\displaystyle D(x,c)}" /></span>.</p>
<p>When the training dataset is unlabeled, conditional GAN does not work directly.</p>
<p>The idea of InfoGAN is to decree that every latent vector in the latent space can be decomposed as&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(�,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6aa9731e621f01f868d5b76594cc384c0d986ade" alt="{\displaystyle (z,c)}" /></span>: an incompressible noise part&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5805f5a9a74bfcb5326c77802d202931959a6044" alt="z" /></span>, and an informative label part&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7422142036966592529a097f042da841a2c9b51" alt="c" /></span>, and encourage the generator to comply with the decree, by encouraging it to maximize&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�,�(�,�))</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/093ae27f662f069b4b04cdd5aa91b47eefff4237" alt="{\displaystyle I(c,G(z,c))}" /></span>, the&nbsp;<a title="Mutual information" href="https://en.wikipedia.org/wiki/Mutual_information">mutual information</a>&nbsp;between&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7422142036966592529a097f042da841a2c9b51" alt="c" /></span>&nbsp;and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a88f03055ac5a10afb8f0ec0fb02a80c698f06d9" alt="{\displaystyle G(z,c)}" /></span>, while making no demands on the mutual information&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5805f5a9a74bfcb5326c77802d202931959a6044" alt="z" /></span>&nbsp;between&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�,�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a88f03055ac5a10afb8f0ec0fb02a80c698f06d9" alt="{\displaystyle G(z,c)}" /></span>.</p>
<p>Unfortunately,&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�,�(�,�))</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/093ae27f662f069b4b04cdd5aa91b47eefff4237" alt="{\displaystyle I(c,G(z,c))}" /></span>&nbsp;is intractable in general, The key idea of InfoGAN is Variational Mutual Information Maximization:<sup id="cite_ref-42" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-42">[42]</a></sup>&nbsp;indirectly maximize it by maximizing a lower bound</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�^(�,�)=��&sim;��,�&sim;��[ln⁡�(�|�(�,�))];�(�,�(�,�))&ge;sup��^(�,�)</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f9d0a6292d5fe0efd763c7789986eda14d3386d" alt="{\displaystyle {\hat {I}}(G,Q)=\mathbb {E} _{z\sim \mu _{Z},c\sim \mu _{C}}[\ln Q(c|G(z,c))];\quad I(c,G(z,c))\geq \sup _{Q}{\hat {I}}(G,Q)}" /></div>
where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a58f821939f10fed529c3d014263bf4455b19c48" alt=" Q" /></span>&nbsp;ranges over all&nbsp;<a title="Markov kernel" href="https://en.wikipedia.org/wiki/Markov_kernel">Markov kernels</a>&nbsp;of type&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;�&rarr;�(&Omega;�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b0945d8c643a9e69c456d4123d92303e2be61b8" alt="{\displaystyle Q:\Omega _{Y}\to {\mathcal {P}}(\Omega _{C})}" /></span>.
<p>&nbsp;</p>
<p>The InfoGAN game is defined as follows:<sup id="cite_ref-43" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-43">[43]</a></sup></p>
<blockquote>
<p>Three probability spaces define an InfoGAN game:</p>
<ul>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(&Omega;�,����)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2629fa11fdbb3c680eae13619fb23d37a175729c" alt="{\displaystyle (\Omega _{X},\mu _{ref})}" /></span>, the space of reference images.</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(&Omega;�,��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e2ef352a13722c5f12d9fc39d8b0e3f0c78fdab6" alt="{\displaystyle (\Omega _{Z},\mu _{Z})}" /></span>, the fixed random noise generator.</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(&Omega;�,��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4c1c92bb72a8bf248d31c6d83501fd1193dc3ab7" alt="{\displaystyle (\Omega _{C},\mu _{C})}" /></span>, the fixed random information generator.</li>
</ul>
<p>There are 3 players in 2 teams: generator, Q, and discriminator. The generator and Q are on one team, and the discriminator on the other team.</p>
<p>The objective function is</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(�,�,�)=����(�,�)&minus;��^(�,�)</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ade4f0dc160b7e16cdadcc5f22399dfa2690c6ef" alt="{\displaystyle L(G,Q,D)=L_{GAN}(G,D)-\lambda {\hat {I}}(G,Q)}" /></div>
where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����(�,�)=��&sim;����,[ln⁡�(�)]+��&sim;��[ln⁡(1&minus;�(�(�,�)))]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7dc8ffffa98d98a125b5ac63e9aa04f7b54a72d7" alt="{\displaystyle L_{GAN}(G,D)=\mathbb {E} _{x\sim \mu _{ref},}[\ln D(x)]+\mathbb {E} _{z\sim \mu _{Z}}[\ln(1-D(G(z,c)))]}" /></span>&nbsp;is the original GAN game objective, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�^(�,�)=��&sim;��,�&sim;��[ln⁡�(�|�(�,�))]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/331080a17784eb6d80cbd5485576237aae26f6de" alt="{\displaystyle {\hat {I}}(G,Q)=\mathbb {E} _{z\sim \mu _{Z},c\sim \mu _{C}}[\ln Q(c|G(z,c))]}" /></span>
<p>&nbsp;</p>
<p>Generator-Q team aims to minimize the objective, and discriminator aims to maximize it:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">min�,�max��(�,�,�)</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/accbd9689e14e05ab91c923338d2039e4d175efe" alt="{\displaystyle \min _{G,Q}\max _{D}L(G,Q,D)}" /></div>
<p>&nbsp;</p>
</blockquote>
<h4><span id="Bidirectional_GAN_.28BiGAN.29"></span><span id="Bidirectional_GAN_(BiGAN)" class="mw-headline">Bidirectional GAN (BiGAN)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Bidirectional GAN (BiGAN)" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=26">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The standard GAN generator is a function of type&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;�&rarr;&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b5493458d2c0c93d111861cbcb8d6b80aab15056" alt="{\displaystyle G:\Omega _{Z}\to \Omega _{X}}" /></span>, that is, it is a mapping from a latent space&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5616932d94313e2541634c5719e3cd3c79f63a82" alt="{\displaystyle \Omega _{Z}}" /></span>&nbsp;to the image space&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/22e27adfa2c5debf6696e0e060f64c9f7e8ea9af" alt="\Omega _{X}" /></span>. This can be understood as a "decoding" process, whereby every latent vector&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&isin;&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6d6962dd0c61a6cc80f276ed088b29f53f420b7d" alt="{\displaystyle z\in \Omega _{Z}}" /></span>&nbsp;is a code for an image&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&isin;&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5ce72c085fa1966747a97c86546ca108761617c6" alt="{\displaystyle x\in \Omega _{X}}" /></span>, and the generator performs the decoding. This naturally leads to the idea of training another network that performs "encoding", creating an&nbsp;<a title="Autoencoder" href="https://en.wikipedia.org/wiki/Autoencoder">autoencoder</a>&nbsp;out of the encoder-generator pair.</p>
<p>Already in the original paper,<sup id="cite_ref-GANnips_3-8" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup>&nbsp;the authors noted that "Learned approximate inference can be performed by training an auxiliary network to predict&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5805f5a9a74bfcb5326c77802d202931959a6044" alt="z" /></span>&nbsp;given&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e315c1e498e50190b9be0e8ad82a80be836c89f" alt="x" /></span>". The bidirectional GAN architecture performs exactly this.<sup id="cite_ref-44" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-44">[44]</a></sup></p>
<p>The BiGAN is defined as follows:</p>
<blockquote>
<p>Two probability spaces define a BiGAN game:</p>
<ul>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(&Omega;�,��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5548787944afedbf2a83370f7f3fe4ef27e657fa" alt="{\displaystyle (\Omega _{X},\mu _{X})}" /></span>, the space of reference images.</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(&Omega;�,��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e2ef352a13722c5f12d9fc39d8b0e3f0c78fdab6" alt="{\displaystyle (\Omega _{Z},\mu _{Z})}" /></span>, the latent space.</li>
</ul>
<p>There are 3 players in 2 teams: generator, encoder, and discriminator. The generator and encoder are on one team, and the discriminator on the other team.</p>
<p>The generator's strategies are functions&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;�&rarr;&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b5493458d2c0c93d111861cbcb8d6b80aab15056" alt="{\displaystyle G:\Omega _{Z}\to \Omega _{X}}" /></span>, and the encoder's strategies are functions&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;�&rarr;&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8a674be6f649be00260e64f4f64e68f8ecbba969" alt="{\displaystyle E:\Omega _{X}\to \Omega _{Z}}" /></span>. The discriminator's strategies are functions&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;�&rarr;[0,1]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/22a37008c49fac57a80a9a59f49c34c0273168f6" alt="{\displaystyle D:\Omega _{X}\to [0,1]}" /></span>.</p>
<p>The objective function is</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(�,�,�)=��&sim;��[ln⁡�(�,�(�))]+��&sim;��[ln⁡(1&minus;�(�(�),�))]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/354bd3dd8cbb2f8292e671dd6b42263d323ef532" alt="{\displaystyle L(G,E,D)=\mathbb {E} _{x\sim \mu _{X}}[\ln D(x,E(x))]+\mathbb {E} _{z\sim \mu _{Z}}[\ln(1-D(G(z),z))]}" /></div>
<p>&nbsp;</p>
<p>Generator-encoder team aims to minimize the objective, and discriminator aims to maximize it:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">min�,�max��(�,�,�)</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c91a460e5241f46de168fed61244b1ec0957824" alt="{\displaystyle \min _{G,E}\max _{D}L(G,E,D)}" /></div>
<p>&nbsp;</p>
</blockquote>
<p>In the paper, they gave a more abstract definition of the objective as:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(�,�,�)=�(�,�)&sim;��,�[ln⁡�(�,�)]+�(�,�)&sim;��,�[ln⁡(1&minus;�(�,�))]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b66ef02b76d9476dc6ec665cb2d84c71fbb4879" alt="{\displaystyle L(G,E,D)=\mathbb {E} _{(x,z)\sim \mu _{E,X}}[\ln D(x,z)]+\mathbb {E} _{(x,z)\sim \mu _{G,Z}}[\ln(1-D(x,z))]}" /></div>
where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��,�(��,��)=��(��)&sdot;��(�)(��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5c329a67d5bf9766e96ae62b0cf3363e56d54a0" alt="{\displaystyle \mu _{E,X}(dx,dz)=\mu _{X}(dx)\cdot \delta _{E(x)}(dz)}" /></span>&nbsp;is the probability distribution on&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;�&times;&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3e148ba5d4b77970cc1a18780e54d8d665de644f" alt="{\displaystyle \Omega _{X}\times \Omega _{Z}}" /></span>&nbsp;obtained by&nbsp;<a title="Pushforward measure" href="https://en.wikipedia.org/wiki/Pushforward_measure">pushing&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/92fbfe0a826a9688c5a885d395228f676b14937a" alt="\mu _{X}" /></span>&nbsp;forward</a>&nbsp;via&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�↦(�,�(�))</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/111687950a72599b79b27a1a9c76c21bb38c19e9" alt="{\displaystyle x\mapsto (x,E(x))}" /></span>, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��,�(��,��)=��(�)(��)&sdot;��(��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fec2350cd0d5b77f2b941fedac88b6447008373e" alt="{\displaystyle \mu _{G,Z}(dx,dz)=\delta _{G(z)}(dx)\cdot \mu _{Z}(dz)}" /></span>&nbsp;is the probability distribution on&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;�&times;&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3e148ba5d4b77970cc1a18780e54d8d665de644f" alt="{\displaystyle \Omega _{X}\times \Omega _{Z}}" /></span>&nbsp;obtained by pushing&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4dfd7b88be4d0e36a21cb6d4a486bcaf0128a324" alt="{\displaystyle \mu _{Z}}" /></span>&nbsp;forward via&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�↦(�(�),�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b25fcc1983db5e76caf703c930e6032cd2a0e44c" alt="{\displaystyle z\mapsto (G(x),z)}" /></span>.
<p>&nbsp;</p>
<p>Applications of bidirectional models include&nbsp;<a class="mw-redirect" title="Semi-supervised learning" href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised learning</a>,<sup id="cite_ref-45" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-45">[45]</a></sup>&nbsp;<a title="Explainable artificial intelligence" href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">interpretable machine learning</a>,<sup id="cite_ref-46" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-46">[46]</a></sup>&nbsp;and&nbsp;<a title="Neural machine translation" href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a>.<sup id="cite_ref-47" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-47">[47]</a></sup></p>
<h4><span id="CycleGAN" class="mw-headline">CycleGAN</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: CycleGAN" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=27">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>CycleGAN is an architecture for performing translations between two domains, such as between photos of horses and photos of zebras, or photos of night cities and photos of day cities.</p>
<p>The CycleGAN game is defined as follows:<sup id="cite_ref-48" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-48">[48]</a></sup></p>
<blockquote>
<p>There are two probability spaces&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(&Omega;�,��),(&Omega;�,��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2a2bd7d5d2b5027d302c3eb576ad41a5fd834fb2" alt="{\displaystyle (\Omega _{X},\mu _{X}),(\Omega _{Y},\mu _{Y})}" /></span>, corresponding to the two domains needed for translations fore-and-back.</p>
<p>There are 4 players in 2 teams: generators&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��:&Omega;�&rarr;&Omega;�,��:&Omega;�&rarr;&Omega;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/163a824da8de88ea3c434adf01301d8e77c1edbb" alt="{\displaystyle G_{X}:\Omega _{X}\to \Omega _{Y},G_{Y}:\Omega _{Y}\to \Omega _{X}}" /></span>, and discriminators&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��:&Omega;�&rarr;[0,1],��:&Omega;�&rarr;[0,1]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8c4c214517f2a68640295a7c1a6d00850fc084e6" alt="{\displaystyle D_{X}:\Omega _{X}\to [0,1],D_{Y}:\Omega _{Y}\to [0,1]}" /></span>.</p>
<p>The objective function is</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">�(��,��,��,��)=����(��,��)+����(��,��)+�������(��,��)</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9b23dfa070aed3bf63fe71da674e6c1250f02667" alt="{\displaystyle L(G_{X},G_{Y},D_{X},D_{Y})=L_{GAN}(G_{X},D_{X})+L_{GAN}(G_{Y},D_{Y})+\lambda L_{cycle}(G_{X},G_{Y})}" /></div>
<p>&nbsp;</p>
<p>where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e888c0a0c21333e7e9ed2c930894c1bdbe9f7cfc" alt="\lambda " /></span>&nbsp;is a positive adjustable parameter,&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/67065de529fe65c7429dc893c2df9a9abbe7ca8f" alt="{\displaystyle L_{GAN}}" /></span>&nbsp;is the GAN game objective, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">������</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/373674bc48195d6b11d55e4126fe21e4aebe3d08" alt="{\displaystyle L_{cycle}}" /></span>&nbsp;is the&nbsp;<em>cycle consistency loss</em>:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">������(��,��)=��&sim;��‖��(��(�))&minus;�‖+��&sim;��‖��(��(�))&minus;�‖</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7097d28c503a500999e6344166ce2002ad3cf93" alt="{\displaystyle L_{cycle}(G_{X},G_{Y})=E_{x\sim \mu _{X}}\|G_{X}(G_{Y}(x))-x\|+E_{y\sim \mu _{Y}}\|G_{Y}(G_{X}(y))-y\|}" /></div>
The generators aim to minimize the objective, and the discriminators aim to maximize it:
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">min��,��max��,���(��,��,��,��)</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d9a55df6d45a6fab12a3d018f4281b99bf33e012" alt="{\displaystyle \min _{G_{X},G_{Y}}\max _{D_{X},D_{Y}}L(G_{X},G_{Y},D_{X},D_{Y})}" /></div>
<p>&nbsp;</p>
</blockquote>
<p>Unlike previous work like pix2pix,<sup id="cite_ref-49" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-49">[49]</a></sup>&nbsp;which requires paired training data, cycleGAN requires no paired data. For example, to train a pix2pix model to turn a summer scenery photo to winter scenery photo and back, the dataset must contain pairs of the same place in summer and winter, shot at the same angle; cycleGAN would only need a set of summer scenery photos, and an unrelated set of winter scenery photos.</p>
<h3><span id="GANs_with_particularly_large_or_small_scales" class="mw-headline">GANs with particularly large or small scales</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: GANs with particularly large or small scales" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=28">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<h4><span id="BigGAN" class="mw-headline">BigGAN</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: BigGAN" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=29">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The BigGAN is essentially a self-attention GAN trained on a large scale (up to 80 million parameters) to generate large images of ImageNet (up to 512 x 512 resolution), with numerous engineering tricks to make it converge.<sup id="cite_ref-:0_23-1" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:0-23">[23]</a></sup><sup id="cite_ref-50" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-50">[50]</a></sup></p>
<h4><span id="Invertible_data_augmentation" class="mw-headline">Invertible data augmentation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Invertible data augmentation" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=30">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>When there is insufficient training data, the reference distribution&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/15d15b590538ca3450d814c51e7707812a8c26b4" alt="{\displaystyle \mu _{ref}}" /></span>&nbsp;cannot be well-approximated by the&nbsp;<a title="Empirical measure" href="https://en.wikipedia.org/wiki/Empirical_measure">empirical distribution</a>&nbsp;given by the training dataset. In such cases,&nbsp;<a title="Data augmentation" href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>&nbsp;can be applied, to allow training GAN on smaller datasets. Na&iuml;ve data augmentation, however, brings its problems.</p>
<p>Consider the original GAN game, slightly reformulated as follows:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">{min���(�,��)=&minus;��&sim;����[ln⁡�(�)]&minus;��&sim;��[ln⁡(1&minus;�(�))]min���(�,��)=&minus;��&sim;��[ln⁡(1&minus;�(�))]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/83438b32636de3b08fc5c5e7b8950150791ce3a8" alt="{\displaystyle {\begin{cases}\min _{D}L_{D}(D,\mu _{G})=-\mathbb {E} _{x\sim \mu _{ref}}[\ln D(x)]-\mathbb {E} _{x\sim \mu _{G}}[\ln(1-D(x))]\\\min _{G}L_{G}(D,\mu _{G})=-\mathbb {E} _{x\sim \mu _{G}}[\ln(1-D(x))]\end{cases}}}" /></div>
Now we use data augmentation by randomly sampling semantic-preserving transforms&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;&rarr;&Omega;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4e1aa99370a83771c64b1dada731520ce2237b97" alt="{\displaystyle T:\Omega \to \Omega }" /></span>&nbsp;and applying them to the dataset, to obtain the reformulated GAN game:
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">{min���(�,��)=&minus;��&sim;����,�&sim;������[ln⁡�(�(�))]&minus;��&sim;��[ln⁡(1&minus;�(�))]min���(�,��)=&minus;��&sim;��[ln⁡(1&minus;�(�))]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d411e3e2a786e29a5778967d031cbdf09adfd9d3" alt="{\displaystyle {\begin{cases}\min _{D}L_{D}(D,\mu _{G})=-\mathbb {E} _{x\sim \mu _{ref},T\sim \mu _{trans}}[\ln D(T(x))]-\mathbb {E} _{x\sim \mu _{G}}[\ln(1-D(x))]\\\min _{G}L_{G}(D,\mu _{G})=-\mathbb {E} _{x\sim \mu _{G}}[\ln(1-D(x))]\end{cases}}}" /></div>
This is equivalent to a GAN game with a different distribution&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f98f3fbad59a7b3b12a8f9adaf380a125376fe05" alt="{\displaystyle \mu _{ref}'}" /></span>, sampled by&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/915dff9066e85fe1cc045e5ff1efea15b045f1c3" alt="T(x)" /></span>, with&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&sim;����,�&sim;������</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/219219e84ee81d276c02bc91a6cab6043d17c7d0" alt="{\displaystyle x\sim \mu _{ref},T\sim \mu _{trans}}" /></span>. For example, if&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/15d15b590538ca3450d814c51e7707812a8c26b4" alt="{\displaystyle \mu _{ref}}" /></span>&nbsp;is the distribution of images in ImageNet, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">������</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cbfc8d37a4dbc2c1e909b4db221385b324c36572" alt="{\displaystyle \mu _{trans}}" /></span>&nbsp;samples identity-transform with probability 0.5, and horizontal-reflection with probability 0.5, then&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f98f3fbad59a7b3b12a8f9adaf380a125376fe05" alt="{\displaystyle \mu _{ref}'}" /></span>&nbsp;is the distribution of images in ImageNet and horizontally-reflected ImageNet, combined.
<p>&nbsp;</p>
<p>The result of such training would be a generator that mimics&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f98f3fbad59a7b3b12a8f9adaf380a125376fe05" alt="{\displaystyle \mu _{ref}'}" /></span>. For example, it would generate images that look like they are randomly cropped, if the data augmentation uses random cropping.</p>
<p>The solution is to apply data augmentation to both generated and real images:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">{min���(�,��)=&minus;��&sim;����,�&sim;������[ln⁡�(�(�))]&minus;��&sim;��,�&sim;������[ln⁡(1&minus;�(�(�)))]min���(�,��)=&minus;��&sim;��,�&sim;������[ln⁡(1&minus;�(�(�)))]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/708e5984916386bcb839e42a686d22069ee35cd2" alt="{\displaystyle {\begin{cases}\min _{D}L_{D}(D,\mu _{G})=-\mathbb {E} _{x\sim \mu _{ref},T\sim \mu _{trans}}[\ln D(T(x))]-\mathbb {E} _{x\sim \mu _{G},T\sim \mu _{trans}}[\ln(1-D(T(x)))]\\\min _{G}L_{G}(D,\mu _{G})=-\mathbb {E} _{x\sim \mu _{G},T\sim \mu _{trans}}[\ln(1-D(T(x)))]\end{cases}}}" /></div>
The authors demonstrated high-quality generation using just 100-picture-large datasets.<sup id="cite_ref-51" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-51">[51]</a></sup>
<p>&nbsp;</p>
<p>The StyleGAN-2-ADA paper points out a further point on data augmentation: it must be&nbsp;<em>invertible</em>.<sup id="cite_ref-:4_52-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:4-52">[52]</a></sup>&nbsp;Continue with the example of generating ImageNet pictures. If the data augmentation is "randomly rotate the picture by 0, 90, 180, 270 degrees with&nbsp;<em>equal</em>&nbsp;probability", then there is no way for the generator to know which is the true orientation: Consider two generators&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�,�&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6c11c7db05254b6511cb5244edf569853eee37bb" alt="{\displaystyle G,G'}" /></span>, such that for any latent&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5805f5a9a74bfcb5326c77802d202931959a6044" alt="z" /></span>, the generated image&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e82b08ac9027d31c740345f2302cb7a68d5a0646" alt="G(z)" /></span>&nbsp;is a 90-degree rotation of&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&prime;(�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1d433da6505a730d12ee21b6fb66e7b587a46fac" alt="{\displaystyle G'(z)}" /></span>. They would have exactly the same expected loss, and so neither is preferred over the other.</p>
<p>The solution is to only use invertible data augmentation: instead of "randomly rotate the picture by 0, 90, 180, 270 degrees with&nbsp;<em>equal</em>&nbsp;probability", use "randomly rotate the picture by 90, 180, 270 degrees with 0.1 probability, and keep the picture as it is with 0.7 probability". This way, the generator is still rewarded to keep images oriented the same way as un-augmented ImageNet pictures.</p>
<p>Abstractly, the effect of randomly sampling transformations&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�:&Omega;&rarr;&Omega;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4e1aa99370a83771c64b1dada731520ce2237b97" alt="{\displaystyle T:\Omega \to \Omega }" /></span>&nbsp;from the distribution&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">������</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cbfc8d37a4dbc2c1e909b4db221385b324c36572" alt="{\displaystyle \mu _{trans}}" /></span>&nbsp;is to define a Markov kernel&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">������:&Omega;&rarr;�(&Omega;)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/39b8ac4da94e1f8b88e9de7476add178672400c5" alt="{\displaystyle K_{trans}:\Omega \to {\mathcal {P}}(\Omega )}" /></span>. Then, the data-augmented GAN game pushes the generator to find some&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�^�&isin;�(&Omega;)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/11e1b6421f19a479ccfc0e51685525192e2ac5d2" alt="{\displaystyle {\hat {\mu }}_{G}\in {\mathcal {P}}(\Omega )}" /></span>, such that</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">������&lowast;����=������&lowast;�^�</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5ae01f4e7c75468a0592b9703959cf3e5d019ba5" alt="{\displaystyle K_{trans}*\mu _{ref}=K_{trans}*{\hat {\mu }}_{G}}" /></div>
where&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&lowast;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/94a65d2fd6eb453771b7de81319f7c1bdf0da2ba" alt="*" /></span>&nbsp;is the&nbsp;<a title="Convolution of probability distributions" href="https://en.wikipedia.org/wiki/Convolution_of_probability_distributions">Markov kernel convolution</a>. A data-augmentation method is defined to be&nbsp;<em>invertible</em>&nbsp;if its Markov kernel&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">������</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a0b269cfbaf318f476988c114b3717a78e7c8998" alt="{\displaystyle K_{trans}}" /></span>&nbsp;satisfies
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">������&lowast;�=������&lowast;�&prime;⟹�=�&prime;&forall;�,�&prime;&isin;�(&Omega;)</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b08c45db47c2e1b110ca134158d6c715131902b" alt="{\displaystyle K_{trans}*\mu =K_{trans}*\mu '\implies \mu =\mu '\quad \forall \mu ,\mu '\in {\mathcal {P}}(\Omega )}" /></div>
Immediately by definition, we see that composing multiple invertible data-augmentation methods results in yet another invertible method. Also by definition, if the data-augmentation method is invertible, then using it in a GAN game does not change the optimal strategy&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�^�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ff89e647a3f6a3bf250b3faf1ec642c52f2ffe99" alt="{\displaystyle {\hat {\mu }}_{G}}" /></span>&nbsp;for the generator, which is still&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">����</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/15d15b590538ca3450d814c51e7707812a8c26b4" alt="{\displaystyle \mu _{ref}}" /></span>.
<p>&nbsp;</p>
<p>There are two prototypical examples of invertible Markov kernels:</p>
<p><strong>Discrete case</strong>: Invertible&nbsp;<a title="Stochastic matrix" href="https://en.wikipedia.org/wiki/Stochastic_matrix">stochastic matrices</a>, when&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d80b0b33ae50a23bfe35d912fb6d780bf6e9f135" alt="\Omega " /></span>&nbsp;is finite.</p>
<p>For example, if&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;={&uarr;,&darr;,&larr;,&rarr;}</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bc8a15f373abba4cc2da174efa55c425bb93c69c" alt="{\displaystyle \Omega =\{\uparrow ,\downarrow ,\leftarrow ,\rightarrow \}}" /></span>&nbsp;is the set of four images of an arrow, pointing in 4 directions, and the data augmentation is "randomly rotate the picture by 90, 180, 270 degrees with probability&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c42931ccbde9ee150ca3a39d82428ff718140a53" alt="p" /></span>, and keep the picture as it is with probability&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">(1&minus;3�)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b530304d2e6a9751e917871dbc69f4ccd11aeab" alt="{\displaystyle (1-3p)}" /></span>", then the Markov kernel&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">������</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a0b269cfbaf318f476988c114b3717a78e7c8998" alt="{\displaystyle K_{trans}}" /></span>&nbsp;can be represented as a stochastic matrix:</p>
<div class="mwe-math-element">
<div class="mwe-math-mathml-display mwe-math-mathml-a11y">[������]=[(1&minus;3�)����(1&minus;3�)����(1&minus;3�)����(1&minus;3�)]</div>
<img class="mwe-math-fallback-image-display" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ca9754f61e7f936d873ecfa5a7a7237aa2b02c6a" alt="{\displaystyle [K_{trans}]={\begin{bmatrix}(1-3p)&amp;p&amp;p&amp;p\\p&amp;(1-3p)&amp;p&amp;p\\p&amp;p&amp;(1-3p)&amp;p\\p&amp;p&amp;p&amp;(1-3p)\end{bmatrix}}}" /></div>
and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">������</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a0b269cfbaf318f476988c114b3717a78e7c8998" alt="{\displaystyle K_{trans}}" /></span>&nbsp;is an invertible kernel iff&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">[������]</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e51428b20010e3dbcf0a439c2d948cf775fd1d47" alt="{\displaystyle [K_{trans}]}" /></span>&nbsp;is an invertible matrix, that is,&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&ne;1/4</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/de1588fffbfc30890ac56c5f23d4a13d228a17ac" alt="{\displaystyle p\neq 1/4}" /></span>.
<p>&nbsp;</p>
<p><strong>Continuous case</strong>: The gaussian kernel, when&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;=��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/504f9ebcf49b94b718a345cd7de6acb74e54711b" alt="{\displaystyle \Omega =\mathbb {R} ^{n}}" /></span>&nbsp;for some&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&ge;1</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132a50fc29543d4c5bb33b06c211da4baa6480cf" alt="n\geq 1" /></span>.</p>
<p>For example, if&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">&Omega;=�2562</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3140627203a8483e51738421fde0d49e0c8470d2" alt="{\displaystyle \Omega =\mathbb {R} ^{256^{2}}}" /></span>&nbsp;is the space of 256x256 images, and the data-augmentation method is "generate a gaussian noise&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&sim;�(0,�2562)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75512decfcec50500b9e01b9a1f5e125917d3bf8" alt="{\displaystyle z\sim {\mathcal {N}}(0,I_{256^{2}})}" /></span>, then add&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ae91d4bde14d78a981cfba664238a73d4d16840b" alt="{\displaystyle \epsilon z}" /></span>&nbsp;to the image", then&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">������</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a0b269cfbaf318f476988c114b3717a78e7c8998" alt="{\displaystyle K_{trans}}" /></span>&nbsp;is just convolution by the density function of&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(0,�2�2562)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c88005a41326848e85385181bbbce8de550133a3" alt="{\displaystyle {\mathcal {N}}(0,\epsilon ^{2}I_{256^{2}})}" /></span>. This is invertible, because convolution by a gaussian is just convolution by the&nbsp;<a title="Heat kernel" href="https://en.wikipedia.org/wiki/Heat_kernel">heat kernel</a>, so given any&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&isin;�(��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c0b6f49caa1b7ab87b7d0e26a8b973ab0c3ee6cd" alt="{\displaystyle \mu \in {\mathcal {P}}(\mathbb {R} ^{n})}" /></span>, the convolved distribution&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">������&lowast;�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9bbbabb9eb068984dc4d724784c7d76b1898b528" alt="{\displaystyle K_{trans}*\mu }" /></span>&nbsp;can be obtained by heating up&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a921f40b7242b3272e7cf974785792df4b2544bb" alt="\mathbb {R} ^{n}" /></span>&nbsp;precisely according to&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/eadf83405ce8a69fbbd03de0a0642e1409b3adfc" alt="\mu " /></span>, then wait for time&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�2/4</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1524aa5f2980777d78e9bc41e2f0ac974b7fa6b9" alt="{\displaystyle \epsilon ^{2}/4}" /></span>. With that, we can recover&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/eadf83405ce8a69fbbd03de0a0642e1409b3adfc" alt="\mu " /></span>&nbsp;by running the&nbsp;<a title="Heat equation" href="https://en.wikipedia.org/wiki/Heat_equation">heat equation</a>&nbsp;<em>backwards in time</em>&nbsp;for&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�2/4</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1524aa5f2980777d78e9bc41e2f0ac974b7fa6b9" alt="{\displaystyle \epsilon ^{2}/4}" /></span>.</p>
<p>More examples of invertible data augmentations are found in the paper.<sup id="cite_ref-:4_52-1" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:4-52">[52]</a></sup></p>
<h4><span id="SinGAN" class="mw-headline">SinGAN</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: SinGAN" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=31">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>SinGAN pushes data augmentation to the limit, by using only a single image as training data and performing data augmentation on it. The GAN architecture is adapted to this training method by using a multi-scale pipeline.</p>
<p>The generator&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5551faa0c67e2772a68ae24ecb0d828adb057a56" alt="G" /></span>&nbsp;is decomposed into a pyramid of generators&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�=�1∘�2∘⋯∘��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/157546da714f1d080a1fa0964dce722a7bcdb8e1" alt="{\displaystyle G=G_{1}\circ G_{2}\circ \cdots \circ G_{N}}" /></span>, with the lowest one generating the image&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��(��)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e3b0502844f3f6eeaa76a478b6c1af8b46ebc29e" alt="{\displaystyle G_{N}(z_{N})}" /></span>&nbsp;at the lowest resolution, then the generated image is scaled up to&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(��(��))</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/721cde5b1c092bc96003a0eb894225b394d0d5b9" alt="{\displaystyle r(G_{N}(z_{N}))}" /></span>, and fed to the next level to generate an image&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��&minus;1(��&minus;1+�(��(��)))</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a88b29bc4a0f41e024495569319f65138ec3641" alt="{\displaystyle G_{N-1}(z_{N-1}+r(G_{N}(z_{N})))}" /></span>&nbsp;at a higher resolution, and so on. The discriminator is decomposed into a pyramid as well.<sup id="cite_ref-53" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-53">[53]</a></sup></p>
<h3><span id="StyleGAN_series" class="mw-headline">StyleGAN series</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: StyleGAN series" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=32">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="hatnote navigation-not-searchable">Main article:&nbsp;<a title="StyleGAN" href="https://en.wikipedia.org/wiki/StyleGAN">StyleGAN</a></div>
<p>The StyleGAN family is a series of architectures published by&nbsp;<a title="Nvidia" href="https://en.wikipedia.org/wiki/Nvidia">Nvidia</a>'s research division.</p>
<h4><span id="Progressive_GAN" class="mw-headline">Progressive GAN</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Progressive GAN" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=33">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Progressive GAN<sup id="cite_ref-:1_17-1" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:1-17">[17]</a></sup>&nbsp;is a method for training GAN for large-scale image generation stably, by growing a GAN generator from small to large scale in a pyramidal fashion. Like SinGAN, it decomposes the generator as<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�=�1∘�2∘⋯∘��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/157546da714f1d080a1fa0964dce722a7bcdb8e1" alt="{\displaystyle G=G_{1}\circ G_{2}\circ \cdots \circ G_{N}}" /></span>, and the discriminator as&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�=�1∘�2∘⋯∘��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2fc2aeeaee0f99dea503f8d56f8015b008ff4cfa" alt="{\displaystyle D=D_{1}\circ D_{2}\circ \cdots \circ D_{N}}" /></span>.</p>
<p>During training, at first only&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��,��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2092bb205a6e1c5e7ff395a2f831217e18e0ac0d" alt="{\displaystyle G_{N},D_{N}}" /></span>&nbsp;are used in a GAN game to generate 4x4 images. Then&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��&minus;1,��&minus;1</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5f8960f329f7f7725da26898bf7736730bf455c4" alt="{\displaystyle G_{N-1},D_{N-1}}" /></span>&nbsp;are added to reach the second stage of GAN game, to generate 8x8 images, and so on, until we reach a GAN game to generate 1024x1024 images.</p>
<p>To avoid shock between stages of the GAN game, each new layer is "blended in" (Figure 2 of the paper<sup id="cite_ref-:1_17-2" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:1-17">[17]</a></sup>). For example, this is how the second stage GAN game starts:</p>
<ul>
<li>Just before, the GAN game consists of the pair&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">��,��</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2092bb205a6e1c5e7ff395a2f831217e18e0ac0d" alt="{\displaystyle G_{N},D_{N}}" /></span>&nbsp;generating and discriminating 4x4 images.</li>
<li>Just after, the GAN game consists of the pair&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">((1&minus;�)+�&sdot;��&minus;1)∘�∘��,��∘�∘((1&minus;�)+�&sdot;��&minus;1)</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fcc5849152233ea4e0f628113f86251d3bc8f219" alt="{\displaystyle ((1-\alpha )+\alpha \cdot G_{N-1})\circ u\circ G_{N},D_{N}\circ d\circ ((1-\alpha )+\alpha \cdot D_{N-1})}" /></span>&nbsp;generating and discriminating 8x8 images. Here, the functions&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�,�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9183aba32e59e7464316ac1ae1cf14f693fef420" alt="{\displaystyle u,d}" /></span>&nbsp;are image up- and down-sampling functions, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ee2a319db178e51919baafc482b83b8a29411715" alt="\alpha " /></span>&nbsp;is a blend-in factor (much like an&nbsp;<a title="Alpha compositing" href="https://en.wikipedia.org/wiki/Alpha_compositing">alpha</a>&nbsp;in image composing) that smoothly glides from 0 to 1.</li>
</ul>
<h4><span id="StyleGAN-1" class="mw-headline">StyleGAN-1</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: StyleGAN-1" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=34">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<figure><a class="mw-file-description" href="https://en.wikipedia.org/wiki/File:StyleGAN-1_and_StyleGAN-2.png"><img class="mw-file-element" src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/StyleGAN-1_and_StyleGAN-2.png/361px-StyleGAN-1_and_StyleGAN-2.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/97/StyleGAN-1_and_StyleGAN-2.png/542px-StyleGAN-1_and_StyleGAN-2.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/97/StyleGAN-1_and_StyleGAN-2.png/722px-StyleGAN-1_and_StyleGAN-2.png 2x" alt="" width="361" height="156" data-file-width="5400" data-file-height="2335" /></a>
<figcaption>The main architecture of StyleGAN-1 and StyleGAN-2</figcaption>
</figure>
<p>StyleGAN-1 is designed as a combination of Progressive GAN with&nbsp;<a title="Neural style transfer" href="https://en.wikipedia.org/wiki/Neural_style_transfer">neural style transfer</a>.<sup id="cite_ref-54" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-54">[54]</a></sup></p>
<p>The key architectural choice of StyleGAN-1 is a progressive growth mechanism, similar to Progressive GAN. Each generated image starts as a constant&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">4&times;4&times;512</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3f195bca56a5371a675f6c11db5c77fdc1add6e" alt="{\displaystyle 4\times 4\times 512}" /></span>&nbsp;array, and repeatedly passed through style blocks. Each style block applies a "style latent vector" via affine transform ("adaptive instance normalization"), similar to how neural style transfer uses&nbsp;<a class="mw-redirect" title="Gramian matrix" href="https://en.wikipedia.org/wiki/Gramian_matrix">Gramian matrix</a>. It then adds noise, and normalize (subtract the mean, then divide by the variance).</p>
<p>At training time, usually only one style latent vector is used per image generated, but sometimes two ("mixing regularization") in order to encourage each style block to independently perform its stylization without expecting help from other style blocks (since they might receive an entirely different style latent vector).</p>
<p>After training, multiple style latent vectors can be fed into each style block. Those fed to the lower layers control the large-scale styles, and those fed to the higher layers control the fine-detail styles.</p>
<p>Style-mixing between two images&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�,�&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/868106c4dab7e143519d80dfb0ce9ca91f367330" alt="{\displaystyle x,x'}" /></span>&nbsp;can be performed as well. First, run a gradient descent to find&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�,�&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1ebb34c090ac87c69c346229c9a782940085c78d" alt="{\displaystyle z,z'}" /></span>&nbsp;such that&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�(�)&asymp;�,�(�&prime;)&asymp;�&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/13b66af6652153fed22cc04ad05ca12d78855554" alt="{\displaystyle G(z)\approx x,G(z')\approx x'}" /></span>. This is called "projecting an image back to style latent space". Then,&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5805f5a9a74bfcb5326c77802d202931959a6044" alt="z" /></span>&nbsp;can be fed to the lower style blocks, and&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2583ff5fb39a111a122b9558bfd3f4604a9550db" alt="z'" /></span>&nbsp;to the higher style blocks, to generate a composite image that has the large-scale style of&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e315c1e498e50190b9be0e8ad82a80be836c89f" alt="x" /></span>, and the fine-detail style of&nbsp;<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y">�&prime;</span><img class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ad671ae6006c25f9d6a79e14a920a65fd85e0ed3" alt="x'" /></span>. Multiple images can also be composed this way.</p>
<h4><span id="StyleGAN-2" class="mw-headline">StyleGAN-2</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: StyleGAN-2" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=35">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>StyleGAN-2 improves upon StyleGAN-1, by using the style latent vector to transform the convolution layer's weights instead, thus solving the "blob" problem.<sup id="cite_ref-55" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-55">[55]</a></sup></p>
<p>This was updated by the StyleGAN-2-ADA ("ADA" stands for "adaptive"),<sup id="cite_ref-:4_52-2" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-:4-52">[52]</a></sup>&nbsp;which uses invertible data augmentation as described above. It also tunes the amount of data augmentation applied by starting at zero, and gradually increasing it until an "overfitting heuristic" reaches a target level, thus the name "adaptive".</p>
<h4><span id="StyleGAN-3" class="mw-headline">StyleGAN-3</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: StyleGAN-3" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=36">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>StyleGAN-3<sup id="cite_ref-56" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-56">[56]</a></sup>&nbsp;improves upon StyleGAN-2 by solving the "texture sticking" problem, which can be seen in the official videos.<sup id="cite_ref-57" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-57">[57]</a></sup>&nbsp;They analyzed the problem by the&nbsp;<a title="Nyquist&ndash;Shannon sampling theorem" href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquist&ndash;Shannon sampling theorem</a>, and argued that the layers in the generator learned to exploit the high-frequency signal in the pixels they operate upon.</p>
<p>To solve this, they proposed imposing strict&nbsp;<a title="Low-pass filter" href="https://en.wikipedia.org/wiki/Low-pass_filter">lowpass filters</a>&nbsp;between each generator's layers, so that the generator is forced to operate on the pixels in a way&nbsp;<a title="Faithful representation" href="https://en.wikipedia.org/wiki/Faithful_representation">faithful</a>&nbsp;to the continuous signals they represent, rather than operate on them as merely discrete signals. They further imposed rotational and translational invariance by using more&nbsp;<a title="Filter (signal processing)" href="https://en.wikipedia.org/wiki/Filter_(signal_processing)">signal filters</a>. The resulting StyleGAN-3 is able to solve the texture sticking problem, as well as generating images that rotate and translate smoothly.</p>
<h2><span id="Applications" class="mw-headline">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Applications" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=37">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>GAN applications have increased rapidly.<sup id="cite_ref-58" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-58">[58]</a></sup></p>
<h3><span id="Fashion.2C_art_and_advertising"></span><span id="Fashion,_art_and_advertising" class="mw-headline">Fashion, art and advertising</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Fashion, art and advertising" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=38">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>GANs can be used to generate art;&nbsp;<em><a title="The Verge" href="https://en.wikipedia.org/wiki/The_Verge">The Verge</a></em>&nbsp;wrote in March 2019 that "The images created by GANs have become the defining look of contemporary AI art."<sup id="cite_ref-59" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-59">[59]</a></sup>&nbsp;GANs can also be used to&nbsp;<a title="Inpainting" href="https://en.wikipedia.org/wiki/Inpainting">inpaint</a>&nbsp;photographs<sup id="cite_ref-60" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-60">[60]</a></sup>&nbsp;or create photos of imaginary fashion models, with no need to hire a model, photographer or makeup artist, or pay for a studio and transportation.<sup id="cite_ref-61" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-61">[61]</a></sup>&nbsp;GANs have also been used for virtual shadow generation.<sup id="cite_ref-62" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-62">[62]</a></sup></p>
<h3><span id="Interactive_Media" class="mw-headline">Interactive Media</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Interactive Media" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=39">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In 2020,&nbsp;<a title="Artbreeder" href="https://en.wikipedia.org/wiki/Artbreeder">Artbreeder</a>&nbsp;was used to create the main antagonist in the sequel to the psychological web horror series&nbsp;<em><a title="Ben Drowned" href="https://en.wikipedia.org/wiki/Ben_Drowned">Ben Drowned</a></em>. The author would later go on to praise GAN applications for their ability to help generate assets for independent artists who are short on budget and manpower.<sup id="cite_ref-63" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-63">[63]</a></sup><sup id="cite_ref-64" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-64">[64]</a></sup></p>
<h3><span id="Science" class="mw-headline">Science</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Science" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=40">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>GANs can&nbsp;<a class="mw-redirect" title="Image restoration" href="https://en.wikipedia.org/wiki/Image_restoration">improve</a>&nbsp;<a title="Astrophotography" href="https://en.wikipedia.org/wiki/Astrophotography">astronomical images</a><sup id="cite_ref-65" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-65">[65]</a></sup>&nbsp;and simulate&nbsp;<a title="Gravitational lens" href="https://en.wikipedia.org/wiki/Gravitational_lens">gravitational lensing</a>&nbsp;for dark matter research.<sup id="cite_ref-66" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-66">[66]</a></sup><sup id="cite_ref-67" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-67">[67]</a></sup><sup id="cite_ref-68" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-68">[68]</a></sup>&nbsp;They were used in 2019 to successfully model the distribution of&nbsp;<a title="Dark matter" href="https://en.wikipedia.org/wiki/Dark_matter">dark matter</a>&nbsp;in a particular direction in space and to predict the gravitational lensing that will occur.<sup id="cite_ref-69" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-69">[69]</a></sup><sup id="cite_ref-70" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-70">[70]</a></sup></p>
<p>GANs have been proposed as a fast and accurate way of modeling high energy jet formation<sup id="cite_ref-71" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-71">[71]</a></sup>&nbsp;and modeling&nbsp;<a title="Particle shower" href="https://en.wikipedia.org/wiki/Particle_shower">showers</a>&nbsp;through&nbsp;<a title="Calorimeter (particle physics)" href="https://en.wikipedia.org/wiki/Calorimeter_(particle_physics)">calorimeters</a>&nbsp;of&nbsp;<a title="Particle physics" href="https://en.wikipedia.org/wiki/Particle_physics">high-energy physics</a>&nbsp;experiments.<sup id="cite_ref-72" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-72">[72]</a></sup><sup id="cite_ref-73" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-73">[73]</a></sup><sup id="cite_ref-74" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-74">[74]</a></sup><sup id="cite_ref-75" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-75">[75]</a></sup>&nbsp;GANs have also been trained to accurately approximate bottlenecks in computationally expensive simulations of particle physics experiments. Applications in the context of present and proposed&nbsp;<a title="CERN" href="https://en.wikipedia.org/wiki/CERN">CERN</a>&nbsp;experiments have demonstrated the potential of these methods for accelerating simulation and/or improving simulation fidelity.<sup id="cite_ref-76" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-76">[76]</a></sup><sup id="cite_ref-77" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-77">[77]</a></sup></p>
<h3><span id="Video_games" class="mw-headline">Video games</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Video games" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=41">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In 2018, GANs reached the&nbsp;<a class="mw-redirect" title="Mod (video gaming)" href="https://en.wikipedia.org/wiki/Mod_(video_gaming)">video game modding</a>&nbsp;community, as a method of&nbsp;<a title="Image scaling" href="https://en.wikipedia.org/wiki/Image_scaling">up-scaling</a>&nbsp;low-resolution 2D textures in old video games by recreating them in&nbsp;<a title="4K resolution" href="https://en.wikipedia.org/wiki/4K_resolution">4k</a>&nbsp;or higher resolutions via image training, and then down-sampling them to fit the game's native resolution (with results resembling the&nbsp;<a title="Supersampling" href="https://en.wikipedia.org/wiki/Supersampling">supersampling</a>&nbsp;method of&nbsp;<a title="Spatial anti-aliasing" href="https://en.wikipedia.org/wiki/Spatial_anti-aliasing">anti-aliasing</a>).<sup id="cite_ref-78" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-78">[78]</a></sup>&nbsp;With proper training, GANs provide a clearer and sharper 2D texture image magnitudes higher in quality than the original, while fully retaining the original's level of details, colors, etc. Known examples of extensive GAN usage include&nbsp;<em><a title="Final Fantasy VIII" href="https://en.wikipedia.org/wiki/Final_Fantasy_VIII">Final Fantasy VIII</a></em>,&nbsp;<em><a title="Final Fantasy IX" href="https://en.wikipedia.org/wiki/Final_Fantasy_IX">Final Fantasy IX</a></em>,&nbsp;<em><a title="Resident Evil (2002 video game)" href="https://en.wikipedia.org/wiki/Resident_Evil_(2002_video_game)">Resident Evil REmake</a></em>&nbsp;HD Remaster, and&nbsp;<em><a title="Max Payne" href="https://en.wikipedia.org/wiki/Max_Payne">Max Payne</a></em>.<sup class="noprint Inline-Template Template-Fact">[<em><a title="Wikipedia:Citation needed" href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed"><span title="This claim needs references to reliable sources. (January 2020)">citation needed</span></a></em>]</sup></p>
<h2><span id="AI_generated_video" class="mw-headline">AI generated video</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: AI generated video" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=42">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p><a title="Artificial intelligence art" href="https://en.wikipedia.org/wiki/Artificial_intelligence_art">Artificial intelligence art</a>&nbsp;for video uses AI to generate video from text as&nbsp;<a class="mw-redirect" title="Text-to-Video model" href="https://en.wikipedia.org/wiki/Text-to-Video_model">Text-to-Video model</a><sup id="cite_ref-79" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-79">[79]</a></sup></p>
<h3><span id="Audio_synthesis" class="mw-headline">Audio synthesis</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Audio synthesis" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=43">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="excerpt-block">
<div class="hatnote navigation-not-searchable dablink excerpt-hat selfref">This section is an excerpt from&nbsp;<a title="Generative audio" href="https://en.wikipedia.org/wiki/Generative_audio">Generative audio</a>.<span class="mw-editsection-like plainlinks"><span class="mw-editsection-bracket">[</span><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Generative_audio&amp;action=edit">edit</a><span class="mw-editsection-bracket">]</span></span></div>
<div class="excerpt">
<p><a title="Generative audio" href="https://en.wikipedia.org/wiki/Generative_audio">Generative audio</a>&nbsp;refers to the creation of&nbsp;<a title="Digital audio" href="https://en.wikipedia.org/wiki/Digital_audio">audio</a>&nbsp;files from databases of&nbsp;<a class="mw-redirect" title="Audio clips" href="https://en.wikipedia.org/wiki/Audio_clips">audio clips</a>. This technology differs from&nbsp;<a title="Speech synthesis" href="https://en.wikipedia.org/wiki/Speech_synthesis">AI voices</a>&nbsp;such as Apple's&nbsp;<a title="Siri" href="https://en.wikipedia.org/wiki/Siri">Siri</a>&nbsp;or Amazon's&nbsp;<a title="Amazon Alexa" href="https://en.wikipedia.org/wiki/Amazon_Alexa">Alexa</a>, which use a collection of fragments that are stitched together on demand.</p>
<figure class="mw-default-size"><a class="mw-file-description" href="https://en.wikipedia.org/wiki/File:Audio_curves_graph.png"><img class="mw-file-element" src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Audio_curves_graph.png/220px-Audio_curves_graph.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Audio_curves_graph.png/330px-Audio_curves_graph.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/72/Audio_curves_graph.png/440px-Audio_curves_graph.png 2x" alt="" width="220" height="193" data-file-width="624" data-file-height="547" /></a>
<figcaption>Audio curves</figcaption>
</figure>
Generative audio works by using neural networks to learn the statistical properties of an audio source, then reproduces those properties.<sup id="cite_ref-80" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-80">[80]</a></sup></div>
</div>
<h3><span id="Concerns_about_malicious_applications" class="mw-headline">Concerns about malicious applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Concerns about malicious applications" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=44">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="hatnote navigation-not-searchable">Main article:&nbsp;<a title="Deepfake" href="https://en.wikipedia.org/wiki/Deepfake">Deepfake</a></div>
<figure class="mw-default-size"><a class="mw-file-description" href="https://en.wikipedia.org/wiki/File:Woman_1.jpg"><img class="mw-file-element" src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Woman_1.jpg/220px-Woman_1.jpg" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Woman_1.jpg/330px-Woman_1.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Woman_1.jpg/440px-Woman_1.jpg 2x" alt="" width="220" height="220" data-file-width="1024" data-file-height="1024" /></a>
<figcaption>An image generated by a&nbsp;<a title="StyleGAN" href="https://en.wikipedia.org/wiki/StyleGAN">StyleGAN</a>&nbsp;that looks deceptively like a photograph of a real person. This image was generated by a StyleGAN based on an analysis of portraits.</figcaption>
</figure>
<figure class="mw-default-size"><a class="mw-file-description" href="https://en.wikipedia.org/wiki/File:GAN_deepfake_white_girl.jpg"><img class="mw-file-element" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/GAN_deepfake_white_girl.jpg/220px-GAN_deepfake_white_girl.jpg" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/a/a5/GAN_deepfake_white_girl.jpg/330px-GAN_deepfake_white_girl.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a5/GAN_deepfake_white_girl.jpg/440px-GAN_deepfake_white_girl.jpg 2x" alt="" width="220" height="220" data-file-width="1024" data-file-height="1024" /></a>
<figcaption>Another example of a GAN generated portrait</figcaption>
</figure>
<p>Concerns have been raised about the potential use of GAN-based&nbsp;<a title="Human image synthesis" href="https://en.wikipedia.org/wiki/Human_image_synthesis">human image synthesis</a>&nbsp;for sinister purposes, e.g., to produce fake, possibly incriminating, photographs and videos.<sup id="cite_ref-TPDNEwuaitcryhf|_81-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-TPDNEwuaitcryhf|-81">[81]</a></sup>&nbsp;GANs can be used to generate unique, realistic profile photos of people who do not exist, in order to automate creation of fake social media profiles.<sup id="cite_ref-82" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-82">[82]</a></sup></p>
<p>In 2019 the state of California considered<sup id="cite_ref-83" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-83">[83]</a></sup>&nbsp;and passed on October 3, 2019, the&nbsp;<a class="external text" href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB602" rel="nofollow">bill AB-602</a>, which bans the use of human image synthesis technologies to make fake pornography without the consent of the people depicted, and&nbsp;<a class="external text" href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB730" rel="nofollow">bill AB-730</a>, which prohibits distribution of manipulated videos of a political candidate within 60 days of an election. Both bills were authored by Assembly member&nbsp;<a title="Marc Berman" href="https://en.wikipedia.org/wiki/Marc_Berman">Marc Berman</a>&nbsp;and signed by Governor&nbsp;<a title="Gavin Newsom" href="https://en.wikipedia.org/wiki/Gavin_Newsom">Gavin Newsom</a>. The laws went into effect in 2020.<sup id="cite_ref-CNET2019_84-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-CNET2019-84">[84]</a></sup></p>
<p>DARPA's Media Forensics program studies ways to counteract fake media, including fake media produced using GANs.<sup id="cite_ref-85" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-85">[85]</a></sup></p>
<h3><span id="Transfer_learning" class="mw-headline">Transfer learning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Transfer learning" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=45">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>State-of-art&nbsp;<a title="Transfer learning" href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a>&nbsp;research use GANs to enforce the alignment of the latent feature space, such as in deep reinforcement learning.<sup id="cite_ref-86" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-86">[86]</a></sup>&nbsp;This works by feeding the embeddings of the source and target task to the discriminator which tries to guess the context. The resulting loss is then (inversely) backpropagated through the encoder.</p>
<h3><span id="Miscellaneous_applications" class="mw-headline">Miscellaneous applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: Miscellaneous applications" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=46">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>GAN can be used to detect glaucomatous images helping the early diagnosis which is essential to avoid partial or total loss of vision.<sup id="cite_ref-87" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-87">[87]</a></sup></p>
<p>GANs that produce&nbsp;<a class="mw-redirect" title="Photorealistic rendering" href="https://en.wikipedia.org/wiki/Photorealistic_rendering">photorealistic</a>&nbsp;images can be used to visualize&nbsp;<a title="Interior design" href="https://en.wikipedia.org/wiki/Interior_design">interior design</a>,&nbsp;<a title="Industrial design" href="https://en.wikipedia.org/wiki/Industrial_design">industrial design</a>, shoes,<sup id="cite_ref-88" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-88">[88]</a></sup>&nbsp;bags, and&nbsp;<a title="Clothing" href="https://en.wikipedia.org/wiki/Clothing">clothing</a>&nbsp;items or items for&nbsp;<a title="PC game" href="https://en.wikipedia.org/wiki/PC_game">computer games</a>' scenes.<sup class="noprint Inline-Template Template-Fact">[<em><a title="Wikipedia:Citation needed" href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed"><span title="No source provided. How does a GAN do this? (February 2018)">citation needed</span></a></em>]</sup>&nbsp;Such networks were reported to be used by&nbsp;<a title="Facebook" href="https://en.wikipedia.org/wiki/Facebook">Facebook</a>.<sup id="cite_ref-89" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-89">[89]</a></sup></p>
<p>GANs have been used to create&nbsp;<a title="Forensic facial reconstruction" href="https://en.wikipedia.org/wiki/Forensic_facial_reconstruction">forensic facial reconstructions</a>&nbsp;of deceased historical figures.<sup id="cite_ref-90" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-90">[90]</a></sup></p>
<p>GANs can&nbsp;<a title="3D reconstruction from multiple images" href="https://en.wikipedia.org/wiki/3D_reconstruction_from_multiple_images">reconstruct 3D models of objects from images</a>,<sup id="cite_ref-91" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-91">[91]</a></sup>&nbsp;generate novel objects as 3D point clouds,<sup id="cite_ref-92" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-92">[92]</a></sup>&nbsp;and model patterns of motion in video.<sup id="cite_ref-93" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-93">[93]</a></sup></p>
<p>GANs can be used to age face photographs to show how an individual's appearance might change with age.<sup id="cite_ref-94" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-94">[94]</a></sup></p>
<p>GANs can also be used to inpaint missing features in maps, transfer map styles in cartography<sup id="cite_ref-95" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-95">[95]</a></sup>&nbsp;or augment street view imagery.<sup id="cite_ref-96" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-96">[96]</a></sup></p>
<p>Relevance feedback on GANs can be used to generate images and replace image search systems.<sup id="cite_ref-97" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-97">[97]</a></sup></p>
<p>A variation of the GANs is used in training a network to generate optimal control inputs to nonlinear&nbsp;<a title="Dynamical system" href="https://en.wikipedia.org/wiki/Dynamical_system">dynamical systems</a>. Where the discriminatory network is known as a critic that checks the optimality of the solution and the generative network is known as an Adaptive network that generates the optimal control. The critic and adaptive network train each other to approximate a nonlinear optimal control.<sup id="cite_ref-98" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-98">[98]</a></sup></p>
<p>GANs have been used to visualize the effect that climate change will have on specific houses.<sup id="cite_ref-99" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-99">[99]</a></sup></p>
<p>A GAN model called Speech2Face can reconstruct an image of a person's face after listening to their voice.<sup id="cite_ref-100" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-100">[100]</a></sup></p>
<p>In 2016 GANs were used to generate new molecules for a variety of protein targets implicated in cancer, inflammation, and fibrosis. In 2019 GAN-generated molecules were validated experimentally all the way into mice.<sup id="cite_ref-101" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-101">[101]</a></sup><sup id="cite_ref-102" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-102">[102]</a></sup></p>
<p>Whereas the majority of GAN applications are in image processing, the work has also been done with time-series data. For example, recurrent GANs (R-GANs) have been used to generate energy data for machine learning.<sup id="cite_ref-103" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-103">[103]</a></sup></p>
<h2><span id="History" class="mw-headline">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: History" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=47">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In 1991,&nbsp;<a class="mw-redirect" title="Juergen Schmidhuber" href="https://en.wikipedia.org/wiki/Juergen_Schmidhuber">Juergen Schmidhuber</a>&nbsp;published generative and adversarial&nbsp;<a title="Neural network" href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>&nbsp;that contest with each other in the form of a&nbsp;<a title="Zero-sum game" href="https://en.wikipedia.org/wiki/Zero-sum_game">zero-sum game</a>, where one network's gain is the other network's loss.<sup id="cite_ref-curiosity1991_104-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-curiosity1991-104">[104]</a></sup><sup id="cite_ref-fun2010_105-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-fun2010-105">[105]</a></sup><sup id="cite_ref-gancurpm2020_106-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-gancurpm2020-106">[106]</a></sup>&nbsp;The first network is a&nbsp;<a title="Generative model" href="https://en.wikipedia.org/wiki/Generative_model">generative model</a>&nbsp;with&nbsp;<a class="mw-redirect" title="Stochasticity" href="https://en.wikipedia.org/wiki/Stochasticity">stochasticity</a>&nbsp;that models a&nbsp;<a title="Probability distribution" href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a>&nbsp;over output patterns. The second network learns by&nbsp;<a title="Gradient descent" href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>&nbsp;to predict the reactions of the environment to these patterns. This was called "artificial curiosity." For modern GANs (2014),<sup id="cite_ref-GANnips_3-9" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-GANnips-3">[3]</a></sup>&nbsp;the environmental reaction is 1 or 0 depending on whether the first network's output is in a given set.<sup id="cite_ref-gancurpm2020_106-1" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-gancurpm2020-106">[106]</a></sup></p>
<p>Other people had similar ideas but did not develop them similarly. An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo.<sup id="cite_ref-olli2010_107-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-olli2010-107">[107]</a></sup>&nbsp;This idea was never implemented and did not involve&nbsp;<a class="mw-redirect" title="Stochasticity" href="https://en.wikipedia.org/wiki/Stochasticity">stochasticity</a>&nbsp;in the generator and thus was not a generative model. It is now known as a conditional GAN or cGAN.<sup id="cite_ref-reddit3_108-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-reddit3-108">[108]</a></sup>&nbsp;An idea similar to GANs was used to model animal behavior by Li, Gauci and Gross in 2013.<sup id="cite_ref-Li-etal-GECCO2013_109-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-Li-etal-GECCO2013-109">[109]</a></sup></p>
<p>Another inspiration for GANs was noise-contrastive estimation,<sup id="cite_ref-110" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-110">[110]</a></sup>&nbsp;which uses the same loss function as GANs and which Goodfellow studied during his PhD in 2010&ndash;2014.</p>
<p><a title="Adversarial machine learning" href="https://en.wikipedia.org/wiki/Adversarial_machine_learning">Adversarial machine learning</a>&nbsp;has other uses besides generative modeling and can be applied to models other than neural networks. In control theory, adversarial learning based on neural networks was used in 2006 to train robust controllers in a game theoretic sense, by alternating the iterations between a minimizer policy, the controller, and a maximizer policy, the disturbance.<sup id="cite_ref-111" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-111">[111]</a></sup><sup id="cite_ref-112" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-112">[112]</a></sup></p>
<p>In 2017, a GAN was used for image enhancement focusing on realistic textures rather than pixel-accuracy, producing a higher image quality at high magnification.<sup id="cite_ref-113" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-113">[113]</a></sup>&nbsp;In 2017, the first faces were generated.<sup id="cite_ref-114" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-114">[114]</a></sup>&nbsp;These were exhibited in February 2018 at the Grand Palais.<sup id="cite_ref-115" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-115">[115]</a></sup><sup id="cite_ref-116" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-116">[116]</a></sup>&nbsp;Faces generated by&nbsp;<a title="StyleGAN" href="https://en.wikipedia.org/wiki/StyleGAN">StyleGAN</a><sup id="cite_ref-117" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-117">[117]</a></sup>&nbsp;in 2019 drew comparisons with&nbsp;<a title="Deepfake" href="https://en.wikipedia.org/wiki/Deepfake">Deepfakes</a>.<sup id="cite_ref-TPDNEitboowo2019_118-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-TPDNEitboowo2019-118">[118]</a></sup><sup id="cite_ref-TPDNE_119-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-TPDNE-119">[119]</a></sup><sup id="cite_ref-Style-based_GANs_&ndash;_Generating_and_Tuning_Realistic_Artificial_Faces_120-0" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-Style-based_GANs_%E2%80%93_Generating_and_Tuning_Realistic_Artificial_Faces-120">[120]</a></sup></p>
<p>Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a "CAN", for "creative adversarial network".<sup id="cite_ref-121" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-121">[121]</a></sup>&nbsp;A GAN system was used to create the 2018 painting&nbsp;<em><a title="Edmond de Belamy" href="https://en.wikipedia.org/wiki/Edmond_de_Belamy">Edmond de Belamy</a>,</em>&nbsp;which sold for US$432,500.<sup id="cite_ref-122" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-122">[122]</a></sup>&nbsp;An early 2019 article by members of the original CAN team discussed further progress with that system, and gave consideration as well to the overall prospects for an AI-enabled art.<sup id="cite_ref-123" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-123">[123]</a></sup></p>
<p>In May 2019, researchers at Samsung demonstrated a GAN-based system that produces videos of a person speaking, given only a single photo of that person.<sup id="cite_ref-124" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-124">[124]</a></sup></p>
<p>In August 2019, a large dataset consisting of 12,197 MIDI songs each with paired lyrics and melody alignment was created for neural melody generation from lyrics using conditional GAN-LSTM (refer to sources at GitHub&nbsp;<a class="external text" href="https://github.com/yy1lab/Lyrics-Conditioned-Neural-Melody-Generation" rel="nofollow">AI Melody Generation from Lyrics</a>).<sup id="cite_ref-125" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-125">[125]</a></sup></p>
<p>In May 2020,&nbsp;<a title="Nvidia" href="https://en.wikipedia.org/wiki/Nvidia">Nvidia</a>&nbsp;researchers taught an AI system (termed "GameGAN") to recreate the game of&nbsp;<em><a title="Pac-Man" href="https://en.wikipedia.org/wiki/Pac-Man">Pac-Man</a></em>&nbsp;simply by watching it being played.<sup id="cite_ref-126" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-126">[126]</a></sup><sup id="cite_ref-127" class="reference"><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_note-127">[127]</a></sup></p>
<h2><span id="References" class="mw-headline">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: References" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=48">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist">
<div class="mw-references-wrap mw-references-columns">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-1">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://pub.towardsai.net/generative-ai-and-future-c3b1695876f2" rel="nofollow">"Generative AI and Future"</a>. November 15, 2022.</cite></span></li>
<li id="cite_note-2"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-2">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://www.computer.org/csdl/magazine/co/2022/10/09903869/1H0G6xvtREk" rel="nofollow">"CSDL | IEEE Computer Society"</a>.</cite></span></li>
<li id="cite_note-GANnips-3"><span class="mw-cite-backlink">^&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-0"><span class="cite-accessibility-label">Jump up to:</span><sup><em><strong>a</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-1"><sup><em><strong>b</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-2"><sup><em><strong>c</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-3"><sup><em><strong>d</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-4"><sup><em><strong>e</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-5"><sup><em><strong>f</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-6"><sup><em><strong>g</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-7"><sup><em><strong>h</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-8"><sup><em><strong>i</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-GANnips_3-9"><sup><em><strong>j</strong></em></sup></a></span>&nbsp;<span class="reference-text"><cite id="CITEREFGoodfellowPouget-AbadieMirzaXu2014" class="citation conference cs1">Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014).&nbsp;<a class="external text" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="nofollow"><em>Generative Adversarial Nets</em></a>&nbsp;<span class="cs1-format">(PDF)</span>. Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp.&nbsp;2672&ndash;2680.</cite></span></li>
<li id="cite_note-tomczak2020-4"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-tomczak2020_4-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFTomczak2022" class="citation book cs1">Tomczak, Jakub (2022).&nbsp;<a class="external text" href="https://link.springer.com/book/10.1007/978-3-030-93158-2" rel="nofollow"><em>Deep Generative Modeling</em></a>. Cham: Springer. p.&nbsp;197.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2F978-3-030-93158-2" rel="nofollow">10.1007/978-3-030-93158-2</a>.&nbsp;<a class="mw-redirect" title="ISBN (identifier)" href="https://en.wikipedia.org/wiki/ISBN_(identifier)">ISBN</a>&nbsp;<a title="Special:BookSources/978-3-030-93157-5" href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-030-93157-5"><bdi>978-3-030-93157-5</bdi></a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:246946335" rel="nofollow">246946335</a>.</cite></span></li>
<li id="cite_note-ITT_GANs-5"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-ITT_GANs_5-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFSalimansGoodfellowZarembaCheung2016" class="citation arxiv cs1">Salimans, Tim; Goodfellow, Ian; Zaremba, Wojciech; Cheung, Vicki; Radford, Alec; Chen, Xi (2016). "Improved Techniques for Training GANs".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1606.03498" rel="nofollow">1606.03498</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-6"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-6">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFIsolaZhuZhouEfros2017" class="citation journal cs1">Isola, Phillip; Zhu, Jun-Yan; Zhou, Tinghui; Efros, Alexei (2017).&nbsp;<a class="external text" href="https://phillipi.github.io/pix2pix/" rel="nofollow">"Image-to-Image Translation with Conditional Adversarial Nets"</a>.&nbsp;<em>Computer Vision and Pattern Recognition</em>.</cite></span></li>
<li id="cite_note-7"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-7">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFHoErmon2016" class="citation journal cs1">Ho, Jonathon; Ermon, Stefano (2016).&nbsp;<a class="external text" href="http://papers.nips.cc/paper/6391-generative-adversarial-imitation-learning" rel="nofollow">"Generative Adversarial Imitation Learning"</a>.&nbsp;<em>Advances in Neural Information Processing Systems</em>.&nbsp;<strong>29</strong>: 4565&ndash;4573.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1606.03476" rel="nofollow">1606.03476</a></span>.</cite></span></li>
<li id="cite_note-8"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-8">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://theaisummer.com/gan-computer-vision/#vanilla-gan-generative-adversarial-networks-2014" rel="nofollow">"Vanilla GAN (GANs in computer vision: Introduction to generative learning)"</a>.&nbsp;<em>theaisummer.com</em>. AI Summer. April 10, 2020.&nbsp;<a class="external text" href="https://web.archive.org/web/20200603130655/https://theaisummer.com/gan-computer-vision/" rel="nofollow">Archived</a>&nbsp;from the original on June 3, 2020<span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">September 20,</span>&nbsp;2020</span>.</cite></span></li>
<li id="cite_note-9"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-9">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFLucCouprieChintalaVerbeek2016" class="citation journal cs1">Luc, Pauline; Couprie, Camille; Chintala, Soumith; Verbeek, Jakob (November 25, 2016). "Semantic Segmentation using Adversarial Networks".&nbsp;<em>NIPS Workshop on Adversarial Training, Dec, Barcelona, Spain</em>.&nbsp;<strong>2016</strong>.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1611.08408" rel="nofollow">1611.08408</a></span>.</cite></span></li>
<li id="cite_note-OpenAI_com-10"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-OpenAI_com_10-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFAndrej_KarpathyPieter_AbbeelGreg_BrockmanPeter_Chen" class="citation cs2"><a title="Andrej Karpathy" href="https://en.wikipedia.org/wiki/Andrej_Karpathy">Andrej Karpathy</a>;&nbsp;<a title="Pieter Abbeel" href="https://en.wikipedia.org/wiki/Pieter_Abbeel">Pieter Abbeel</a>; Greg Brockman; Peter Chen; Vicki Cheung; Rocky Duan; Ian Goodfellow; Durk Kingma; Jonathan Ho; Rein Houthooft; Tim Salimans; John Schulman; Ilya Sutskever; Wojciech Zaremba,&nbsp;<a class="external text" href="https://openai.com/blog/generative-models/" rel="nofollow"><em>Generative Models</em></a>,&nbsp;<a title="OpenAI" href="https://en.wikipedia.org/wiki/OpenAI">OpenAI</a><span class="reference-accessdate">, retrieved&nbsp;<span class="nowrap">April 7,</span>&nbsp;2016</span></cite></span></li>
<li id="cite_note-11"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-11">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFMohamedLakshminarayanan2016" class="citation arxiv cs1">Mohamed, Shakir; Lakshminarayanan, Balaji (2016). "Learning in Implicit Generative Models".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1610.03483" rel="nofollow">1610.03483</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/stat.ML" rel="nofollow">stat.ML</a>].</cite></span></li>
<li id="cite_note-:5-12"><span class="mw-cite-backlink">^&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:5_12-0"><span class="cite-accessibility-label">Jump up to:</span><sup><em><strong>a</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:5_12-1"><sup><em><strong>b</strong></em></sup></a></span>&nbsp;<span class="reference-text"><cite id="CITEREFGoodfellow2017" class="citation arxiv cs1">Goodfellow, Ian (April 3, 2017). "NIPS 2016 Tutorial: Generative Adversarial Networks".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1701.00160" rel="nofollow">1701.00160</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-13"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-13">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKingmaWelling2014" class="citation arxiv cs1">Kingma, Diederik P.; Welling, Max (May 1, 2014). "Auto-Encoding Variational Bayes".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1312.6114" rel="nofollow">1312.6114</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/stat.ML" rel="nofollow">stat.ML</a>].</cite></span></li>
<li id="cite_note-14"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-14">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFRezendeMohamedWierstra2014" class="citation journal cs1">Rezende, Danilo Jimenez; Mohamed, Shakir; Wierstra, Daan (June 18, 2014).&nbsp;<a class="external text" href="https://proceedings.mlr.press/v32/rezende14.html" rel="nofollow">"Stochastic Backpropagation and Approximate Inference in Deep Generative Models"</a>.&nbsp;<em>International Conference on Machine Learning</em>. PMLR: 1278&ndash;1286.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1401.4082" rel="nofollow">1401.4082</a></span>.</cite></span></li>
<li id="cite_note-:2-15"><span class="mw-cite-backlink">^&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:2_15-0"><span class="cite-accessibility-label">Jump up to:</span><sup><em><strong>a</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:2_15-1"><sup><em><strong>b</strong></em></sup></a></span>&nbsp;<span class="reference-text"><cite id="CITEREFFarniaOzdaglar2020" class="citation journal cs1">Farnia, Farzan; Ozdaglar, Asuman (November 21, 2020).&nbsp;<a class="external text" href="https://proceedings.mlr.press/v119/farnia20a.html" rel="nofollow">"Do GANs always have Nash equilibria?"</a>.&nbsp;<em>International Conference on Machine Learning</em>. PMLR: 3029&ndash;3039.</cite></span></li>
<li id="cite_note-:3-16"><span class="mw-cite-backlink">^&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:3_16-0"><span class="cite-accessibility-label">Jump up to:</span><sup><em><strong>a</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:3_16-1"><sup><em><strong>b</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:3_16-2"><sup><em><strong>c</strong></em></sup></a></span>&nbsp;<span class="reference-text"><cite id="CITEREFWeng2019" class="citation arxiv cs1">Weng, Lilian (April 18, 2019). "From GAN to WGAN".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1904.08994" rel="nofollow">1904.08994</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-:1-17"><span class="mw-cite-backlink">^&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:1_17-0"><span class="cite-accessibility-label">Jump up to:</span><sup><em><strong>a</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:1_17-1"><sup><em><strong>b</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:1_17-2"><sup><em><strong>c</strong></em></sup></a></span>&nbsp;<span class="reference-text"><cite id="CITEREFKarrasAilaLaineLehtinen2017" class="citation arxiv cs1">Karras, Tero; Aila, Timo; Laine, Samuli; Lehtinen, Jaakko (October 1, 2017). "Progressive Growing of GANs for Improved Quality, Stability, and Variation".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1710.10196" rel="nofollow">1710.10196</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.NE" rel="nofollow">cs.NE</a>].</cite></span></li>
<li id="cite_note-18"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-18">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFSovianyArdeiIonescuLeordeanu2019" class="citation arxiv cs1">Soviany, Petru; Ardei, Claudiu; Ionescu, Radu Tudor; Leordeanu, Marius (October 22, 2019). "Image Difficulty Curriculum for Generative Adversarial Networks (CuGAN)".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1910.08967" rel="nofollow">1910.08967</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-19"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-19">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFHacohenWeinshall2019" class="citation journal cs1">Hacohen, Guy; Weinshall, Daphna (May 24, 2019).&nbsp;<a class="external text" href="https://proceedings.mlr.press/v97/hacohen19a.html" rel="nofollow">"On The Power of Curriculum Learning in Training Deep Networks"</a>.&nbsp;<em>International Conference on Machine Learning</em>. PMLR: 2535&ndash;2544.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1904.03626" rel="nofollow">1904.03626</a></span>.</cite></span></li>
<li id="cite_note-20"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-20">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://www.reddit.com/r/MachineLearning/comments/5qxoaz/comment/dd4041v/?context=3" rel="nofollow">"r/MachineLearning - Comment by u/ian_goodfellow on "[R] [1701.07875] Wasserstein GAN"</a>.&nbsp;<em>reddit</em>. January 30, 2017<span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">July 15,</span>&nbsp;2022</span>.</cite></span></li>
<li id="cite_note-21"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-21">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFLinKhetanFantiOh2018" class="citation conference cs1">Lin, Zinan; et&nbsp;al. (December 2018).&nbsp;<a class="external text" href="https://dl.acm.org/doi/10.5555/3326943.3327081" rel="nofollow"><em>PacGAN: the power of two samples in generative adversarial networks</em></a>. 32nd International Conference on Neural Information Processing Systems. pp.&nbsp;1505&ndash;1514.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1712.04086" rel="nofollow">1712.04086</a></span>.</cite></span></li>
<li id="cite_note-22"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-22">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFMeschederGeigerNowozin2018" class="citation arxiv cs1">Mescheder, Lars; Geiger, Andreas; Nowozin, Sebastian (July 31, 2018). "Which Training Methods for GANs do actually Converge?".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1801.04406" rel="nofollow">1801.04406</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-:0-23"><span class="mw-cite-backlink">^&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:0_23-0"><span class="cite-accessibility-label">Jump up to:</span><sup><em><strong>a</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:0_23-1"><sup><em><strong>b</strong></em></sup></a></span>&nbsp;<span class="reference-text"><cite id="CITEREFBrockDonahueSimonyan2018" class="citation conference cs1">Brock, Andrew; Donahue, Jeff; Simonyan, Karen (September 1, 2018).&nbsp;<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018arXiv180911096B" rel="nofollow"><em>Large Scale GAN Training for High Fidelity Natural Image Synthesis</em></a>. International Conference on Learning Representations 2019.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1809.11096" rel="nofollow">1809.11096</a></span>.</cite></span></li>
<li id="cite_note-24"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-24">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFHeuselRamsauerUnterthinerNessler2017" class="citation journal cs1">Heusel, Martin; Ramsauer, Hubert; Unterthiner, Thomas; Nessler, Bernhard; Hochreiter, Sepp (2017).&nbsp;<a class="external text" href="https://proceedings.neurips.cc/paper/2017/hash/8a1d694707eb0fefe65871369074926d-Abstract.html" rel="nofollow">"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"</a>.&nbsp;<em>Advances in Neural Information Processing Systems</em>. Curran Associates, Inc.&nbsp;<strong>30</strong>.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1706.08500" rel="nofollow">1706.08500</a></span>.</cite></span></li>
<li id="cite_note-25"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-25">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKingmaBa2017" class="citation arxiv cs1">Kingma, Diederik P.; Ba, Jimmy (January 29, 2017). "Adam: A Method for Stochastic Optimization".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1412.6980" rel="nofollow">1412.6980</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-26"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-26">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFZhangIsolaEfrosShechtman2018" class="citation arxiv cs1">Zhang, Richard; Isola, Phillip; Efros, Alexei A.; Shechtman, Eli; Wang, Oliver (2018). "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric". pp.&nbsp;586&ndash;595.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1801.03924" rel="nofollow">1801.03924</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite></span></li>
<li id="cite_note-27"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-27">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFBorji2019" class="citation journal cs1">Borji, Ali (February 1, 2019).&nbsp;<a class="external text" href="https://www.sciencedirect.com/science/article/pii/S1077314218304272" rel="nofollow">"Pros and cons of GAN evaluation measures"</a>.&nbsp;<em>Computer Vision and Image Understanding</em>.&nbsp;<strong>179</strong>: 41&ndash;65.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1802.03446" rel="nofollow">1802.03446</a></span>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.cviu.2018.10.009" rel="nofollow">10.1016/j.cviu.2018.10.009</a>.&nbsp;<a class="mw-redirect" title="ISSN (identifier)" href="https://en.wikipedia.org/wiki/ISSN_(identifier)">ISSN</a>&nbsp;<a class="external text" href="https://www.worldcat.org/issn/1077-3142" rel="nofollow">1077-3142</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:3627712" rel="nofollow">3627712</a>.</cite></span></li>
<li id="cite_note-28"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-28">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFHindupur2022" class="citation cs2">Hindupur, Avinash (July 15, 2022),&nbsp;<a class="external text" href="https://github.com/hindupuravinash/the-gan-zoo" rel="nofollow"><em>The GAN Zoo</em></a><span class="reference-accessdate">, retrieved&nbsp;<span class="nowrap">July 15,</span>&nbsp;2022</span></cite></span></li>
<li id="cite_note-29"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-29">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFOdenaOlahShlens2017" class="citation journal cs1">Odena, Augustus; Olah, Christopher; Shlens, Jonathon (July 17, 2017).&nbsp;<a class="external text" href="https://proceedings.mlr.press/v70/odena17a.html" rel="nofollow">"Conditional Image Synthesis with Auxiliary Classifier GANs"</a>.&nbsp;<em>International Conference on Machine Learning</em>. PMLR: 2642&ndash;2651.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1610.09585" rel="nofollow">1610.09585</a></span>.</cite></span></li>
<li id="cite_note-30"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-30">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFRadfordMetzChintala2016" class="citation journal cs1">Radford, Alec; Metz, Luke; Chintala, Soumith (2016).&nbsp;<a class="external text" href="https://www.semanticscholar.org/paper/Unsupervised-Representation-Learning-with-Deep-Radford-Metz/8388f1be26329fa45e5807e968a641ce170ea078" rel="nofollow">"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"</a>.&nbsp;<em>ICLR</em>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:11758569" rel="nofollow">11758569</a>.</cite></span></li>
<li id="cite_note-31"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-31">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFLongShelhamerDarrell2015" class="citation journal cs1">Long, Jonathan; Shelhamer, Evan; Darrell, Trevor (2015).&nbsp;<a class="external text" href="https://openaccess.thecvf.com/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html" rel="nofollow">"Fully Convolutional Networks for Semantic Segmentation"</a>.&nbsp;<em>CVF</em>: 3431&ndash;3440.</cite></span></li>
<li id="cite_note-32"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-32">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFZhangGoodfellowMetaxasOdena2019" class="citation journal cs1">Zhang, Han; Goodfellow, Ian; Metaxas, Dimitris; Odena, Augustus (May 24, 2019).&nbsp;<a class="external text" href="https://proceedings.mlr.press/v97/zhang19d.html" rel="nofollow">"Self-Attention Generative Adversarial Networks"</a>.&nbsp;<em>International Conference on Machine Learning</em>. PMLR: 7354&ndash;7363.</cite></span></li>
<li id="cite_note-33"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-33">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFLarsenS&oslash;nderbyLarochelleWinther2016" class="citation journal cs1">Larsen, Anders Boesen Lindbo; S&oslash;nderby, S&oslash;ren Kaae; Larochelle, Hugo; Winther, Ole (June 11, 2016).&nbsp;<a class="external text" href="https://proceedings.mlr.press/v48/larsen16.html" rel="nofollow">"Autoencoding beyond pixels using a learned similarity metric"</a>.&nbsp;<em>International Conference on Machine Learning</em>. PMLR: 1558&ndash;1566.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1512.09300" rel="nofollow">1512.09300</a></span>.</cite></span></li>
<li id="cite_note-34"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-34">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFJiangChangWang2021" class="citation arxiv cs1">Jiang, Yifan; Chang, Shiyu; Wang, Zhangyang (December 8, 2021). "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/2102.07074" rel="nofollow">2102.07074</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite></span></li>
<li id="cite_note-35"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-35">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFGroverDharErmon2017" class="citation arxiv cs1">Grover, Aditya; Dhar, Manik; Ermon, Stefano (May 1, 2017). "Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in Generative Models".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1705.08868" rel="nofollow">1705.08868</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-36"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-36">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFArjovskyBottou2017" class="citation arxiv cs1">Arjovsky, Martin; Bottou, L&eacute;on (January 1, 2017). "Towards Principled Methods for Training Generative Adversarial Networks".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1701.04862" rel="nofollow">1701.04862</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/stat.ML" rel="nofollow">stat.ML</a>].</cite></span></li>
<li id="cite_note-37"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-37">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFGoodfellow2014" class="citation arxiv cs1">Goodfellow, Ian J. (December 1, 2014). "On distinguishability criteria for estimating generative models".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1412.6515" rel="nofollow">1412.6515</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/stat.ML" rel="nofollow">stat.ML</a>].</cite></span></li>
<li id="cite_note-38"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-38">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFGoodfellow2016" class="citation web cs1">Goodfellow, Ian (August 31, 2016).&nbsp;<a class="external text" href="https://www.iangoodfellow.com/slides/2016-08-31-Berkeley.pdf" rel="nofollow">"Generative Adversarial Networks (GANs), Presentation at Berkeley Artificial Intelligence Lab"</a>&nbsp;<span class="cs1-format">(PDF)</span>.&nbsp;<a class="external text" href="https://web.archive.org/web/20220508101103/https://www.iangoodfellow.com/slides/2016-08-31-Berkeley.pdf" rel="nofollow">Archived</a>&nbsp;<span class="cs1-format">(PDF)</span>&nbsp;from the original on May 8, 2022.</cite></span></li>
<li id="cite_note-39"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-39">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFLimYe2017" class="citation arxiv cs1">Lim, Jae Hyun; Ye, Jong Chul (May 8, 2017). "Geometric GAN".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1705.02894" rel="nofollow">1705.02894</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/stat.ML" rel="nofollow">stat.ML</a>].</cite></span></li>
<li id="cite_note-40"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-40">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFMaoLiXieLau2017" class="citation journal cs1">Mao, Xudong; Li, Qing; Xie, Haoran; Lau, Raymond Y. K.; Wang, Zhen; Paul Smolley, Stephen (2017).&nbsp;<a class="external text" href="https://openaccess.thecvf.com/content_iccv_2017/html/Mao_Least_Squares_Generative_ICCV_2017_paper.html" rel="nofollow">"Least Squares Generative Adversarial Networks"</a>: 2794&ndash;2802.</cite></span></li>
<li id="cite_note-41"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-41">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFMakhzaniShlensJaitlyGoodfellow2016" class="citation arxiv cs1">Makhzani, Alireza; Shlens, Jonathon; Jaitly, Navdeep;&nbsp;<a title="Ian Goodfellow" href="https://en.wikipedia.org/wiki/Ian_Goodfellow">Goodfellow, Ian</a>;&nbsp;<a title="Brendan Frey" href="https://en.wikipedia.org/wiki/Brendan_Frey">Frey, Brendan</a>&nbsp;(2016). "Adversarial Autoencoders".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1511.05644" rel="nofollow">1511.05644</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-42"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-42">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFBarberAgakov2003" class="citation journal cs1">Barber, David; Agakov, Felix (December 9, 2003).&nbsp;<a class="external text" href="https://dl.acm.org/doi/abs/10.5555/2981345.2981371" rel="nofollow">"The IM algorithm: a variational approach to Information Maximization"</a>.&nbsp;<em>Proceedings of the 16th International Conference on Neural Information Processing Systems</em>. NIPS'03. Cambridge, MA, USA: MIT Press: 201&ndash;208.</cite></span></li>
<li id="cite_note-43"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-43">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFChenDuanHouthooftSchulman2016" class="citation journal cs1">Chen, Xi; Duan, Yan; Houthooft, Rein; Schulman, John; Sutskever, Ilya; Abbeel, Pieter (2016).&nbsp;<a class="external text" href="https://proceedings.neurips.cc/paper/2016/hash/7c9d0b1f96aebd7b5eca8c3edaa19ebb-Abstract.html" rel="nofollow">"InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets"</a>.&nbsp;<em>Advances in Neural Information Processing Systems</em>. Curran Associates, Inc.&nbsp;<strong>29</strong>.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1606.03657" rel="nofollow">1606.03657</a></span>.</cite></span></li>
<li id="cite_note-44"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-44">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFDonahueKr&auml;henb&uuml;hlDarrell2016" class="citation arxiv cs1">Donahue, Jeff; Kr&auml;henb&uuml;hl, Philipp;&nbsp;<a title="Trevor Darrell" href="https://en.wikipedia.org/wiki/Trevor_Darrell">Darrell, Trevor</a>&nbsp;(2016). "Adversarial Feature Learning".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1605.09782" rel="nofollow">1605.09782</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-45"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-45">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFDumoulinBelghaziPooleMastropietro2016" class="citation arxiv cs1">Dumoulin, Vincent; Belghazi, Ishmael; Poole, Ben; Mastropietro, Olivier; Arjovsky, Alex; Courville, Aaron (2016). "Adversarially Learned Inference".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1606.00704" rel="nofollow">1606.00704</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/stat.ML" rel="nofollow">stat.ML</a>].</cite></span></li>
<li id="cite_note-46"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-46">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFXi_ChenYan_DuanRein_HouthooftJohn_Schulman2016" class="citation arxiv cs1">Xi Chen; Yan Duan; Rein Houthooft; John Schulman;&nbsp;<a title="Ilya Sutskever" href="https://en.wikipedia.org/wiki/Ilya_Sutskever">Ilya Sutskever</a>;&nbsp;<a title="Pieter Abbeel" href="https://en.wikipedia.org/wiki/Pieter_Abbeel">Pieter Abeel</a>&nbsp;(2016). "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1606.03657" rel="nofollow">1606.03657</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-47"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-47">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFZhirui_ZhangShujie_LiuMu_LiMing_Zhou2018" class="citation web cs1">Zhirui Zhang; Shujie Liu; Mu Li; Ming Zhou; Enhong Chen (October 2018).&nbsp;<a class="external text" href="https://www.aclweb.org/anthology/K18-1019.pdf" rel="nofollow">"Bidirectional Generative Adversarial Networks for Neural Machine Translation"</a>&nbsp;<span class="cs1-format">(PDF)</span>. pp.&nbsp;190&ndash;199.</cite></span></li>
<li id="cite_note-48"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-48">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFZhuParkIsolaEfros2017" class="citation arxiv cs1">Zhu, Jun-Yan; Park, Taesung; Isola, Phillip; Efros, Alexei A. (2017). "Unpaired Image-To-Image Translation Using Cycle-Consistent Adversarial Networks". pp.&nbsp;2223&ndash;2232.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1703.10593" rel="nofollow">1703.10593</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite></span></li>
<li id="cite_note-49"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-49">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFIsolaZhuZhouEfros2017" class="citation arxiv cs1">Isola, Phillip; Zhu, Jun-Yan; Zhou, Tinghui; Efros, Alexei A. (2017). "Image-To-Image Translation With Conditional Adversarial Networks". pp.&nbsp;1125&ndash;1134.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1611.07004" rel="nofollow">1611.07004</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite></span></li>
<li id="cite_note-50"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-50">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFBrownlee2019" class="citation web cs1">Brownlee, Jason (August 22, 2019).&nbsp;<a class="external text" href="https://machinelearningmastery.com/a-gentle-introduction-to-the-biggan/" rel="nofollow">"A Gentle Introduction to BigGAN the Big Generative Adversarial Network"</a>.&nbsp;<em>Machine Learning Mastery</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">July 15,</span>&nbsp;2022</span>.</cite></span></li>
<li id="cite_note-51"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-51">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFShengyuZhijianJiJun-Yan2020" class="citation journal cs1">Shengyu, Zhao; Zhijian, Liu; Ji, Lin; Jun-Yan, Zhu; Song, Han (2020).&nbsp;<a class="external text" href="https://proceedings.neurips.cc/paper/2020/hash/55479c55ebd1efd3ff125f1337100388-Abstract.html" rel="nofollow">"Differentiable Augmentation for Data-Efficient GAN Training"</a>.&nbsp;<em>Advances in Neural Information Processing Systems</em>.&nbsp;<strong>33</strong>.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/2006.10738" rel="nofollow">2006.10738</a></span>.</cite></span></li>
<li id="cite_note-:4-52"><span class="mw-cite-backlink">^&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:4_52-0"><span class="cite-accessibility-label">Jump up to:</span><sup><em><strong>a</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:4_52-1"><sup><em><strong>b</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-:4_52-2"><sup><em><strong>c</strong></em></sup></a></span>&nbsp;<span class="reference-text"><cite id="CITEREFTeroMiikaJanneSamuli2020" class="citation journal cs1">Tero, Karras; Miika, Aittala; Janne, Hellsten; Samuli, Laine; Jaakko, Lehtinen; Timo, Aila (2020).&nbsp;<a class="external text" href="https://proceedings.neurips.cc/paper/2020/hash/8d30aa96e72440759f74bd2306c1fa3d-Abstract.html" rel="nofollow">"Training Generative Adversarial Networks with Limited Data"</a>.&nbsp;<em>Advances in Neural Information Processing Systems</em>.&nbsp;<strong>33</strong>.</cite></span></li>
<li id="cite_note-53"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-53">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFShahamDekelMichaeli2019" class="citation book cs1">Shaham, Tamar Rott; Dekel, Tali; Michaeli, Tomer (October 2019).&nbsp;<a class="external text" href="https://dx.doi.org/10.1109/iccv.2019.00467" rel="nofollow">"SinGAN: Learning a Generative Model from a Single Natural Image"</a>.&nbsp;<em>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</em>. IEEE. pp.&nbsp;4569&ndash;4579.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1905.01164" rel="nofollow">1905.01164</a></span>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2Ficcv.2019.00467" rel="nofollow">10.1109/iccv.2019.00467</a>.&nbsp;<a class="mw-redirect" title="ISBN (identifier)" href="https://en.wikipedia.org/wiki/ISBN_(identifier)">ISBN</a>&nbsp;<a title="Special:BookSources/978-1-7281-4803-8" href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-7281-4803-8"><bdi>978-1-7281-4803-8</bdi></a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:145052179" rel="nofollow">145052179</a>.</cite></span></li>
<li id="cite_note-54"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-54">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKarrasLaineAila2019" class="citation book cs1">Karras, Tero; Laine, Samuli; Aila, Timo (June 2019).&nbsp;<a class="external text" href="https://dx.doi.org/10.1109/cvpr.2019.00453" rel="nofollow">"A Style-Based Generator Architecture for Generative Adversarial Networks"</a>.&nbsp;<em>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>. IEEE. pp.&nbsp;4396&ndash;4405.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1812.04948" rel="nofollow">1812.04948</a></span>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2Fcvpr.2019.00453" rel="nofollow">10.1109/cvpr.2019.00453</a>.&nbsp;<a class="mw-redirect" title="ISBN (identifier)" href="https://en.wikipedia.org/wiki/ISBN_(identifier)">ISBN</a>&nbsp;<a title="Special:BookSources/978-1-7281-3293-8" href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-7281-3293-8"><bdi>978-1-7281-3293-8</bdi></a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:54482423" rel="nofollow">54482423</a>.</cite></span></li>
<li id="cite_note-55"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-55">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKarrasLaineAittalaHellsten2020" class="citation book cs1">Karras, Tero; Laine, Samuli; Aittala, Miika; Hellsten, Janne; Lehtinen, Jaakko; Aila, Timo (June 2020).&nbsp;<a class="external text" href="https://dx.doi.org/10.1109/cvpr42600.2020.00813" rel="nofollow">"Analyzing and Improving the Image Quality of StyleGAN"</a>.&nbsp;<em>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>. IEEE. pp.&nbsp;8107&ndash;8116.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1912.04958" rel="nofollow">1912.04958</a></span>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2Fcvpr42600.2020.00813" rel="nofollow">10.1109/cvpr42600.2020.00813</a>.&nbsp;<a class="mw-redirect" title="ISBN (identifier)" href="https://en.wikipedia.org/wiki/ISBN_(identifier)">ISBN</a>&nbsp;<a title="Special:BookSources/978-1-7281-7168-5" href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-7281-7168-5"><bdi>978-1-7281-7168-5</bdi></a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:209202273" rel="nofollow">209202273</a>.</cite></span></li>
<li id="cite_note-56"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-56">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFTimo2021" class="citation book cs1">Timo, Karras, Tero Aittala, Miika Laine, Samuli H&auml;rk&ouml;nen, Erik Hellsten, Janne Lehtinen, Jaakko Aila (June 23, 2021).&nbsp;<a class="external text" href="http://worldcat.org/oclc/1269560084" rel="nofollow"><em>Alias-Free Generative Adversarial Networks</em></a>.&nbsp;<a class="mw-redirect" title="OCLC (identifier)" href="https://en.wikipedia.org/wiki/OCLC_(identifier)">OCLC</a>&nbsp;<a class="external text" href="https://www.worldcat.org/oclc/1269560084" rel="nofollow">1269560084</a>.</cite></span></li>
<li id="cite_note-57"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-57">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKarrasAittalaLaineH&auml;rk&ouml;nen" class="citation web cs1">Karras, Tero; Aittala, Miika; Laine, Samuli; H&auml;rk&ouml;nen, Erik; Hellsten, Janne; Lehtinen, Jaakko; Aila, Timo.&nbsp;<a class="external text" href="https://nvlabs.github.io/stylegan3" rel="nofollow">"Alias-Free Generative Adversarial Networks (StyleGAN3)"</a>.&nbsp;<em>nvlabs.github.io</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">July 16,</span>&nbsp;2022</span>.</cite></span></li>
<li id="cite_note-58"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-58">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFCaesar2019" class="citation cs2">Caesar, Holger (March 1, 2019),&nbsp;<a class="external text" href="https://github.com/nightrome/really-awesome-gan" rel="nofollow"><em>A list of papers on Generative Adversarial (Neural) Networks: nightrome/really-awesome-gan</em></a><span class="reference-accessdate">, retrieved&nbsp;<span class="nowrap">March 2,</span>&nbsp;2019</span></cite></span></li>
<li id="cite_note-59"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-59">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFVincent2019" class="citation news cs1">Vincent, James (March 5, 2019).&nbsp;<a class="external text" href="https://www.theverge.com/2019/3/5/18251267/ai-art-gans-mario-klingemann-auction-sothebys-technology" rel="nofollow">"A never-ending stream of AI art goes up for auction"</a>.&nbsp;<em>The Verge</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">June 13,</span>&nbsp;2020</span>.</cite></span></li>
<li id="cite_note-60"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-60">^</a></strong></span>&nbsp;<span class="reference-text">Yu, Jiahui, et al. "<a class="external text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Generative_Image_Inpainting_CVPR_2018_paper.pdf" rel="nofollow">Generative image inpainting with contextual attention</a>." Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.</span></li>
<li id="cite_note-61"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-61">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFWong" class="citation web cs1">Wong, Ceecee.&nbsp;<a class="external text" href="https://www.cdotrends.com/story/14300/rise-ai-supermodels" rel="nofollow">"The Rise of AI Supermodels"</a>.&nbsp;<em>CDO Trends</em>.</cite></span></li>
<li id="cite_note-62"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-62">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFTaifUgailMehmood2020" class="citation journal cs1">Taif, K.; Ugail, H.; Mehmood, I. (2020).&nbsp;<a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7302543" rel="nofollow">"Cast Shadow Generation Using Generative Adversarial Networks"</a>.&nbsp;<em>Computational Science &ndash; ICCS 2020</em>. Lecture Notes in Computer Science.&nbsp;<strong>12141</strong>: 481&ndash;495.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2F978-3-030-50426-7_36" rel="nofollow">10.1007/978-3-030-50426-7_36</a>.&nbsp;<a class="mw-redirect" title="ISBN (identifier)" href="https://en.wikipedia.org/wiki/ISBN_(identifier)">ISBN</a>&nbsp;<a title="Special:BookSources/978-3-030-50425-0" href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-030-50425-0"><bdi>978-3-030-50425-0</bdi></a>.&nbsp;<a class="mw-redirect" title="PMC (identifier)" href="https://en.wikipedia.org/wiki/PMC_(identifier)">PMC</a>&nbsp;<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7302543" rel="nofollow">7302543</a></span>.</cite></span></li>
<li id="cite_note-63"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-63">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFAllen2020" class="citation web cs1">Allen, Eric Van (July 8, 2020).&nbsp;<a class="external text" href="https://www.usgamer.net/articles/ben-drowned-zelda-creepypasta-finale-artificial-intelligence" rel="nofollow">"An Infamous Zelda Creepypasta Saga Is Using Artificial Intelligence to Craft Its Finale"</a>.&nbsp;<em>USgamer</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">November 7,</span>&nbsp;2022</span>.</cite></span></li>
<li id="cite_note-64"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-64">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFarcadeattack2020" class="citation web cs1">arcadeattack (September 28, 2020).&nbsp;<a class="external text" href="https://www.arcadeattack.co.uk/podcast-september-4-2020/" rel="nofollow">"Arcade Attack Podcast &ndash; September (4 of 4) 2020 - Alex Hall (Ben Drowned) - Interview"</a>.&nbsp;<em>Arcade Attack</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">November 7,</span>&nbsp;2022</span>.</cite></span></li>
<li id="cite_note-65"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-65">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFSchawinskiZhangZhangFowler2017" class="citation journal cs1">Schawinski, Kevin; Zhang, Ce; Zhang, Hantian; Fowler, Lucas; Santhanam, Gokula Krishnan (February 1, 2017). "Generative Adversarial Networks recover features in astrophysical images of galaxies beyond the deconvolution limit".&nbsp;<em>Monthly Notices of the Royal Astronomical Society: Letters</em>.&nbsp;<strong>467</strong>&nbsp;(1): L110&ndash;L114.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1702.00403" rel="nofollow">1702.00403</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2017MNRAS.467L.110S" rel="nofollow">2017MNRAS.467L.110S</a>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1093%2Fmnrasl%2Fslx008" rel="nofollow">10.1093/mnrasl/slx008</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:7213940" rel="nofollow">7213940</a>.</cite></span></li>
<li id="cite_note-66"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-66">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKincade" class="citation news cs1">Kincade, Kathy.&nbsp;<a class="external text" href="https://www.rdmag.com/news/2019/05/researchers-train-neural-network-study-dark-matter" rel="nofollow">"Researchers Train a Neural Network to Study Dark Matter"</a>. R&amp;D Magazine.</cite></span></li>
<li id="cite_note-67"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-67">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKincade2019" class="citation news cs1">Kincade, Kathy (May 16, 2019).&nbsp;<a class="external text" href="https://phys.org/news/2019-05-cosmogan-neural-network-dark.html" rel="nofollow">"CosmoGAN: Training a neural network to study dark matter"</a>.&nbsp;<em>Phys.org</em>.</cite></span></li>
<li id="cite_note-68"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-68">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://www.sciencedaily.com/releases/2019/05/190516145206.htm" rel="nofollow">"Training a neural network to study dark matter"</a>.&nbsp;<em>Science Daily</em>. May 16, 2019.</cite></span></li>
<li id="cite_note-69"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-69">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFat_06:13" class="citation web cs1">at 06:13, Katyanna Quach 20 May 2019.&nbsp;<a class="external text" href="https://www.theregister.co.uk/2019/05/20/neural_networks_dark_matter/" rel="nofollow">"Cosmoboffins use neural networks to build dark matter maps the easy way"</a>.&nbsp;<em>www.theregister.co.uk</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">May 20,</span>&nbsp;2019</span>.</cite></span></li>
<li id="cite_note-70"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-70">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFMustafaBardBhimjiLukić2019" class="citation journal cs1">Mustafa, Mustafa; Bard, Deborah; Bhimji, Wahid; Lukić, Zarija; Al-Rfou, Rami; Kratochvil, Jan M. (May 6, 2019). "CosmoGAN: creating high-fidelity weak lensing convergence maps using Generative Adversarial Networks".&nbsp;<em>Computational Astrophysics and Cosmology</em>.&nbsp;<strong>6</strong>&nbsp;(1): 1.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1706.02390" rel="nofollow">1706.02390</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2019ComAC...6....1M" rel="nofollow">2019ComAC...6....1M</a>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1186%2Fs40668-019-0029-9" rel="nofollow">10.1186/s40668-019-0029-9</a>.&nbsp;<a class="mw-redirect" title="ISSN (identifier)" href="https://en.wikipedia.org/wiki/ISSN_(identifier)">ISSN</a>&nbsp;<a class="external text" href="https://www.worldcat.org/issn/2197-7909" rel="nofollow">2197-7909</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:126034204" rel="nofollow">126034204</a>.</cite></span></li>
<li id="cite_note-71"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-71">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFPaganinide_OliveiraNachman2017" class="citation journal cs1">Paganini, Michela; de Oliveira, Luke; Nachman, Benjamin (2017). "Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis".&nbsp;<em>Computing and Software for Big Science</em>.&nbsp;<strong>1</strong>: 4.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1701.05927" rel="nofollow">1701.05927</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2017arXiv170105927D" rel="nofollow">2017arXiv170105927D</a>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs41781-017-0004-6" rel="nofollow">10.1007/s41781-017-0004-6</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:88514467" rel="nofollow">88514467</a>.</cite></span></li>
<li id="cite_note-72"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-72">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFPaganinide_OliveiraNachman2018" class="citation journal cs1">Paganini, Michela; de Oliveira, Luke; Nachman, Benjamin (2018). "Accelerating Science with Generative Adversarial Networks: An Application to 3D Particle Showers in Multi-Layer Calorimeters".&nbsp;<em>Physical Review Letters</em>.&nbsp;<strong>120</strong>&nbsp;(4): 042003.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1705.02355" rel="nofollow">1705.02355</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018PhRvL.120d2003P" rel="nofollow">2018PhRvL.120d2003P</a>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1103%2FPhysRevLett.120.042003" rel="nofollow">10.1103/PhysRevLett.120.042003</a>.&nbsp;<a class="mw-redirect" title="PMID (identifier)" href="https://en.wikipedia.org/wiki/PMID_(identifier)">PMID</a>&nbsp;<a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/29437460" rel="nofollow">29437460</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:3330974" rel="nofollow">3330974</a>.</cite></span></li>
<li id="cite_note-73"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-73">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFPaganinide_OliveiraNachman2018" class="citation journal cs1">Paganini, Michela; de Oliveira, Luke; Nachman, Benjamin (2018). "CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks".&nbsp;<em>Phys. Rev. D</em>.&nbsp;<strong>97</strong>&nbsp;(1): 014021.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1712.10321" rel="nofollow">1712.10321</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018PhRvD..97a4021P" rel="nofollow">2018PhRvD..97a4021P</a>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1103%2FPhysRevD.97.014021" rel="nofollow">10.1103/PhysRevD.97.014021</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:41265836" rel="nofollow">41265836</a>.</cite></span></li>
<li id="cite_note-74"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-74">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFErdmannGlombitzaQuast2019" class="citation journal cs1">Erdmann, Martin; Glombitza, Jonas; Quast, Thorben (2019). "Precise Simulation of Electromagnetic Calorimeter Showers Using a Wasserstein Generative Adversarial Network".&nbsp;<em>Computing and Software for Big Science</em>.&nbsp;<strong>3</strong>: 4.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1807.01954" rel="nofollow">1807.01954</a></span>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs41781-018-0019-7" rel="nofollow">10.1007/s41781-018-0019-7</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:54216502" rel="nofollow">54216502</a>.</cite></span></li>
<li id="cite_note-75"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-75">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFMusellaPandolfi2018" class="citation journal cs1">Musella, Pasquale; Pandolfi, Francesco (2018). "Fast and Accurate Simulation of Particle Detectors Using Generative Adversarial Networks".&nbsp;<em>Computing and Software for Big Science</em>.&nbsp;<strong>2</strong>: 8.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1805.00850" rel="nofollow">1805.00850</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018arXiv180500850M" rel="nofollow">2018arXiv180500850M</a>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs41781-018-0015-y" rel="nofollow">10.1007/s41781-018-0015-y</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:119474793" rel="nofollow">119474793</a>.</cite></span></li>
<li id="cite_note-76"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-76">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PUBNOTES/ATL-SOFT-PUB-2018-001/" rel="nofollow">"Deep generative models for fast shower simulation in ATLAS"</a>. 2018.</cite></span></li>
<li id="cite_note-77"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-77">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFSHiP2019" class="citation journal cs1">SHiP, Collaboration (2019). "Fast simulation of muons produced at the SHiP experiment using Generative Adversarial Networks".&nbsp;<em>Journal of Instrumentation</em>.&nbsp;<strong>14</strong>&nbsp;(11): P11028.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1909.04451" rel="nofollow">1909.04451</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2019JInst..14P1028A" rel="nofollow">2019JInst..14P1028A</a>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1088%2F1748-0221%2F14%2F11%2FP11028" rel="nofollow">10.1088/1748-0221/14/11/P11028</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:202542604" rel="nofollow">202542604</a>.</cite></span></li>
<li id="cite_note-78"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-78">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFTangQiaoLoyDong2018" class="citation news cs1">Tang, Xiaoou; Qiao, Yu; Loy, Chen Change; Dong, Chao; Liu, Yihao; Gu, Jinjin; Wu, Shixiang; Yu, Ke; Wang, Xintao (September 1, 2018). "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1809.00219" rel="nofollow">1809.00219</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018arXiv180900219W" rel="nofollow">2018arXiv180900219W</a>.</cite></span></li>
<li id="cite_note-79"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-79">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFNarain2021" class="citation web cs1">Narain, Rohit (December 29, 2021).&nbsp;<a class="external text" href="https://www.datatobiz.com/blog/smart-video-generation-from-text/" rel="nofollow">"Smart Video Generation from Text Using Deep Neural Networks"</a><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">October 13,</span>&nbsp;2022</span>.</cite></span></li>
<li id="cite_note-80"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-80">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation news cs1"><a class="external text" href="https://www.economist.com/news/science-and-technology/21724370-generating-convincing-audio-and-video-fake-events-fake-news-you-aint-seen" rel="nofollow">"Fake news: you ain't seen nothing yet"</a>.&nbsp;<em>The Economist</em>. July 2017<span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">July 1,</span>&nbsp;2017</span>.</cite></span></li>
<li id="cite_note-TPDNEwuaitcryhf|-81"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-TPDNEwuaitcryhf|_81-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFmsmash2019" class="citation web cs1">msmash (February 14, 2019).&nbsp;<a class="external text" href="https://tech.slashdot.org/story/19/02/14/199200/this-person-does-not-exist-website-uses-ai-to-create-realistic-yet-horrifying-faces" rel="nofollow">"'This Person Does Not Exist' Website Uses AI To Create Realistic Yet Horrifying Faces"</a>.&nbsp;<em>Slashdot</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">February 16,</span>&nbsp;2019</span>.</cite></span></li>
<li id="cite_note-82"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-82">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFDoyle2019" class="citation news cs1">Doyle, Michael (May 16, 2019).&nbsp;<a class="external text" href="https://www.courierpress.com/story/news/crime/2019/05/16/john-beasley-lives-saddlehorse-drive-evansville-does-he/3700111002/" rel="nofollow">"John Beasley lives on Saddlehorse Drive in Evansville. Or does he?"</a>. Courier and Press.</cite></span></li>
<li id="cite_note-83"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-83">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFTargett2019" class="citation news cs1">Targett, Ed (May 16, 2019). "California moves closer to making deepfake pornography illegal". Computer Business Review.</cite></span></li>
<li id="cite_note-CNET2019-84"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-CNET2019_84-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFMihalcik2019" class="citation web cs1">Mihalcik, Carrie (October 4, 2019).&nbsp;<a class="external text" href="https://www.cnet.com/news/california-laws-seek-to-crack-down-on-deepfakes-in-politics-and-porn/" rel="nofollow">"California laws seek to crack down on deepfakes in politics and porn"</a>.&nbsp;<em><a class="mw-redirect" title="Cnet.com" href="https://en.wikipedia.org/wiki/Cnet.com">cnet.com</a></em>.&nbsp;<a title="CNET" href="https://en.wikipedia.org/wiki/CNET">CNET</a><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">October 13,</span>&nbsp;2019</span>.</cite></span></li>
<li id="cite_note-85"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-85">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKnight2018" class="citation magazine cs1">Knight, Will (August 7, 2018).&nbsp;<a class="external text" href="https://www.technologyreview.com/s/611726/the-defense-department-has-produced-the-first-tools-for-catching-deepfakes/" rel="nofollow">"The Defense Department has produced the first tools for catching deepfakes"</a>.&nbsp;<em>MIT Technology Review</em>.</cite></span></li>
<li id="cite_note-86"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-86">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFLiFran&ccedil;ois-LavetDoanPineau2021" class="citation arxiv cs1">Li, Bonnie; Fran&ccedil;ois-Lavet, Vincent; Doan, Thang; Pineau, Joelle (February 14, 2021). "Domain Adversarial Reinforcement Learning".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/2102.07097" rel="nofollow">2102.07097</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></span></li>
<li id="cite_note-87"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-87">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFBisnetode_Carvalho_FilhoMagalh&atilde;es2020" class="citation journal cs1">Bisneto, Tomaz Ribeiro Viana; de Carvalho Filho, Antonio Oseas; Magalh&atilde;es, Deborah Maria Vieira (February 2020). "Generative adversarial network and texture features applied to automatic glaucoma detection".&nbsp;<em>Applied Soft Computing</em>.&nbsp;<strong>90</strong>: 106165.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.asoc.2020.106165" rel="nofollow">10.1016/j.asoc.2020.106165</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:214571484" rel="nofollow">214571484</a>.</cite></span></li>
<li id="cite_note-88"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-88">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFWei2019" class="citation web cs1">Wei, Jerry (July 3, 2019).&nbsp;<a class="external text" href="https://towardsdatascience.com/generating-shoe-designs-with-deep-learning-5dde432a23b8" rel="nofollow">"Generating Shoe Designs with Machine Learning"</a>.&nbsp;<em>Medium</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">November 6,</span>&nbsp;2019</span>.</cite></span></li>
<li id="cite_note-89"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-89">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFGreenemeier2016" class="citation web cs1">Greenemeier, Larry (June 20, 2016).&nbsp;<a class="external text" href="https://www.scientificamerican.com/article/when-will-computers-have-common-sense-ask-facebook/" rel="nofollow">"When Will Computers Have Common Sense? Ask Facebook"</a>.&nbsp;<em>Scientific American</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">July 31,</span>&nbsp;2016</span>.</cite></span></li>
<li id="cite_note-90"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-90">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation cs2"><a class="external text" href="https://www.youtube.com/watch?v=5mr6-JbuLrQ" rel="nofollow"><em>Reconstruction of the Roman Emperors: Interview with Daniel Voshart</em></a><span class="reference-accessdate">, retrieved&nbsp;<span class="nowrap">June 3,</span>&nbsp;2022</span></cite></span></li>
<li id="cite_note-91"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-91">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="http://3dgan.csail.mit.edu/" rel="nofollow">"3D Generative Adversarial Network"</a>.&nbsp;<em>3dgan.csail.mit.edu</em>.</cite></span></li>
<li id="cite_note-92"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-92">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFAchlioptasDiamantiMitliagkasGuibas2018" class="citation arxiv cs1">Achlioptas, Panos; Diamanti, Olga; Mitliagkas, Ioannis; Guibas, Leonidas (2018). "Learning Representations and Generative Models for 3D Point Clouds".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1707.02392" rel="nofollow">1707.02392</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite></span></li>
<li id="cite_note-93"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-93">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFVondrickPirsiavashTorralba2016" class="citation web cs1">Vondrick, Carl; Pirsiavash, Hamed; Torralba, Antonio (2016).&nbsp;<a class="external text" href="https://www.cs.columbia.edu/~vondrick/tinyvideo/" rel="nofollow">"Generating Videos with Scene Dynamics"</a>.&nbsp;<em>carlvondrick.com</em>.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1609.02612" rel="nofollow">1609.02612</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2016arXiv160902612V" rel="nofollow">2016arXiv160902612V</a>.</cite></span></li>
<li id="cite_note-94"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-94">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFAntipovBaccoucheDugelay2017" class="citation arxiv cs1">Antipov, Grigory; Baccouche, Moez; Dugelay, Jean-Luc (2017). "Face Aging With Conditional Generative Adversarial Networks".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1702.01983" rel="nofollow">1702.01983</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite></span></li>
<li id="cite_note-95"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-95">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKangGaoRoth2019" class="citation journal cs1">Kang, Yuhao; Gao, Song; Roth, Rob (2019).&nbsp;<a class="external text" href="https://geods.geography.wisc.edu/archives/1192" rel="nofollow">"Transferring Multiscale Map Styles Using Generative Adversarial Networks"</a>.&nbsp;<em>International Journal of Cartography</em>.&nbsp;<strong>5</strong>&nbsp;(2&ndash;3): 115&ndash;141.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1905.02200" rel="nofollow">1905.02200</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2019arXiv190502200K" rel="nofollow">2019arXiv190502200K</a>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1080%2F23729333.2019.1615729" rel="nofollow">10.1080/23729333.2019.1615729</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:146808465" rel="nofollow">146808465</a>.</cite></span></li>
<li id="cite_note-96"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-96">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFWijnandsNiceThompsonZhao2019" class="citation journal cs1">Wijnands, Jasper; Nice, Kerry; Thompson, Jason; Zhao, Haifeng; Stevenson, Mark (2019). "Streetscape augmentation using generative adversarial networks: Insights related to health and wellbeing".&nbsp;<em>Sustainable Cities and Society</em>.&nbsp;<strong>49</strong>: 101602.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1905.06464" rel="nofollow">1905.06464</a></span>.&nbsp;<a class="mw-redirect" title="Bibcode (identifier)" href="https://en.wikipedia.org/wiki/Bibcode_(identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2019arXiv190506464W" rel="nofollow">2019arXiv190506464W</a>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.scs.2019.101602" rel="nofollow">10.1016/j.scs.2019.101602</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:155100183" rel="nofollow">155100183</a>.</cite></span></li>
<li id="cite_note-97"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-97">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFUkkonenJoonaRuotsalo2020" class="citation journal cs1">Ukkonen, Antti; Joona, Pyry; Ruotsalo, Tuukka (2020).&nbsp;<a class="external text" href="https://doi.org/10.1145/3397271.3401129" rel="nofollow">"Generating Images Instead of Retrieving Them: Relevance Feedback on Generative Adversarial Networks"</a>.&nbsp;<em>Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em>: 1329&ndash;1338.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1145%2F3397271.3401129" rel="nofollow">10.1145/3397271.3401129</a>.&nbsp;<a class="mw-redirect" title="Hdl (identifier)" href="https://en.wikipedia.org/wiki/Hdl_(identifier)">hdl</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://hdl.handle.net/10138%2F328471" rel="nofollow">10138/328471</a></span>.&nbsp;<a class="mw-redirect" title="ISBN (identifier)" href="https://en.wikipedia.org/wiki/ISBN_(identifier)">ISBN</a>&nbsp;<a title="Special:BookSources/9781450380164" href="https://en.wikipedia.org/wiki/Special:BookSources/9781450380164"><bdi>9781450380164</bdi></a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:220730163" rel="nofollow">220730163</a>.</cite></span></li>
<li id="cite_note-98"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-98">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFPadhiUnnikrishnan2006" class="citation journal cs1">Padhi, Radhakant; Unnikrishnan, Nishant (2006). "A single network adaptive critic (SNAC) architecture for optimal control synthesis for a class of nonlinear systems".&nbsp;<em>Neural Networks</em>.&nbsp;<strong>19</strong>&nbsp;(10): 1648&ndash;1660.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.neunet.2006.08.010" rel="nofollow">10.1016/j.neunet.2006.08.010</a>.&nbsp;<a class="mw-redirect" title="PMID (identifier)" href="https://en.wikipedia.org/wiki/PMID_(identifier)">PMID</a>&nbsp;<a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/17045458" rel="nofollow">17045458</a>.</cite></span></li>
<li id="cite_note-99"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-99">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation magazine cs1"><a class="external text" href="https://www.technologyreview.com/f/613547/ai-can-show-us-the-ravages-of-climate-change/" rel="nofollow">"AI can show us the ravages of climate change"</a>.&nbsp;<em>MIT Technology Review</em>. May 16, 2019.</cite></span></li>
<li id="cite_note-100"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-100">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFChristian2019" class="citation news cs1">Christian, Jon (May 28, 2019).&nbsp;<a class="external text" href="https://futurism.com/the-byte/ai-guesses-appearance-voice" rel="nofollow">"ASTOUNDING AI GUESSES WHAT YOU LOOK LIKE BASED ON YOUR VOICE"</a>. Futurism.</cite></span></li>
<li id="cite_note-101"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-101">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFZhavoronkov2019" class="citation journal cs1">Zhavoronkov, Alex (2019). "Deep learning enables rapid identification of potent DDR1 kinase inhibitors".&nbsp;<em>Nature Biotechnology</em>.&nbsp;<strong>37</strong>&nbsp;(9): 1038&ndash;1040.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1038%2Fs41587-019-0224-x" rel="nofollow">10.1038/s41587-019-0224-x</a>.&nbsp;<a class="mw-redirect" title="PMID (identifier)" href="https://en.wikipedia.org/wiki/PMID_(identifier)">PMID</a>&nbsp;<a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/31477924" rel="nofollow">31477924</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:201716327" rel="nofollow">201716327</a>.</cite></span></li>
<li id="cite_note-102"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-102">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFBarber" class="citation magazine cs1">Barber, Gregory.&nbsp;<a class="external text" href="https://www.wired.com/story/molecule-designed-ai-exhibits-druglike-qualities/" rel="nofollow">"A Molecule Designed By AI Exhibits "Druglike" Qualities"</a>.&nbsp;<em>Wired</em>.</cite></span></li>
<li id="cite_note-103"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-103">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFMohammad_Navid_FekriAnanda_Mohon_GhoshKatarina_Grolinger2020" class="citation journal cs1">Mohammad Navid Fekri; Ananda Mohon Ghosh; Katarina Grolinger (2020).&nbsp;<a class="external text" href="https://doi.org/10.3390%2Fen13010130" rel="nofollow">"Generating Energy Data for Machine Learning with Recurrent Generative Adversarial Networks"</a>.&nbsp;<em>Energies</em>.&nbsp;<strong>13</strong>&nbsp;(1): 130.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.3390%2Fen13010130" rel="nofollow">10.3390/en13010130</a></span>.</cite></span></li>
<li id="cite_note-curiosity1991-104"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-curiosity1991_104-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFSchmidhuber1991" class="citation conference cs1"><a class="mw-redirect" title="Juergen Schmidhuber" href="https://en.wikipedia.org/wiki/Juergen_Schmidhuber">Schmidhuber, J&uuml;rgen</a>&nbsp;(1991). "A possibility for implementing curiosity and boredom in model-building neural controllers".&nbsp;<em>Proc. SAB'1991</em>. MIT Press/Bradford Books. pp.&nbsp;222&ndash;227.</cite></span></li>
<li id="cite_note-fun2010-105"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-fun2010_105-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFSchmidhuber2010" class="citation journal cs1"><a title="J&uuml;rgen Schmidhuber" href="https://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber">Schmidhuber, J&uuml;rgen</a>&nbsp;(2010). "Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990-2010)".&nbsp;<em>IEEE Transactions on Autonomous Mental Development</em>.&nbsp;<strong>2</strong>&nbsp;(3): 230&ndash;247.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTAMD.2010.2056368" rel="nofollow">10.1109/TAMD.2010.2056368</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:234198" rel="nofollow">234198</a>.</cite></span></li>
<li id="cite_note-gancurpm2020-106"><span class="mw-cite-backlink">^&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-gancurpm2020_106-0"><span class="cite-accessibility-label">Jump up to:</span><sup><em><strong>a</strong></em></sup></a>&nbsp;<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-gancurpm2020_106-1"><sup><em><strong>b</strong></em></sup></a></span>&nbsp;<span class="reference-text"><cite id="CITEREFSchmidhuber2020" class="citation journal cs1"><a class="mw-redirect" title="Juergen Schmidhuber" href="https://en.wikipedia.org/wiki/Juergen_Schmidhuber">Schmidhuber, J&uuml;rgen</a>&nbsp;(2020). "Generative Adversarial Networks are Special Cases of Artificial Curiosity (1990) and also Closely Related to Predictability Minimization (1991)".&nbsp;<em>Neural Networks</em>.&nbsp;<strong>127</strong>: 58&ndash;66.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1906.04493" rel="nofollow">1906.04493</a></span>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.neunet.2020.04.008" rel="nofollow">10.1016/j.neunet.2020.04.008</a>.&nbsp;<a class="mw-redirect" title="PMID (identifier)" href="https://en.wikipedia.org/wiki/PMID_(identifier)">PMID</a>&nbsp;<a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/32334341" rel="nofollow">32334341</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:216056336" rel="nofollow">216056336</a>.</cite></span></li>
<li id="cite_note-olli2010-107"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-olli2010_107-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFNiemitalo2010" class="citation web cs1">Niemitalo, Olli (February 24, 2010).&nbsp;<a class="external text" href="http://yehar.com/blog/?p=167" rel="nofollow">"A method for training artificial neural networks to generate missing data within a variable context"</a>.&nbsp;<em>Internet Archive (Wayback Machine)</em>.&nbsp;<a class="external text" href="https://web.archive.org/web/20120312111546/http://yehar.com/blog/?p=167" rel="nofollow">Archived</a>&nbsp;from the original on March 12, 2012<span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">February 22,</span>&nbsp;2019</span>.</cite></span></li>
<li id="cite_note-reddit3-108"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-reddit3_108-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://www.reddit.com/r/MachineLearning/comments/bnqm0p/d_gans_were_invented_in_2010/" rel="nofollow">"GANs were invented in 2010?"</a>.&nbsp;<em>reddit r/MachineLearning</em>. 2019<span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">May 28,</span>&nbsp;2019</span>.</cite></span></li>
<li id="cite_note-Li-etal-GECCO2013-109"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-Li-etal-GECCO2013_109-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFLiGauciGross2013" class="citation conference cs1">Li, Wei; Gauci, Melvin; Gross, Roderich (July 6, 2013). "Proceeding of the fifteenth annual conference on Genetic and evolutionary computation conference - GECCO '13".&nbsp;<em>Proceedings of the 15th Annual Conference on Genetic and Evolutionary Computation (GECCO 2013)</em>. Amsterdam, The Netherlands: ACM. pp.&nbsp;223&ndash;230.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1145%2F2463372.2465801" rel="nofollow">10.1145/2463372.2465801</a>.&nbsp;<a class="mw-redirect" title="ISBN (identifier)" href="https://en.wikipedia.org/wiki/ISBN_(identifier)">ISBN</a>&nbsp;<a title="Special:BookSources/9781450319638" href="https://en.wikipedia.org/wiki/Special:BookSources/9781450319638"><bdi>9781450319638</bdi></a>.</cite></span></li>
<li id="cite_note-110"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-110">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFGutmannHyv&auml;rinen" class="citation journal cs1">Gutmann, Michael; Hyv&auml;rinen, Aapo.&nbsp;<a class="external text" href="http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf" rel="nofollow">"Noise-Contrastive Estimation"</a>&nbsp;<span class="cs1-format">(PDF)</span>.&nbsp;<em>International Conference on AI and Statistics</em>.</cite></span></li>
<li id="cite_note-111"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-111">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFAbu-KhalafLewisHuang2008" class="citation journal cs1">Abu-Khalaf, Murad; Lewis, Frank L.; Huang, Jie (July 1, 2008). "Neurodynamic Programming and Zero-Sum Games for Constrained Control Systems".&nbsp;<em>IEEE Transactions on Neural Networks</em>.&nbsp;<strong>19</strong>&nbsp;(7): 1243&ndash;1252.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTNN.2008.2000204" rel="nofollow">10.1109/TNN.2008.2000204</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:15680448" rel="nofollow">15680448</a>.</cite></span></li>
<li id="cite_note-112"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-112">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFAbu-KhalafLewisHuang2006" class="citation journal cs1">Abu-Khalaf, Murad; Lewis, Frank L.; Huang, Jie (December 1, 2006). "Policy Iterations on the Hamilton&ndash;Jacobi&ndash;Isaacs Equation for&nbsp;<em>H</em><sub>&infin;</sub>&nbsp;State Feedback Control With Input Saturation".&nbsp;<em>IEEE Transactions on Automatic Control</em>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTAC.2006.884959" rel="nofollow">10.1109/TAC.2006.884959</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:1338976" rel="nofollow">1338976</a>.</cite></span></li>
<li id="cite_note-113"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-113">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFSajjadiSch&ouml;lkopfHirsch2016" class="citation arxiv cs1">Sajjadi, Mehdi S. M.; Sch&ouml;lkopf, Bernhard; Hirsch, Michael (December 23, 2016). "EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1612.07919" rel="nofollow">1612.07919</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite></span></li>
<li id="cite_note-114"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-114">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://medium.com/@alagraphy/this-person-does-not-exist-neither-will-anything-if-artificial-intelligence-keeps-learning-1a9fcba728f" rel="nofollow">"This Person Does Not Exist: Neither Will Anything Eventually with AI"</a>. March 20, 2019.</cite></span></li>
<li id="cite_note-115"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-115">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://www.issuewire.com/artificial-intelligence-enters-the-history-of-art-1620667772563815" rel="nofollow">"ARTificial Intelligence enters the History of Art"</a>. December 28, 2018.</cite></span></li>
<li id="cite_note-116"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-116">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFTom_F&eacute;vrier2019" class="citation web cs1">Tom F&eacute;vrier (February 17, 2019).&nbsp;<a class="external text" href="https://link.medium.com/MYqBrGHIKV" rel="nofollow">"Le scandale de l'intelligence ARTificielle"</a>.</cite></span></li>
<li id="cite_note-117"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-117">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://github.com/NVlabs/stylegan" rel="nofollow">"StyleGAN: Official TensorFlow Implementation"</a>. March 2, 2019 &ndash; via GitHub.</cite></span></li>
<li id="cite_note-TPDNEitboowo2019-118"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-TPDNEitboowo2019_118-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFPaez2019" class="citation web cs1">Paez, Danny (February 13, 2019).&nbsp;<a class="external text" href="https://www.inverse.com/article/53280-this-person-does-not-exist-gans-website=website=Inverse" rel="nofollow">"This Person Does Not Exist Is the Best One-Off Website of 2019"</a><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">February 16,</span>&nbsp;2019</span>.</cite></span></li>
<li id="cite_note-TPDNE-119"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-TPDNE_119-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFBeschizza2019" class="citation web cs1">Beschizza, Rob (February 15, 2019).&nbsp;<a class="external text" href="https://boingboing.net/2019/02/15/this-person-does-not-exist.html" rel="nofollow">"This Person Does Not Exist"</a>.&nbsp;<em>Boing-Boing</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">February 16,</span>&nbsp;2019</span>.</cite></span></li>
<li id="cite_note-Style-based_GANs_&ndash;_Generating_and_Tuning_Realistic_Artificial_Faces-120"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-Style-based_GANs_%E2%80%93_Generating_and_Tuning_Realistic_Artificial_Faces_120-0">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFHorev2018" class="citation web cs1">Horev, Rani (December 26, 2018).&nbsp;<a class="external text" href="https://web.archive.org/web/20201105101517/https://www.lyrn.ai/2018/12/26/a-style-based-generator-architecture-for-generative-adversarial-networks/" rel="nofollow">"Style-based GANs &ndash; Generating and Tuning Realistic Artificial Faces"</a>.&nbsp;<em>Lyrn.AI</em>. Archived from&nbsp;<a class="external text" href="https://www.lyrn.ai/2018/12/26/a-style-based-generator-architecture-for-generative-adversarial-networks/" rel="nofollow">the original</a>&nbsp;on November 5, 2020<span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">February 16,</span>&nbsp;2019</span>.</cite></span></li>
<li id="cite_note-121"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-121">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFElgammalLiuElhoseinyMazzone2017" class="citation arxiv cs1">Elgammal, Ahmed; Liu, Bingchen; Elhoseiny, Mohamed; Mazzone, Marian (2017). "CAN: Creative Adversarial Networks, Generating "Art" by Learning About Styles and Deviating from Style Norms".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1706.07068" rel="nofollow">1706.07068</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.AI" rel="nofollow">cs.AI</a>].</cite></span></li>
<li id="cite_note-122"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-122">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFCohn2018" class="citation news cs1">Cohn, Gabe (October 25, 2018).&nbsp;<a class="external text" href="https://www.nytimes.com/2018/10/25/arts/design/ai-art-sold-christies.html" rel="nofollow">"AI Art at Christie's Sells for $432,500"</a>.&nbsp;<em>The New York Times</em>.</cite></span></li>
<li id="cite_note-123"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-123">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFMazzone,_MarianAhmed_Elgammal2019" class="citation journal cs1">Mazzone, Marian; Ahmed Elgammal (February 21, 2019).&nbsp;<a class="external text" href="https://doi.org/10.3390%2Farts8010026" rel="nofollow">"Art, Creativity, and the Potential of Artificial Intelligence"</a>.&nbsp;<em>Arts</em>.&nbsp;<strong>8</strong>: 26.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.3390%2Farts8010026" rel="nofollow">10.3390/arts8010026</a></span>.</cite></span></li>
<li id="cite_note-124"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-124">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFKulp2019" class="citation magazine cs1">Kulp, Patrick (May 23, 2019).&nbsp;<a class="external text" href="https://www.adweek.com/digital/samsungs-ai-lab-can-create-fake-video-footage-from-a-single-headshot/" rel="nofollow">"Samsung's AI Lab Can Create Fake Video Footage From a Single Headshot"</a>.&nbsp;<em>AdWeek</em>.</cite></span></li>
<li id="cite_note-125"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-125">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFYuCanales2021" class="citation journal cs1">Yu, Yi; Canales, Simon (2021). "Conditional LSTM-GAN for Melody Generation from Lyrics".&nbsp;<em>ACM Transactions on Multimedia Computing, Communications, and Applications</em>.&nbsp;<strong>17</strong>: 1&ndash;20.&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1908.05551" rel="nofollow">1908.05551</a></span>.&nbsp;<a class="mw-redirect" title="Doi (identifier)" href="https://en.wikipedia.org/wiki/Doi_(identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1145%2F3424116" rel="nofollow">10.1145/3424116</a>.&nbsp;<a class="mw-redirect" title="ISSN (identifier)" href="https://en.wikipedia.org/wiki/ISSN_(identifier)">ISSN</a>&nbsp;<a class="external text" href="https://www.worldcat.org/issn/1551-6857" rel="nofollow">1551-6857</a>.&nbsp;<a class="mw-redirect" title="S2CID (identifier)" href="https://en.wikipedia.org/wiki/S2CID_(identifier)">S2CID</a>&nbsp;<a class="external text" href="https://api.semanticscholar.org/CorpusID:199668828" rel="nofollow">199668828</a>.</cite></span></li>
<li id="cite_note-126"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-126">^</a></strong></span>&nbsp;<span class="reference-text"><cite class="citation news cs1"><a class="external text" href="https://www.theverge.com/2020/5/22/21266251/nvidia-ai-gamegan-recreate-pac-man-virutal-environment" rel="nofollow">"Nvidia's AI recreates Pac-Man from scratch just by watching it being played"</a>.&nbsp;<em>The Verge</em>. May 22, 2020.</cite></span></li>
<li id="cite_note-127"><span class="mw-cite-backlink"><strong><a title="Jump up" href="https://en.wikipedia.org/wiki/Generative_adversarial_network#cite_ref-127">^</a></strong></span>&nbsp;<span class="reference-text"><cite id="CITEREFSeung_Wook_KimZhouPhilionTorralba2020" class="citation arxiv cs1">Seung Wook Kim; Zhou, Yuhao; Philion, Jonah; Torralba, Antonio; Fidler, Sanja (2020). "Learning to Simulate Dynamic Environments with GameGAN".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/2005.12126" rel="nofollow">2005.12126</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite></span></li>
</ol>
</div>
</div>
<h2><span id="External_links" class="mw-headline">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a title="Edit section: External links" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=49">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul class="noprint portalbox portalborder portalright">
<li class="portalbox-entry"><span class="portalbox-image"><span class="noviewer"><a class="mw-file-description" href="https://en.wikipedia.org/wiki/File:Ballerina-icon.jpg"><img class="mw-file-element" src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Ballerina-icon.jpg/23px-Ballerina-icon.jpg" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Ballerina-icon.jpg/35px-Ballerina-icon.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Ballerina-icon.jpg/47px-Ballerina-icon.jpg 2x" alt="icon" width="23" height="28" data-file-width="306" data-file-height="367" /></a></span></span><span class="portalbox-link"><a class="mw-redirect" title="Portal:Art" href="https://en.wikipedia.org/wiki/Portal:Art">Art portal</a></span></li>
</ul>
<ul>
<li><cite id="CITEREFKnight" class="citation news cs1">Knight, Will.&nbsp;<a class="external text" href="https://www.technologyreview.com/s/603216/5-big-predictions-for-artificial-intelligence-in-2017/" rel="nofollow">"5 Big Predictions for Artificial Intelligence in 2017"</a>.&nbsp;<em>MIT Technology Review</em><span class="reference-accessdate">. Retrieved&nbsp;<span class="nowrap">January 5,</span>&nbsp;2017</span>.</cite></li>
<li><cite id="CITEREFKarrasLaineAila2018" class="citation arxiv cs1">Karras, Tero; Laine, Samuli; Aila, Timo (2018). "A Style-Based Generator Architecture for Generative Adversarial Networks".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1812.04948" rel="nofollow">1812.04948</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.NE" rel="nofollow">cs.NE</a>].</cite></li>
<li><a class="external text" href="https://www.thispersondoesnotexist.com/" rel="nofollow">This Person Does Not Exist</a>&nbsp;&ndash; photorealistic images of people who do not exist, generated by&nbsp;<a title="StyleGAN" href="https://en.wikipedia.org/wiki/StyleGAN">StyleGAN</a></li>
<li><a class="external text" href="https://thiscatdoesnotexist.com/" rel="nofollow">This Cat Does Not Exist</a>&nbsp;&ndash; photorealistic images of cats who do not exist, generated by&nbsp;<a title="StyleGAN" href="https://en.wikipedia.org/wiki/StyleGAN">StyleGAN</a></li>
<li><cite id="CITEREFWangSheWard2019" class="citation arxiv cs1">Wang, Zhengwei; She, Qi; Ward, Tomas E. (2019). "Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy".&nbsp;<a class="mw-redirect" title="ArXiv (identifier)" href="https://en.wikipedia.org/wiki/ArXiv_(identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://arxiv.org/abs/1906.01529" rel="nofollow">1906.01529</a></span>&nbsp;[<a class="external text" href="https://arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite></li>
</ul>
<div class="navbox-styles">&nbsp;</div>
<div class="navbox">
<table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner mw-made-collapsible mw-collapsed">
<tbody>
<tr>
<th class="navbox-title" colspan="2" scope="col"><button class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" tabindex="0" type="button"><span class="mw-collapsible-text">show</span></button>
<div class="navbar plainlinks hlist navbar-mini">
<ul>
<li class="nv-view"><a title="Template:Differentiable computing" href="https://en.wikipedia.org/wiki/Template:Differentiable_computing"><abbr title="View this template">v</abbr></a></li>
<li class="nv-talk"><a title="Template talk:Differentiable computing" href="https://en.wikipedia.org/wiki/Template_talk:Differentiable_computing"><abbr title="Discuss this template">t</abbr></a></li>
<li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Differentiable_computing&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li>
</ul>
</div>
<div id="Differentiable_computing">Differentiable computing</div>
</th>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="catlinks" class="catlinks" data-mw="interface">
<div id="mw-normal-catlinks" class="mw-normal-catlinks"><a title="Help:Category" href="https://en.wikipedia.org/wiki/Help:Category">Categories</a>:&nbsp;
<ul>
<li><a title="Category:Neural network architectures" href="https://en.wikipedia.org/wiki/Category:Neural_network_architectures">Neural network architectures</a></li>
<li><a title="Category:Cognitive science" href="https://en.wikipedia.org/wiki/Category:Cognitive_science">Cognitive science</a></li>
<li><a title="Category:Unsupervised learning" href="https://en.wikipedia.org/wiki/Category:Unsupervised_learning">Unsupervised learning</a></li>
<li><a title="Category:Generative artificial intelligence" href="https://en.wikipedia.org/wiki/Category:Generative_artificial_intelligence">Generative artificial intelligence</a></li>
</ul>
</div>
</div>
</div>
</div>
<div class="mw-footer-container"><footer id="footer" class="mw-footer">
<ul id="footer-info">
<li id="footer-info-lastmod">This page was last edited on 24 July 2023, at 15:52<span class="anonymous-show">&nbsp;(UTC)</span>.</li>
<li id="footer-info-copyright">Text is available under the&nbsp;<a href="https://creativecommons.org/licenses/by-sa/4.0/" rel="license">Creative Commons Attribution-ShareAlike License 4.0</a>; additional terms may apply. By using this site, you agree to the&nbsp;<a href="https://foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a>&nbsp;and&nbsp;<a href="https://foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia&reg; is a registered trademark of the&nbsp;<a href="https://www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>
<ul id="footer-places">
<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy policy</a></li>
<li id="footer-places-about"><a href="https://en.wikipedia.org/wiki/Wikipedia:About">About Wikipedia</a></li>
<li id="footer-places-disclaimers"><a href="https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer">Disclaimers</a></li>
<li id="footer-places-contact"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
<li id="footer-places-wm-codeofconduct"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Universal_Code_of_Conduct">Code of Conduct</a></li>
<li id="footer-places-mobileview"><a class="noprint stopMobileRedirectToggle" href="https://en.m.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;mobileaction=toggle_view_mobile">Mobile view</a></li>
<li id="footer-places-developers"><a href="https://developer.wikimedia.org/">Developers</a></li>
<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement">Cookie statement</a></li>
</ul>
<ul id="footer-icons" class="noprint">
<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="https://en.wikipedia.org/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" alt="Wikimedia Foundation" width="88" height="31" /></a></li>
<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="https://en.wikipedia.org/static/images/footer/poweredby_mediawiki_88x31.png" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" alt="Powered by MediaWiki" width="88" height="31" /></a></li>
</ul>
</footer></div>
</div>
</div>
<div id="p-dock-bottom" class="vector-settings">&nbsp;</div>